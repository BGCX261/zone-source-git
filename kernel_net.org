#+STARTUP: showall
* 了解一下接收中断处理函数的主要任务,以后要自已写一个时可以知道要写什么东西.
- ULN:

     #+BEGIN_EXAMPLE
Specifically, the interrupt handler:
1. Copies the frame into an sk_buff data structure.*
2. Initializes some of the sk_buff parameters for use later by upper network layers
(notably skb->protocol, which identifies the higher-layer protocol handler and
will play a major role in Chapter 13).
3. Updates some other parameters private to the device, which we do not consider
in this chapter because they do not influence the frame’s path inside the net-
work stack.
4. Signals the kernel about the new frame by scheduling the NET_RX_SOFTIRQ softirq
for execution.
     #+END_EXAMPLE
** static inline int netif_running(const struct net_device *dev)
*** include/linux/netdevice.h:
- 测试net_device->state的__LINK_STATE_START.
- dev_open设置__LINK_STATE_START.
- dev_close清__LINK_STATE_START.
- dev_open()用EXPORT_SYMBOL()导出.
- dev_open()指的是网络的dev_open().
** int dev_open(struct net_device *dev)
*** net/core/dev.c:
- 开始要检查net_device->flags的IFF_UP, 这个标志是干什么的呢?
  
  ULN:IFF_UP, is used to say whether the device is enabled (up) or disabled (down).
  
  IFF_UP和__LINK_STATE_START的区别是什么呢?是什么关系呢?
  
  IFF_UP是应用层传进来的.在/usr/include/linux/if.h有定义, __LINK_STATE_START没有

- 从代码可以看出,调用这个函数时若发现IFF_UP设置,那么就不做任何事情,否则就会设置__LINK_STATE_START
- 若net_device->open没有定义,那么即会设置IFF_UP,也会设置__LINK_STATE_START,

  #+BEGIN_EXAMPLE
	set_bit(__LINK_STATE_START, &dev->state);
	if (dev->open) {
		ret = dev->open(dev);
		if (ret)
			clear_bit(__LINK_STATE_START, &dev->state);
	}

 	/*
	 *	If it went open OK then:
	 */

	if (!ret) {
		/*
		 *	Set the flags.
		 */
		dev->flags |= IFF_UP;
  #+END_EXAMPLE
  
  从以上的代码还可以看出若调用net_device->open失败的话会清掉__LINK_STATE_START,IFF_UP也不会设置.
  
  所以总结就是__LINK_STATE_START和IFF_UP是同时设和同时清的.
  
  uln是这样说__LINK_STATE_START的:A device can be considered enabled when the
         __LINK_STATE_START flag is set in net_ device->state.
         
  若是没有定义net_device->open的话就一定是打开成功的.
  
- 成功打开后就会给netdev_chain键加NETDEV_UP通知.
  
** loopback是没有使用输入输出队列的.
** 有一些设备可以让用户选择用netif_rx还是NAPI的.
** NAPI:当NAPI正处理接收帧时又接到新的帧就会继续处理; 当输入队列为空时就会使能中断.
- NAPI使用的输入队列和非NAPI使用的输入队列是不同的,后者是softnet_data->input_pkt_queue.
- 每一个CPU有一个softnet_data, softnet_data->poll_list链表里的设备都有输入帧要被处理,那么
  是不是说每一个设备都有自已输入队列呢?
  
** static void net_rx_action(struct softirq_action *h)
*** net/core/dev.c:
- [[/home/yj/net_rx_action function.png]]
- 这个函数是软中断函数
  #+BEGIN_EXAMPLE
  open_softirq(NET_RX_SOFTIRQ, net_rx_action, NULL);
  #+END_EXAMPLE
- 这个函数可以从softnet_data->input_pkt_queue(非NAPI)和设备内存(NAPI)里取帧来处理.
  
  每次调用net_rx_action(),最多只能处理netdev_max_backlog(300)个帧,这些帧可能有在非
  NAPI(softnet_data->input_pkt_queue)和NAPI(设备内存)里,而input_pkt_queue的最大值也是
  netdev_max_backlog.
  
  至于每次调用设备的poll()方法会处理多少个帧,就由poll()方法去定,不一定是处理完所有的帧,这个
  可以从代码看出
  #+BEGIN_EXAMPLE
		if (dev->quota <= 0 || dev->poll(dev, &budget)) {
			netpoll_poll_unlock(dev);
			local_irq_disable();
			list_del(&dev->poll_list);
			list_add_tail(&dev->poll_list, &queue->poll_list);
  #+END_EXAMPLE 
  还会把设备重新插到poll_list的尾部
  poll()的
  第二个参数就是返回这个调用net_rx_action()还剩多少个帧可以使用.
- 若条件满足从poll_list里取出设备,那么就从poll_list里取出设备,取出设备之后还要看设备的
  quota是否还有剩,这个quota和budget又是不一样的.
- 这个函数一共做了下的判断:
  1.poll_list是否为空
  2.budget是否还有
  3.这个函数执行是否超时
  4.设备是否还有quota
  5.设备是否还有帧没处理,poll()函数返回.
- uln: net_rx_action runs with interrupts enabled, new frames could be added to a device’s
  input queue while net_rx_action is running. Thus, the number of available frames could
  become greater than budget, and net_rx_action has to take action to make sure it does
  not run too long in such cases.

- 这个函数在处理超过netdev_max_backlog和处理时间超过一个tick就会退出
  #+BEGIN_EXAMPLE

		if (budget <= 0 || jiffies - start_time > 1)
			goto softnet_break;
  #+END_EXAMPLE 
  
  退出后会增加time_squeeze.  uln:Number of times net_rx_action had to return while frames
  were still in the CPU ingress queue, so as not to become a CPU hog.
- uln:It is important to underline that interrupts are disabled only for those devices in
  poll_list, which applies only to devices that use NAPI and do not share backlog_dev.
  
  在poll_list里的设备是禁止中断的,也就是说使用NAPI的设备是禁止中断的.
  
  但是看代码看不出哪里会有打开中断的语句啊.只是调用了一下dev_put()
- 函数一开始是禁止中断,接着就在一个while循环里遍历在softnet_data->poll_list里的设备
- 从代码看这个函数是没有时间限制的,只要jiffies不回绕就可以了
  #+BEGIN_EXAMPLE
  		if (budget <= 0 || jiffies - start_time > 1)
  #+END_EXAMPLE
- 处理完某个设备的quota个帧后还有帧时,就会把这个设备重新插入到poll_list队列,又因为
  net_rx_action()没有时间限制,所以还有帧的设备还会在本次调用net_rx_action()中被轮询到的,这
  样重新插入只是为了公平性.
[[/home/yj/snapshot1.png]]
- 从图中可以看出, 
  
  NAPI的驱动到达_netif_rx_schedule()有两条路,一条是直接到达,一条是通过netif_rx_schedule().

  其它驱动到到达_netif_rx_schedule()只能通过netif_rx_schedule()
  
  NAPI和非NAPI都使用softnet_data->poll_list队列,这个队列里的设备都禁止了中断
** static inline void netif_rx_complete(struct net_device *dev)
*** include/linux/netdevice.h:
- netif_rx_schedule()把设备加到poll_list,这个函数把设备从poll_list里删除
- 两个操作:
  1.是从poll_list链表里删除,
  2.是清掉__LINK_STATE_RX_SCHED
** static inline void netif_rx_schedule(struct net_device *dev)
*** include/linux/netdevice.h:
- 先调用netif_rx_schedule_prep()
  
  netif_rx_schedule_prep()的任务就是判断__LINK_STATE_START有没有设置, 若有设置就设
  置__LINK_STATE_RX_SCHED,所以是设置了__LINK_STATE_START才能处理接收帧的.

  netif_rx_complete()把__LINK_STATE_RX_SCHED清了, 所以设了__LINK_STATE_RX_SCHED就说明设备
  在poll_list等待处理处理.
  
  若发现__LINK_STATE_RX_SCHED已经设置了,那么就退出,若发现没设置,那么就调
  用__netif_rx_schedule(),所以可以看出若设置已经在poll_list里的话,那么就不会再调
  用__netif_rx_schedule()再把备设插入到poll_list.

- 接着就调用__netif_rx_schedule

  这个函数的任务就是:
  1. 把设备hold住,(net_device->refcnt)

  2. 把设备加到poll_list里,修改合适的net_device->quota

  3. raise NET_RX_SOFTIRQ
** static inline void netif_poll_disable(struct net_device *dev)
*** include/linux/netdevice.h:
- 这个函数是用来禁止一个设备插入到poll_list里的, 做法就是设置__LINK_STATE_RX_SCHED
- 在禁止之后是不是因为可能在调用这个函数的时都是因为netif_rx_action()执行太久了而调用的,所
  以若发现之前是没有禁止的话,那么就会用schedule_time()调度,为什么还要先设置为
  TASK_INTERRUPTIBLE呢?
  #+BEGIN_EXAMPLE
	while (test_and_set_bit(__LINK_STATE_RX_SCHED, &dev->state)) {
		/* No hurry. */
		current->state = TASK_INTERRUPTIBLE;
		schedule_timeout(1);
	}
  #+END_EXAMPLE
** int netif_rx(struct sk_buff *skb)
*** net/core/dev.c:
- [[/home/yj/netif_rx.png]]
- 一开始检查是不是使用NETPOLL的方式来处理接收帧,若是就用相应NETPOLL函数处理.处理完就返回,不
  再往下执行.
  #+BEGIN_EXAMPLE

	/* if netpoll wants it, pretend we never saw it */
	if (netpoll_rx(skb))
		return NET_RX_DROP;
  #+END_EXAMPLE
- 在netif_rx()开始设置skb->stamp时间戳,这个非NAPI的方式,那么NAPI的方式是什么呢?
  
  保存时间耗时间,所以在需要的时候才保存
  
  #+BEGIN_EXAMPLE
static inline void net_timestamp(struct timeval *stamp)
{
	if (atomic_read(&netstamp_needed))
		do_gettimeofday(stamp);
  #+END_EXAMPLE
  还有一个地方是保存时间的,就是在调用完netif_rx()的时候
  #+BEGIN_EXAMPLE
netif_rx(skb);
dev->last_rx = jiffies;
  #+END_EXAMPLE

- softnet_data->input_pkt_queue:This queue, initialized in net_dev_init, is where incoming
  frames are stored before being processed by the driver. It is used by non-NAPI drivers;
  those that have been upgraded to NAPI use their own private queues.
- 若input_pkt_queue为空,那么就先调度,再把skb插入到input_pkt_queue.
  #+BEGIN_EXAMPLE
enqueue:
			dev_hold(skb->dev);
			__skb_queue_tail(&queue->input_pkt_queue, skb);
#ifndef OFFLINE_SAMPLE
			get_sample_stats(this_cpu);
#endif
			local_irq_restore(flags);
			return queue->cng_level;
		}

		if (queue->throttle)
			queue->throttle = 0;

		netif_rx_schedule(&queue->backlog_dev);
		goto enqueue;
  #+END_EXAMPLE 
  
  为什么是先调度再插入input_pkt_queue呢?这也没问题,因为netif_rx()是在
  
  softnet_data->backlog_dev是什么来的,为什么要调度它呢?

  http://bbs.chinaunix.net/thread-3608336-1-1.html

  这里queue->backlog_dev并不是一个实际上存在的网络设备，netif_rx_schedule()只是利用了其中的
  poll函数而已.
  
  netif_rx处理过程:第一次因为接收包发生中断后，关闭中断，进入中断处理函数，此时连续处理接收
  到的包（这也是在中断期间处理多帧的本质），通过netif_rx()函数将新接收的包链入
  softdata->input_pkt_data队列上。当没有新包时，中断处理结束，开中断。
  
  softnet_data->backlog_dev是一个struct net_device的实例,不是一个指针.
  
  这个函数为什么要在队列为空时调用netif_rx_schedule()来调应backlog_dev呢?因为队列为空,那么
  poll_list里肯定是没有backlog_dev这个设备的,所以要调度它.
  
  一共有四种接收数据包的方法：
  1 轮询
  2 中断
  3 在中断期间处理多帧netif_rx
  4 NAPI
  
  这里的前提是Linux中中断处理函数是非抢占的，不可重入的，也就是说在处理一个中断时，会将本地
  CPU的所有中断全部关掉。
  
  使用netif_rx方法时，连续处理多个包的操作（操作主要是链入input_pkt_queue队列）是在中断处理
  函数中进行的，在这期间CPU的中断是关闭的。而使用NAPI时，连续处理多个包的操作也是在中断处理
  函数中进行的，但是此时进行的操作很简单，就是将该网络设备加入softnet_data->poll_list中,并
  且即使对多个包也只需进行一次。而具体的接收包的操作是在
  net_rx_action()-->netif_receive_skb()中进行的，此时的执行上下文是软中断，而CPU的中断此时
  是开启的。所以说NAPI关闭CPU中断持续的时间比netif_rx方法要少一些。
- 与skb相关的真实设备是skb->dev
- backlog_dev和input_pkt_queue是什么关系呢?
  
  所有的非NAPI设备的接收帧skb都放到input_pkt_queue里,处理input_pkt_queue的skb都是用
  backlog_dev->poll函数,实现为process_backlog().在process_backlog()里就是循环从
  input_pkt_queue取出skb,再把skb传给netif_receive_skb(),再dev_put(skb->dev).
- - uln:The input queue is managed by softnet_data->input_pkt_queue. Each input queue has a
  maximum length given by the global variable netdev_max_backlog, whose value is 300. This
  means that each CPU can have up to 300 frames in its input queue wait-ing to be
  processed, regardless of the number of devices in the system.*
  
  每个cpu的input_pkt_queue的最大值是300,不管有多少的设备,但这只对非NAPI设备而言.NAPI有自己
  的队列.
  
  #+BEGIN_EXAMPLE
	if (queue->input_pkt_queue.qlen <= netdev_max_backlog) {
		if (queue->input_pkt_queue.qlen) {
			if (queue->throttle)
				goto drop;

enqueue:
			dev_hold(skb->dev);
			__skb_queue_tail(&queue->input_pkt_queue, skb);
  #+END_EXAMPLE 
  
  uln:However, this is hard to keep track of in an SMP system where the interrupts are
  distributed dynamically among the CPUs. It is not obvious which device will talk to
  which CPU. Thus, the value of netdev_max_backlog is chosen through trial and error. 
  
- netif_rx()这个函数是会把包丢掉的,当在throttle时就会,就是在input_pkt_queue的大小大于300时.
** static int process_backlog(struct net_device *backlog_dev, int *budget)
*** include/linux/netdevice.h:
- [[/home/yj/process_backlog function.png]]
- 这个函数是backlog_dev->poll的实现
- 在net_rx_action()的budget是300,backlog_dev->quota是64,所以若在input_pkt_queue里的设备都
  是超过64,那么最多可以处理4个设备.在net_rx_action()里若处理了某个设备的quota个帧就会把设
  备插到poll_list尾部.
- 取传入的budget和backlog_dev->quota的最小值作为要处理的skb数.在net_rx_action()调用poll方
  法时传入的budget是netdev_max_backlog这个常量.所以这样做就是限制最大值.
- skb都是从input_pkt_queue里取出的.
- 调用netif_receive_skb()处理skb,再dev_put(skb->dev),每当有一个skb->dev引用设备,就get一次
  该设备.
- 当input_pkt_queue里没有帧时,就会把backlog_dev从poll_list里删除,并清
  掉__LINK_STATE_RX_SCHED,以示可以调度backlog_dev,就是可以把backlog_dev再插入poll_list里了.
- 所以驱动调用netif_rx()把skb放到input_pkt_queue里去,调度backlog_dev.软中断处理函数
  net_rx_action()就把input_pkt_queue里的skb给取出来处理.
** not function
- 当流量很大而使CPU负载很高时的处理:
 1. Reducing the number of interrupts if possible
 2. Discarding frames as early as possible in the ingress path
** static void get_sample_stats(int cpu)
*** net/core/dev.c:
- 这个函数用来计算拥塞的,在netif_rx()里调用.
- 通过当前的softnet_data->avg_blog和softnet_data->input_pkt_queue.qlen来计算当前的avg_blog
  值
  #+BEGIN_EXAMPLE
	int blog = sd->input_pkt_queue.qlen;
	int avg_blog = sd->avg_blog;

	avg_blog = (avg_blog >> 1) + (blog >> 1);
  #+END_EXAMPLE 
  #+BEGIN_EXAMPLE
	sd->avg_blog = avg_blog;
  #+END_EXAMPLE 
- 得出的avg_blog值与mod_cong,lo_cong,no_cong比较,大于这些值分别表示高,中,低的拥塞,小于
  no_cong就表示NET_RX_SUCCESS,
  
  cng_level的值有:
  #+BEGIN_EXAMPLE
#define NET_RX_SUCCESS		0   /* keep 'em coming, baby */
#define NET_RX_DROP		1  /* packet dropped */
#define NET_RX_CN_LOW		2   /* storm alert, just in case */
#define NET_RX_CN_MOD		3   /* Storm on its way! */
#define NET_RX_CN_HIGH		4   /* The storm is here */
#define NET_RX_BAD		5  /* packet dropped due to kernel error */
  #+END_EXAMPLE 
- netif_rx()返回的是cng_level的值.当是NET_RX_DROP时,调用netif_rx()的驱动就会
- 在netif_rx()有判断OFFLINE_SAMPLE
  #+BEGIN_EXAMPLE
#ifndef OFFLINE_SAMPLE
			get_sample_stats(this_cpu);
#endif
  #+END_EXAMPLE
  uln:调用avg_blog和cng_level只在get_sample_stats调用,但调用它有两种方式,一个是netif_rx(),
  一个是周期调用,但不能同时使用,通过OFFLINE_SAMPLE判断
- 有RAND_LIE的原因:
  在系统有多个设备使用一个队列时,防止贪婪的设备.
  
  uln:In a system with only one interface, it does not really make sense to drop random
  frames here and there if there is no congestion; it would simply lower the through-
  put. But let’s suppose we have multiple interfaces sharing an input queue and one device
  with a traffic load much higher than the others. Since the greedy device fills the
  shared ingress queue faster than the other devices, the latter will often find no space
  in the ingress queue and therefore their frames will be dropped.* The greedy device will
  also see some of its frames dropped, but not proportionally to its load. When a system
  with multiple interfaces experiences congestion, it should drop ingress frames across
  all the devices proportionally to their loads. The RAND_LIE code adds some fairness when
  used in this context: dropping extra frames randomly should end up dropping them
  proportionally to the load. 
** int netif_receive_skb(struct sk_buff *skb)
*** net/core/dev.c:
- [[/home/yj/netif_receive_skb function.png]]
- 一开始做的事和netif_rx的一样:
  1.调用netpoll_rx()
  2.设置skb->stamp
  
  若是非NAPI,会先调用netif_rx(),之后软中断net_rx_action()会调用process_backlog(),转而调用
  netif_receive_skb(),所以会设置再次,但netpoll_rx不是调用两次,因为netif_rx()调用完
  netpoll_rx()之后就会直接退出,而不会做后面的处理.
- 接着处理bond设备, uln:Bonding allows a group of interfaces to be grouped together and be
  treated as a sin-gle interface. If the interface from which the frame was received
  belonged to one such group, the reference to the receiving interface in the sk_buff data
  structure must be changed to the device in the group with the role of master before
  netif_receive_skb delivers the packet to the L3 handler. 
  
  skb_bond()就把skb->dev赋给skb->real_dev,skb->dev->master赋给skb->dev->master.
- uln:When neither the bridging code nor the ingress Traffic Control code consumes the
  frame, the latter is passed to the L3 protocol handlers (usually there is only one
  handler per protocol, but multiple ones can be registered).
** not function
- 相对接收的poll_list,发送的有output_queue
- __LINK_STATE_START设置了就可以接收,但发送要 _清_ __LINK_STATE_XOFF
- 调度了设备接收就设置__LINK_STATE_RX_SCHED ,
  
  发送就设置__LINK_STATE_SCHED.
- dev_queue_xmit()和netif_rx()类似.

  [[/home/yjScheduling a device: (a) for reception (RX); (b) for transmission (TX).png]]
** static inline void netif_start_queue(struct net_device *dev)
*** include/linux/netdevice.h:
- 清__LINK_STATE_XOFF
** static inline void netif_stop_queue(struct net_device *dev)
*** include/linux/netdevice.h:
- 设置__LINK_STATE_XOFF
** static inline int netif_queue_stopped(const struct net_device *dev)
*** include/linux/netdevice.h:
- 判断__LINK_STATE_XOFF
** static inline void netif_schedule(struct net_device *dev)
*** include/linux/netdevice.h:
- 结合里面调用的__netif_schedule()来看.
- 若设备被允许发送帧__LINK_STATE_XOFF,那么调用完这个函数就一定是表明设备被调度了,也就是
  说__LINK_STATE_SCHED设置了,__LINK_STATE_SCHED设置了也就说明设备已经在output_queue队列里了
- 从把设备插入到output_queue队列来看,output_queue是一个单向链表,
  #+BEGIN_EXAMPLE
		dev->next_sched = sd->output_queue;
		sd->output_queue = dev;
  #+END_EXAMPLE
- 插入完就raise软中断.
- uln:output_queue is used by both NAPI and non-NAPI devices, and poll_list is used only
  to handle NAPI devices.
  
  NAPI和非NAPI设备都是插入到output_queue队列,和输入的不同.
- uln:output_queue represents a list of devices that have something to send (because they
  failed on previous attempts, as described in the section “Queuing Discipline
  Inter-face”) or whose egress queues have been re-enabled after having been disabled for
  a while.
  
  有帧要发送的设备会插入到output_queue,
  
  被禁止的设备的输出队列重新使能后该设备也会被插入到队列,为什么可以这样呢?
** static inline void netif_wake_queue(struct net_device *dev)
*** include/linux/netdevice.h:
- 这个函数与netif_schedule()只有一个不同,就是用test_and_clear_bit(),而不是test_bit()
  #+BEGIN_EXAMPLE
static inline void netif_wake_queue(struct net_device *dev)
{
#ifdef CONFIG_NETPOLL_TRAP
	if (netpoll_trap())
		return;
#endif
	if (test_and_clear_bit(__LINK_STATE_XOFF, &dev->state))
		__netif_schedule(dev);
}
  #+END_EXAMPLE
- 结果就是这个函数执行完之后设备一定是在output_queue里的.
  
  相当于执行netif_start_queue()和netif_schedule()
** not function
- Almost all devices use a queue to schedule egress traffic, and the kernel can use
  algorithms known as queuing disciplines to arrange the frames in the most efficient
  order for transmission.
- Whenever a device is scheduled for transmission, the next frame to transmit is selected
  by the qdisc_run function, which indirectly calls the dequeue virtual function of the
  associated queuing discipline.
** static inline void qdisc_run(struct net_device *dev)
*** include/net/pkt_sched.h:
- 先判断设备是不是被关闭发送了,就是判断__LINK_STATE_XOFF是否设置.若可以发送就调用
  qdisc_restart()
** int qdisc_restart(struct net_device *dev)
*** net/sched/sch_generic.c:
- [[/home/yj/qdisc_restart function.png]]
- uln:a device is scheduled for transmission.Sometimes it is because something in the
  egress queue is waiting to be transmitted. But at other times, the device is scheduled
  because the queue has been disabled for a while and therefore there could be something
  waiting in the queue from previous failed transmission attempts. The driver does not
  know whether anything has actually arrived; it must schedule the device in case data is
  waiting. If in fact no data is waiting, the subsequent call to the dequeue method
  fails. Even if data is waiting, the call can fail because complex queuing disciplines
  may decide not to transmit any of the data.
  
  当设备被调度来发送时,一般是因为有东西在输出队列里等待发送,有时是因为设备被禁止了,在使能
  之前有数据放到输出队列里,但是因为设备被禁止而不能调度,所以在使能之后要再调度它.
- 函数一开始就dequeue队列了,从中取出发送帧
- 调用这个函数需要2个锁:
  
  uln:
  
  1. The lock that protects the queue (dev->queue_lock). This is acquired by the caller of
     qdisc_restart (dev_queue_xmit).
     
     dev->queue_lock锁,这个锁在调用qdisc_restart()之前已经在dev_queue_xmit()获
     取.qdisc_restart()就不用再获取.

  2. The lock on the driver’s transmit routine hard_start_xmit (dev->xmit_lock). The lock
     is managed by this function. When the device driver already implements its own
     locking, it indicates this by setting the NETIF_F_LLTX flag (lockless transmission
     feature) in dev->features to tell the upper layers that there is no need to acquire
     the dev->xmit_lock lock as well. The use of NETIF_F_LLTX allows the kernel to
     optimize the transmit data path by not acquiring dev->xmit_lock when it is not
     needed. Of course, there is no need to acquire the lock if the queue is empty.
     
     另一个是dev->xmit_lock,但这个锁被驱动自已实现的锁给代替了,就是dev->features的
     NETIF_F_LLTX标志,dev->features告诉上层没有必要获取dev->xmit_lock.
     
     以下代码是判断驱动是否支持NETIF_F_LLTX
     #+BEGIN_EXAMPLE
   		unsigned nolock = (dev->features & NETIF_F_LLTX);
     #+END_EXAMPLE
     
     若不支持,那么获取dev->xmit_lock锁,那么就是有问题的,若是同一CPU获取的,就返回-1,若是另一
     个CPU获取的就把帧重新插入队列.
     #+BEGIN_EXAMPLE
   			if (!spin_trylock(&dev->xmit_lock)) {
			collision:
				/* So, someone grabbed the driver. */
				
				/* It may be transient configuration error,
				   when hard_start_xmit() recurses. We detect
				   it by checking xmit owner and drop the
				   packet when deadloop is detected.
				*/
				if (dev->xmit_lock_owner == smp_processor_id()) {
					kfree_skb(skb);
					if (net_ratelimit())
						printk(KERN_DEBUG "Dead loop on netdevice %s, fix it urgently!\n", dev->name);
					return -1;
				}
				__get_cpu_var(netdev_rx_stat).cpu_collision++;
				goto requeue;
			}
      #+END_EXAMPLE 
- 虽然qdisc_run()已经调用netif_queue_stopped()做检查,但是到qdisc_restart()里面才获取锁,所
  以在获取锁之后要再调用一次netif_queue_stopped().
  #+BEGIN_EXAMPLE
			if (!netif_queue_stopped(dev)) {
  #+END_EXAMPLE 
- uln:netdev_nit represents the number of protocol sniffers registered. If any are
  registered, dev_queue_xmit_nit is used to deliver a copy of the frame to each.
  
  #+BEGIN_EXAMPLE
				if (netdev_nit)
					dev_queue_xmit_nit(skb, dev);
  #+END_EXAMPLE
- 然后就是调用设备的hard_start_xmit()来发送帧了
  #+BEGIN_EXAMPLE
				ret = dev->hard_start_xmit(skb, dev);
  #+END_EXAMPLE 
- hard_start_xmit()返回NETDEV_TX_OK表示帧发送成功,但是为什么返回-1呢?
  
  #+BEGIN_EXAMPLE
				if (ret == NETDEV_TX_OK) { 
					if (!nolock) {
						dev->xmit_lock_owner = -1;
						spin_unlock(&dev->xmit_lock);
					}
					spin_lock(&dev->queue_lock);
					return -1;
				}
  #+END_EXAMPLE 
  有注释是这样说返回值的:
  #+BEGIN_EXAMPLE
   Returns:  0  - queue is empty.
            >0  - queue is not empty, but throttled.
	    <0  - queue is not empty. Device is throttled, if dev->tbusy != 0.
  #+END_EXAMPLE 
  
  若不是以上两个返回值,那么就是NETDEV_TX_BUSY了,且从代码看,往后执行的代码都是
  NETDEV_TX_BUSY的情况.
  
  返回NETDEV_TX_BUSY是因为:uln:The driver has discovered that the NIC lacks sufficient
  room in its transmit buffer pool. When this condition is detected, the driver often
  calls netif_stop_queue too.
  #+BEGIN_EXAMPLE
			/* NETDEV_TX_BUSY - we need to requeue */
			/* Release the driver */
			if (!nolock) { 
				dev->xmit_lock_owner = -1;
				spin_unlock(&dev->xmit_lock);
			} 
			spin_lock(&dev->queue_lock);
			q = dev->qdisc;
		}

		/* Device kicked us out :(
		   This is possible in three cases:

		   0. driver is locked
		   1. fastroute is enabled
		   2. device cannot determine busy state
		      before start of transmission (f.e. dialout)
		   3. device is buggy (ppp)
		 */

requeue:
		q->ops->requeue(skb, q);
		netif_schedule(dev);
		return 1;
  #+END_EXAMPLE 
- 总结把帧重新插入队列的原因:uln:
  
  1. The queue is disabled (netif_queue_stopped(dev) is true).
  2. Another CPU is holding the lock on the driver.
  3. The driver failed (hard_start_xmit did not return NETDEV_TX_OK).

** not function
- dev_queue_xmit()可以有两种路径来调用dev->hard_start_xmit
  
  1. 调用qdisc_run() -> qdisc_restart() -> hard_start_xmit() 在qdisc_restart()里已说.
     
  2. 直接调用.
** int dev_queue_xmit(struct sk_buff *skb)
*** net/core/dev.c:
- [[/home/yj/dev_queue_xmit function.png]]
  [[/home/yj/dev_queue_xmit function1.png]]
- 这个函数开始要检查有效负载的是否分段,

  若分段,那么skb_shinfo(skb)->frag_list不为空.
  
  若设备支持scatter/gather DMA,那么NETIF_F_FRAGLIST就设置.
  
  __skb_linearize()是合并段的.
  #+BEGIN_EXAMPLE
if (skb_shinfo(skb)->frag_list &&
!(dev->features&NETIF_F_FRAGLIST) &&
_ _skb_linearize(skb, GFP_ATOMIC)) {
goto out_kfree_skb;
}
  #+END_EXAMPLE 
  
  也要合并在高端内存的段.
  #+BEGIN_EXAMPLE
	/* Fragmented skb is linearized if device does not support SG,
	 * or if at least one of fragments is in highmem and device
	 * does not support DMA from it.
	 */
	if (skb_shinfo(skb)->nr_frags &&
	    (!(dev->features & NETIF_F_SG) || illegal_highdma(dev, skb)) &&
	    __skb_linearize(skb, GFP_ATOMIC))
		goto out_kfree_skb;
  #+END_EXAMPLE 
- 接下来是作检验,要使用软件校验的情况:uln:
  
  1. There is no support for hardware checksumming.
  2. The interface can use hardware checksumming only for TCP/UDP packets over IP, but the
     packet being transmitted does not use IP or uses another L4 protocol over IP.
     
  #+BEGIN_EXAMPLE
  /* If packet is not checksummed and device does not support
  * checksumming for this protocol, complete checksumming here.
  */
  if (skb->ip_summed == CHECKSUM_HW &&
  (!(dev->features & (NETIF_F_HW_CSUM | NETIF_F_NO_CSUM)) &&
  (!(dev->features & NETIF_F_IP_CSUM) ||
  skb->protocol != htons(ETH_P_IP))))
  if (skb_checksum_help(skb, 0))
  goto out_kfree_skb;
  #+END_EXAMPLE 
  
  对于接收和发送,就算skb->ip_summed有相同的值,但是有不同的意思.对于发送的CHECKSUM:uln:The
  protocol has stored into its header the checksum on the pseudoheader only;the device is
  supposed to complete it by adding the checksum on the L4 header and payload.
  
  #+BEGIN_EXAMPLE
#define NETIF_F_HW_CSUM		8	/* Can checksum all the packets. */
#define NETIF_F_NO_CSUM		4	/* Does not require checksum. F.e. loopack. */
#define NETIF_F_IP_CSUM		2	/* Can checksum only TCP/UDP over IPv4. */
  #+END_EXAMPLE 
- uln:Once the checksum has been handled, all the headers are ready; the next step is to
  decide which frame to transmit.
- 若使用了流量控制,就是说dev->qdisc->enqueue虚函数被设置,那么就用qdisc->enqueue把帧插入队
  列,然后再调用qdisc_run()来选一个帧发送,被选到的不一定是刚插入的.
  #+BEGIN_EXAMPLE
	q = rcu_dereference(dev->qdisc);
#ifdef CONFIG_NET_CLS_ACT
	skb->tc_verd = SET_TC_AT(skb->tc_verd,AT_EGRESS);
#endif
	if (q->enqueue) {
		/* Grab device queue */
		spin_lock(&dev->queue_lock);

		rc = q->enqueue(skb, q);

		qdisc_run(dev);

		spin_unlock(&dev->queue_lock);
		rc = rc == NET_XMIT_BYPASS ? NET_XMIT_SUCCESS : rc;
		goto out;
	}
  #+END_EXAMPLE 
  
  以上的代码是在有队列的处理,处理完就goto out了,以下的代码是没有队列的处理
  #+BEGIN_EXAMPLE
	if (dev->flags & IFF_UP) {
		int cpu = smp_processor_id(); /* ok because BHs are off */

		if (dev->xmit_lock_owner != cpu) {

			HARD_TX_LOCK(dev, cpu);

			if (!netif_queue_stopped(dev)) {
				if (netdev_nit)
					dev_queue_xmit_nit(skb, dev);

				rc = 0;
				if (!dev->hard_start_xmit(skb, dev)) {
					HARD_TX_UNLOCK(dev);
					goto out;
				}
			}
			HARD_TX_UNLOCK(dev);
			if (net_ratelimit())
				printk(KERN_CRIT "Virtual device %s asks to "
				       "queue packet!\n", dev->name);
		} else {
			/* Recursion is detected! It is possible,
			 * unfortunately */
			if (net_ratelimit())
				printk(KERN_CRIT "Dead loop on virtual device "
				       "%s, fix it urgently!\n", dev->name);
		}
	}
  #+END_EXAMPLE 
  
  从上面代码看,在没有流量控制插入队列的函数的情况下,要设置了IFF_UP才可以发送
  
  从上面代码看,锁的拥有者不能是自己,否则出错.
  
  在HARD_TX_LOCK里,若发现设置了NETIF_F_LLTX,就不用给dev->xmit_lock加锁了,
  
  在上面的代码里有一段是和disc_restart()的一段类似的,就是
  1. 判断是否使能发送
     #+BEGIN_EXAMPLE
   			if (!netif_queue_stopped(dev)) {
     #+END_EXAMPLE

  2. 是否有nit设备,若有就把帧发给nit设备
     #+BEGIN_EXAMPLE
				if (netdev_nit)
					dev_queue_xmit_nit(skb, dev);
     #+END_EXAMPLE

  3. 调用hard_start_xmit()发送.
     #+BEGIN_EXAMPLE
     				if (!dev->hard_start_xmit(skb, dev)) {
					HARD_TX_UNLOCK(dev);
					goto out;
				}
     #+END_EXAMPLE
** static void net_tx_action(struct softirq_action *h)
*** net/core/dev.c:
- 这个函数是NET_TX_SOFTIRQ的软中断处理函数
- 在两个地方被调用
  
  uln:
  
   It can be triggered with raise_softirq_irqoff(NET_TX_SOFTIRQ) by devices in two
  different contexts, to accomplish two main tasks:
  1. By netif_wake_queue when transmission is enabled on a device. In this case, it makes
     sure that frames waiting to be sent are actually sent when all the needed conditions
     are met (for instance, when the device has enough memory).
  2. By dev_kfree_skb_irq when a transmission has completed and the device driver signals
     with the former routine that the associated buffer can be released. In this case, it
     deallocates the sk_buff structures associated with successfully transmitted buffers.
  
  一个是在netif_wake_queue(),也就是里面调用的__netif_schedule(),netif_schedule()也调
  用__netif_schedule().
  
  另一个是dev_kfree_skb_irq(),但是在dev_kfree_skb()里没有,上面的uln说是为了释放skb
  buffer的,因为释放要占用时间,而中断的执行时间要尽可能的短,所以放到net_tx_action()里释放已
  完成发送的buffer的.
- 一开始是释放buffer
  #+BEGIN_EXAMPLE
	if (sd->completion_queue) {
		struct sk_buff *clist;

		local_irq_disable();
		clist = sd->completion_queue;
		sd->completion_queue = NULL;
		local_irq_enable();

		while (clist) {
			struct sk_buff *skb = clist;
			clist = clist->next;

			BUG_TRAP(!atomic_read(&skb->users));
			__kfree_skb(skb);
		}
	}
  #+END_EXAMPLE 
  
  它是释放所有在队列里的buffer,不是被限制释放多少个buffer.
  
  buffer是在中断上下文中调用dev_kfree_skb_irq()把buffer加入队列的,所以访问
  softdata->completion_queue时要禁止中断.
- 接下来就是处理发送帧的发送了
  #+BEGIN_EXAMPLE
	if (sd->output_queue) {
		struct net_device *head;

		local_irq_disable();
		head = sd->output_queue;
		sd->output_queue = NULL;
		local_irq_enable();

		while (head) {
			struct net_device *dev = head;
			head = head->next_sched;

			smp_mb__before_clear_bit();
			clear_bit(__LINK_STATE_SCHED, &dev->state);

			if (spin_trylock(&dev->queue_lock)) {
				qdisc_run(dev);
				spin_unlock(&dev->queue_lock);
			} else {
				netif_schedule(dev);
			}
		}
  #+END_EXAMPLE
  这个函数也是一次想处理掉所有的输出队列的设备
  
  处理每一个buffer前,都会把dev->state的__LINK_STATE_SCHED给清掉
  
  接着就是获取设备的输出队列锁,若这个锁被其它CPU给取了,那么现在就不能处理这个设备的输出队
  列,其它CPU获取这个锁的原因可能是因为往队列里加buffer或发送buffer,所以还是重新再调度设备.
  
  最终的发送还是在net_tx_action()里调用qdisc_run(),转而调用qdisc_restart(),转而调用设备虚
  函数hard_start_xmit()
** not function
*** [[/home/yj/the big picture.png]]
*** [[/home/yj/Data_structure_used_to_store_the_registered_protocol_handlers.png]]
    #+BEGIN_EXAMPLE
  struct packet_type {
	__be16			type;	/* This is really htons(ether_type).	*/
	struct net_device		*dev;	/* NULL is wildcarded here		*/
	int			(*func) (struct sk_buff *, struct net_device *,
					 struct packet_type *);
	void			*af_packet_priv;
	struct list_head	list;
};

    #+END_EXAMPLE 
** void dev_add_pack(struct packet_type *pt)
*** net/core/dev.c:
- 功能注释有：
  #+BEGIN_EXAMPLE
 *	Add a protocol handler to the networking stack. The passed &packet_type
 *	is linked into kernel lists and may not be freed until it has been
 *	removed from the kernel lists.
  #+END_EXAMPLE 
- 为什么要转ETH_P_ALL的字节序呢?
  #+BEGIN_EXAMPLE
	if (pt->type == htons(ETH_P_ALL)) {
  #+END_EXAMPLE 
  因为pt->type的数据是从网络转入的.所以ETH_P_ALL这些值也不是linux内核自己规定的.
  
- uln:netdev_nit represents the number of protocol sniffers registered. If any are
  registered, dev_queue_xmit_nit is used to deliver a copy of the frame to each.
  
  ETH_P_ALL:This is not a real protocol. It is used as a wildcard for a handler such as a
  packet sniffer that listens to all the protocols.
  
  #+BEGIN_EXAMPLE
	if (pt->type == htons(ETH_P_ALL)) {
		netdev_nit++;
		list_add_rcu(&pt->list, &ptype_all);
	} else {
  #+END_EXAMPLE
- ETH_P_ALL的类型的都是放到ptype_all链表里的,
  #+BEGIN_EXAMPLE
	if (pt->type == htons(ETH_P_ALL)) {
		netdev_nit++;
		list_add_rcu(&pt->list, &ptype_all);
  #+END_EXAMPLE 
- 其它的类型放到ptype_base这个hash链表里,链表是与上15
  #+BEGIN_EXAMPLE
		hash = ntohs(pt->type) & 15;
		list_add_rcu(&pt->list, &ptype_base[hash]);
  #+END_EXAMPLE 
- struct packet_type这个结构体是给第二层用的.
  http://blog.csdn.net/jw212/article/details/6738497
- 现在有一个问题就是驱动是在哪一层的呢?
  http://cache.baiducontent.com/c?m=9d78d513d9d430d94f999e697c16c0111c4381132ba6d5020ba2843897732835506692fd76600704a29e3e7000df5e2dece74774200250a0edc89f3aadac935838f82723071d9206528d16f58d0067d621e347f4ff49a6adf04593ad8982c854249b0e5a67dba1cf015751dd6f861532e5a79f5f152913aded4666e8590073d97c1e&p=882a9645d5d21fec1ea4d32d02148f&newp=882a9645d59e16fc57ef8f665443cf231610db2151d3d7122283&user=baidu&fm=sc&query=%CD%F8%C2%E7%C7%FD%B6%AF+tcp+ip%C4%C4%D2%BB%B2%E3&qid=&p1=3
  
  http://blog.csdn.net/jw212/article/details/6738497
  这个文章有说netif_receive_skb()是第二层的,之前是经过了驱动的了,在process_backlog()里会调
  用netif_receive_skb(),process_backlog()是驱动的下半部分,因为驱动把后半部分的任务交给了软
  中断,在软中断里调用了process_backlog (),所以驱动还是第二层,而且是第二层的一部分.
- 协议是可以以一个模块的方式给加载进去的.  uln:If dev_add_pack was called within the
  function init_module, which is in charge of module initialization, dev_remove_pack is
  most likely within cleanup_module, which is called by the kernel when the module is to
  be removed.
- Ethernet这个词是指哪一层呢?  uln:A number of protocols go under the loose term
  Ethernet. The 802.2 and 802.3 standards are represented by the protocols ETH_P_802_2 and
  ETH_P_802_3, respectively, but there are many other Ethernet protocols, listed in Table
  13-2, as well as the LLC and SNAP extensions. 
** not function
- 以太网头的定义
  #+BEGIN_EXAMPLE
struct ethhdr
{
unsigned
 char
 h_dest[ETH_ALEN];
unsigned
 char
 h_source[ETH_ALEN];
unsigned
 short h_proto;
} __ATTRIBUTE__((packed));
  #+END_EXAMPLE 
- 802.2和802.3都是用Ethernet的头,但是使用的不同是h_proto域,
  #+BEGIN_EXAMPLE
To save space, the IEEE decided to use values greater than 1,536 to represent the
Ethernet protocol. Some preexisting protocols with identifiers lower than 1,536
(0x600 hexadecimal) were updated to meet the criteria. The 802.2 and 802.3 protocols,
however, use the field to store the length of the frame.* Values ranging from
1,501 to 1,535 are not legal in this field.
  #+END_EXAMPLE
  
  大于1500表示是Ethernet帧,且h_proto表示协议号.
  
  若小于1500表示是802.2或802.3号,且h_proto表示帧的长度.
  
  [[/home/yj/Differences_between_Ethernet_and_802.3_frames.png]]
  
  IEEE 802.2 逻辑链路控制(LLC)
  IEEE 802.3 带碰撞检测的载波侦听多路访问(CSMA/CD)方法和物理层规范(以太网)
** unsigned short eth_type_trans(struct sk_buff *skb, struct net_device *dev)
*** net/ethernet/eth.c:
- 这个函数有两个件务,首先是设置skb->pkt_type,再就是确定好正确的协议(skb->protocol)再返回.
- skb->mac的注释是
  #+BEGIN_EXAMPLE
 *	@mac: Link layer header
  #+END_EXAMPLE
  #+BEGIN_EXAMPLE
	union {
	  	unsigned char 	*raw;
	} mac;
  #+END_EXAMPLE 

  从下面的代码看出这个函数是在第二层调用的
  #+BEGIN_EXAMPLE
	skb->mac.raw=skb->data;
  #+END_EXAMPLE
- 之后是移skb->data的指针
  #+BEGIN_EXAMPLE
	skb_pull(skb,ETH_HLEN);
  #+END_EXAMPLE 
  从uln的图13-8可以看出,以太网帧的头的确是14(ETH_HLEN).
- 接着就是获取以太网头
  #+BEGIN_EXAMPLE
	eth = eth_hdr(skb);
  #+END_EXAMPLE
- 设置输入设备
  #+BEGIN_EXAMPLE
 *	@input_dev: Device we arrived on
  #+END_EXAMPLE 
  #+BEGIN_EXAMPLE
	skb->input_dev = dev;
  #+END_EXAMPLE
- 接下来判断是广播还是多播
  
  uln:An Ethernet address is 48 bits or 6 bytes long. The two
  least significant bits of the first byte (in network byte order) have a special meaning
  (see Figure 13-9):
  
  1. Bit 0 distinguishes multicast addresses from unicast addresses. Broadcast addresses
     are a special case of multicast. When set to 1, this bit denotes multicast; when 0,
     it denotes unicast. After checking the bit through if(*eth->h_dest&1), the function
     goes on to see whether the frame is a broadcast frame by comparing the address to the
     device’s broadcast address through memcmp(eth->h_dest,dev->broadcast, ETH_ALEN).
  2. Bit 1 distinguishes local addresses from global addresses. Global addresses are
     worldwide unique, local addresses are not: it is up to the system administrator to
     assign local addresses properly.* When set to 1, this bit denotes a global address;
     when 0, it denotes a local address.

  #+BEGIN_EXAMPLE
  if(*eth->h_dest&1)
  {
  if(memcmp(eth->h_dest,dev->broadcast, ETH_ALEN)==0)
  skb->pkt_type=PACKET_BROADCAST;
  else
  skb->pkt_type=PACKET_MULTICAST;
  }
  #+END_EXAMPLE
  #+BEGIN_EXAMPLE
  /*
  *	This ALLMULTI check should be redundant by 1.4
  *	so don't forget to remove it.
  *
  *	Seems, you forgot to remove it. All silly devices
  *	seems to set IFF_PROMISC.
  */
	 
  else if(1 /*dev->flags&IFF_PROMISC*/)
  {
  if(memcmp(eth->h_dest,dev->dev_addr, ETH_ALEN))
  skb->pkt_type=PACKET_OTHERHOST;
  }
  #+END_EXAMPLE
- 接下来就是返回合适的协议
  
  #+BEGIN_EXAMPLE
	if (ntohs(eth->h_proto) >= 1536)
		return eth->h_proto;
		
	rawp = skb->data;
	
	/*
	 *	This is a magic hack to spot IPX packets. Older Novell breaks
	 *	the protocol design and runs IPX over 802.3 without an 802.2 LLC
	 *	layer. We look for FFFF which isn't a used 802.2 SSAP/DSAP. This
	 *	won't work for fault tolerant netware but does for the rest.
	 */
	if (*(unsigned short *)rawp == 0xFFFF)
		return htons(ETH_P_802_3);
		
	/*
	 *	Real 802.2 LLC
	 */
	return htons(ETH_P_802_2);
  #+END_EXAMPLE
- uln:If values bigger than 1,536 are interpreted as protocol IDs, how does a device
  driver find the size of the frames it receives? In both cases, whether protocol/length
  values are less than 1,500 or greater than 1,536, it is the device itself that stores
  the size of the frame into one if its registers, where the device driver can read
  it. Devices can figure out the size of each frame thanks to well-known bit patterns used
  for that purpose.
  
  若h_proto表示协议,那么从设备的寄存器获取帧长度.以下是 drivers/net/3c59x.c 里的
  vortex_rx()代码.
  #+BEGIN_EXAMPLE
/* The packet length: up to 4.5K!. */
int pkt_len = rx_status & 0x1fff;
struct sk_buff *skb;
skb = dev_al打loc_skb(pkt_len + 5);
  #+END_EXAMPLE
- 这个函数的返回值是赋给skb->protocol的,所以ETH_P_802_2这类东西是给skb->protocol的.
  
  skb->protocol是网络字节序的.
- 这个是给以太网用的,还有其它类似的如tr_type_trans().
- Whenever an incoming frame is classified by eth_type_trans as using the LLC header
  (because it has a type/length field that is less than 1,536 and no special IPX case is
  detected), the initialization of skb->protocol to ETH_P_802_2 leads to the selection of
  the llc_rcv handler (see Table 13-1). This handler will select the right protocol
  handler based on the DSAP field in the LLC header: to do so, it calls the rcv_func
  handler registered with llc_sap_open for those SAPs opened by the kernel, and feeds the
  right input to the right state machine when the SAPs were opened with a PF_LLC socket
  (see Figure 13-10).
** not function
*** Ethernet Versus IEEE 802.3 Frames 
- The data structure used to define a SNAP protocol is datalink_proto
  #+BEGIN_EXAMPLE
struct datalink_proto {
        unsigned char   type[8];

	struct llc_sap   *sap;

        unsigned short  header_length;

        int     (*rcvfunc)(struct sk_buff *, struct net_device *,
                                struct packet_type *);
	int     (*request)(struct datalink_proto *, struct sk_buff *,
                                        unsigned char *);
	struct list_head node;
};
  #+END_EXAMPLE 
- [[/home/yj/Figure 13-11. Protocol detection for Ethernet 802.3 802.3 SNAP frames.png]]
  这个图上面就是eth_type_trans()
** not function
*** Chapter 14: Bridging: Concepts
- [[/home/yj/Figure 14-1. (a) Repeater; (b) bridge; (c) router.png]]
- [[/home/yj/Figure 14-5. Address learning and aging.png]]
- [[./Figure 15-2. Hierarchical bridged L2 topology.png]]
  注意access交换机,distribute交换机,core交换机.
- [[./Figure 15-6. Port state transitions.png]]
- [[./Figure 15-7. Bridge ID and port ID changes introduced by 802.1t.png]]
- [[./Figure 15-8. a) Configuration BPDU; b) BPDU.png]]
- [[./Table 15-3. BPDU versions.png]]
- [[./Figure 15-15. Handling the Forward Delay timer.png]]
- [[./Figure 15-20. BPDU encapsulation.png]]
- [[./Figure 15-21. Configuration BPDU transmission logic.png]]
- [[./Figure 16-3. (a) Transmitting on a bridge device; (b) receiving on a bridge device.png]]
** static int __init br_init(void)
*** net/bridge/br.c:
- 这个函数是用来初始化网桥的,可以编进内核也可以编成模块.
- 一开始调用br_fdb_init ()来建立 net_bridge_fdb_entry结构体的slab cache
- 若有设置CONFIG_BRIDGE_NETFILETER,那么说明有打开网桥的防火墙.可以看出网桥也是有嵌入防火墙
  的.
  #+BEGIN_EXAMPLE
#ifdef CONFIG_BRIDGE_NETFILTER
	if (br_netfilter_init())
		return 1;
#endif
  #+END_EXAMPLE
- 接下来调用brioctl_set()把br_ioctl_hook这个类型为函数的全局变量设为
  br_ioctl_deviceless_stub
- 设置类型为函数的全局变量的br_handle_frame_hook为br_handle_frame,br_handle_frame_hook是用
  来处理输入BPDU的,其实只有这里设置br_handle_frame_hook.
- 设置br_fdb_get_hook函数为br_fdb_get,

  设置br_fdb_put_hook函数为br_fdb_put
- 注册网桥的通知链的回调函数.
- 这个函数只是设置一些函数,并没有添加网桥,用br_add_bridge ()来添加.
** not function
*** Initialization of Bridging Code
- [[./Figure 16-6. Relationships between the main data structure types.png]]
** int br_add_bridge(const char *name)
*** net/bridge/br_if.c:
- 这个函数用来建立一个新网桥
- 先调用new_bridge_dev()新建和初始化一个网桥的结构体,就是strict net_bridge.下面有讲这个函
  数.
- 调用dev_alloc_name()来分配一个设备的名字

  uln:When the name of the device passed to alloc_netdev is in the form
  name%d(e.g.,“eth%d”), the kernel completes the name using the function
  dev_alloc_name. The latter changes %d to the first unassigned number for that device
  type.
- 调用register_netdevice()来注册设备.

** static struct net_device *new_bridge_dev(const char *name)
*** net/bridge/br_if.c:
- 这个函数调用alloc_netdev()分配struct net_device,而net_device->priv作为私有数据会被初始化
  为struct net_bridge这个结构体所占的大小.

  br_dev_setup()函数初始化了新分配的net_device里的很多成员
  #+BEGIN_EXAMPLE
	ether_setup(dev);

	dev->do_ioctl = br_dev_ioctl;
	dev->get_stats = br_dev_get_stats;
	dev->hard_start_xmit = br_dev_xmit;
	dev->open = br_dev_open;
	dev->set_multicast_list = br_dev_set_multicast_list;
	dev->change_mtu = br_change_mtu;
	dev->destructor = free_netdev;
	SET_MODULE_OWNER(dev);
	dev->stop = br_dev_stop;
	dev->tx_queue_len = 0;
	dev->set_mac_address = NULL;
	dev->priv_flags = IFF_EBRIDGE;
  #+END_EXAMPLE

  里面调用的ether_setup()有一些是重复设置的,如change_mtu,但change_mtu最终为br_change_mtu
  #+BEGIN_EXAMPLE
void ether_setup(struct net_device *dev)
{
	dev->change_mtu		= eth_change_mtu;
	dev->hard_header	= eth_header;
	dev->rebuild_header 	= eth_rebuild_header;
	dev->set_mac_address 	= eth_mac_addr;
	dev->hard_header_cache	= eth_header_cache;
	dev->header_cache_update= eth_header_cache_update;
	dev->hard_header_parse	= eth_header_parse;

	dev->type		= ARPHRD_ETHER;
	dev->hard_header_len 	= ETH_HLEN;
	dev->mtu		= 1500; /* eth_mtu */
	dev->addr_len		= ETH_ALEN;
	dev->tx_queue_len	= 1000;	/* Ethernet wants good queues */	
	dev->flags		= IFF_BROADCAST|IFF_MULTICAST;
	
	memset(dev->broadcast,0xFF, ETH_ALEN);

}
  #+END_EXAMPLE 
- net_bridge->dev指向包含该net_bridge的net_device.
- 在br_dev_setup()里初始化完了net_device,而net_bridge就在接下来的代码初始化了.
** struct net_device *alloc_netdev(int sizeof_priv, const char *name, void (*setup)(struct net_device *))
*** net/core/dev.c:
- 以下的代码是用来计算net_device.padded的大小的.

  net_device.padded指的就是为了对齐而在所分配的内存开头空出一段内存.
  #+BEGIN_EXAMPLE
	dev = (struct net_device *)
		(((long)p + NETDEV_ALIGN_CONST) & ~NETDEV_ALIGN_CONST);
	dev->padded = (char *)dev - (char *)p;
  #+END_EXAMPLE
- 而net_device是从net_device->padded开始的,所以释放时要注意向后加上这一段.
- 调用这个函数分配一个net_device时都要传入一个setup函数来设置新分配的struct net_device.所
  以不同的类型的设备所设置的net_device是不一样的.如网桥和路由器的设置就不一样.
- 从调用的netdev_priv()可以看出,net_device的私有空间是在struct net_device之后的
  #+BEGIN_EXAMPLE
	if (sizeof_priv)
		dev->priv = netdev_priv(dev);

static inline void *netdev_priv(struct net_device *dev)
{
	return (char *)dev + ((sizeof(struct net_device)
                               + NETDEV_ALIGN_CONST)
                              & ~NETDEV_ALIGN_CONST);
}
  #+END_EXAMPLE 
** not function
*** 
- uln:

  They are two different concepts:

  • Registration and unregistration, if we exclude the act of loading a device driver
  module, are user independent; the kernel drives them. A device that has been only
  registered is not operative yet. We will see when a device is registered and
  unregistered in the sections “When a Device Is Registered” and “When a Device Is
  Unregistered.”

  • Enabling and disabling a device require user intervention. Once a device has been
  registered by the kernel, the user can see it by means of user commands, configure it,
  and enable it. See the later section “Enabling and Disabling a Net- work Device.”
** int br_add_if(struct net_bridge *br, struct net_device *dev)
*** net/bridge/br_if.c:
- 这个函数用来添加一个端口到网桥
- 第二个参数dev就是要被添加的端口
- 若是回环接口就不能加

  若设备类型是ARPHDR_ETHER,就不能加

  #+BEGIN_EXAMPLE
	if (dev->flags & IFF_LOOPBACK || dev->type != ARPHRD_ETHER)
		return -EINVAL;
  #+END_EXAMPLE
