#+STARTUP: showall
* question/answer:
- 因为中断的处理函数在内核态运行，又因为中断可以嵌套的，如果一连续有行验中断产生，那么会不
  会把内核栈给爆了？应该不会,因为产生某个中断之后系统会禁止相应的中断.
- 内核线程用谁的栈呢？应该是当前进程的,再次回到用户态的时候线程已经执行完了,所以内核栈不用
  因为再次回到用户态的时候把内核栈保存下来.但像ksoftirqd()这样的内核线程会调用schedule(),在
  内核空间用schdule()会切换进程,那原来的硬件上下文保存在那里了呢?什么时候会再用呢?
- 进程0最后执行cpu_idle()
- linux2.6有exit_group()和_exit()系统调用来终止一个用户程序。前者用do_group_exit()实现，C库
  的exit()调用，后者用do_exit()实现，如C库的pthread_exit()调用。
- TGID，PGID，SID这几个hash表的主要目的是让你容易通过一个领头进程找到它的线程组中的其它线程，
  进程组中的其它进程，对话中的其它进程。
- 一个中断号一个irq_desc_t结构体。
- irq_desc_t里的depth表示这个中断被禁止了多少次，但是Linux经常是禁止所有中断，为了效率不能
  在这种情况一个一个中断来禁止。
- arm的用arch/arm/kernel/irq.c的，里面有disable_irq()之类的，i386用kernel/irq/manage.c也有
  disable_irq()之类的，但是disable_irq()的实现是一样的。request_irq()也有类似的情况.
- 中断丢失是发生要多处理器中的。CPU A在应答一个中断线前被CPU B禁止了相同的中断，但是CPU A在
  应答之后执行do_irq()，但在do_irq()里会检查IRQ_DISABLE,所以do_irq()不会往下执行了。
- SA_INTERRUPT 这个标志指的是在禁止本地上所有的中断，而不是自已本身。
- IRQ_PER_CPU:该IRQ只能发生在一个cpu上
  IRQ_LEVEL:该中断由电平触发
  IRQ_MASKED:屏蔽了其他中断
- irq_desc->handler和irqaction->handler老是混淆.
- set_current_state这个函数不就只是改变进程的状态吗?并没有对运行队列做出相应的操作.这有什么
  用呢?好像在schedule()里会检测这个标志.
- ULK有句这样的话被我误解了:Right after switching from User Mode to Kernel Mode, the
  kernel stack of a process is always empty, and therefore the esp register points to the
  byte immediately following the stack.我以为从内核态切回用户态后就会把内核栈给清掉了,原来
  不是,只是说把esp给改变了,当这个进程再切回到内核态时就会用回原来在内核态的数据,如调用read
  函数时可能会休眠以致切换到其它进程.
- ret_from_intr()和ret_from_exception()时若有可能会进行调度。
- ULK:a preemptive kernel differs from a nonpreemptive kernel on the way a process running
  in Kernel Mode reacts to asynchronous events that could induce a process switchfor
  instance, an interrupt handler that awakes a higher priority process. We will call this
  kind of process switch a forced process switch。linux不能在中断里进行进程切换。那么不在定
  时器中断里进行切换那么它是怎么做到分时的呢？
- ULK：Both in preemptive and nonpreemptive kernels, a process running in Kernel Mode can
  voluntarily relinquish the CPU, for instance because it has to sleep waiting for some
  resource. We will call this kind of process switch a planned process switch.非抢占不是说
  不能在内核态进行进程切换。
- schedule()可能因为preempt_count设了PREEMPT_ACTIVE而会不调度，是不是说明调用schedule()有可
  能不会切换进程的可能呢？
- 对于多核处理机，使用PREEMPT_ACTIVE实现禁止抢占是没有什么作用的，不能防止其它CPU防问临界区，
  仅仅是不能进行进程切换而已，要用自旋锁之类的.不是这样的，还是有用的，不禁止抢占会
- ULK：kernel preemption may happen either when a kernel control path (usually, an
  interrupt handler) is terminated, or when an exception handler reenables kernel
  preemption by means of preempt_enable( )，kernel preemption may also happen when
  deferrable functions are enabled.所以有三个地方是内核固定会调度的。
- 感觉PREEMPT_ACTIVE实现的抢占在单核上就像一个LBK，在多核中又没什么作用。
- ULK:spin locks are usually convenient, because many kernel resources are locked for a
  fraction of a millisecond only;therefore, it would be far more time-consuming to release
  the CPU and reacquire it later.
- ULK:In the case of a uniprocessor system, the locks themselves are useless, and the spin
  lock primitives just disable or enable the kernel preemption.
- 可以确定设置PREEMPT_ACTIVE是不能/会抢占的意思。
** struct pid * fastcall find_pid(enum pid_type type, int nr)
- 没办法，还是要用遍历
** int fastcall attach_pid(task_t *task, enum pid_type type, int nr)
- 注意所有的成员都要设置好。
** static fastcall int __detach_pid(task_t *task, enum pid_type type)
- 返回值被detach_pid使用得有点巧妙。
** void fastcall detach_pid(task_t *task, enum pid_type type)
- 比__detach_pid ()多一个功能就是把从pid位图里把nr删掉。
** task_t *find_task_by_pid_type(int type, int nr)
** void switch_exec_pids(task_t *leader, task_t *thread)
- 一个非领头线程调用sys_execve()时就调用它。
** void __init pidhash_init(void)
** void __init pidmap_init(void)
- 主要是做0号进程的工作。只分配一页。
** int alloc_pidmap(void)
- 在这里也分配页给page
- alloc_pidmap里的求max_scan的方法为什么要减!offset呢?因为若不在一页的起始位置就要减去0而不是1是因为想多循环一次当前页，所以max_scan指的是
  将要经过多少次页头（页尾）.
** int default_wake_function(wait_queue_t *curr, unsigned mode, int sync, void *key)
- 仅仅是调用try_to_wake_up
- key参数没有用
- 所以自定义唤醒函数时,里面可以一开始调用default_wake_function,在最后做一些想做的事情,而不
  能在一开始做想做的事情因为进程还没有切换.不是这样的,无论在default_wake_function之前还是之
  后所做的事都是在被切换的进程的上下文中进行的.
** int autoremove_wake_function(wait_queue_t *wait, unsigned mode, int sync, void *key)
- 调用上一个函数后从链表中删除,删除用list_del_init,与__remove_wait_queue所用的list_del不一
  样,为什么是在调用上一个函数之前而不是之后呢?被try_to_wake_up()之后没有从等待队列里删除会
  不会又再次唤醒呢?
** #define DEFINE_WAIT(name)
- 用了上一个函数作为唤醒函数。
- 若用这个定义一个WAIT,因为用上一个函数作为唤醒调用函数,所以同时会把它从队列删除.唤醒之后不
  用再把它从队列删除.
** static inline void init_waitqueue_func_entry(wait_queue_t *q, wait_queue_func_t func) 
*** include/linux/wait.h:
- 可以自定义唤醒函数。仅此而已,没有赋值给task
** static inline void init_waitqueue_entry(wait_queue_t *q, struct task_struct *p)
*** include/linux/wait.h:
- 与上一个比多了初始化进程。但唤醒函数用default_wake_function, flags都是0
** #define DECLARE_WAITQUEUE(name, tsk)
*** include/linux/wait.h:
- 注意与DEFINE_WAIT的不同，用tsk,default_wake_function,NULL和NULL初始task_list,而不是
  current,autoremove_wake_function,LIST_HEAD_INIT
- 那么用DECLARE_WAITQUEUE定义的要不要在删除的时候把它从链表删除呢？要的,用
  remove_wait_queue，在ulk里也有说的:unless DEFINE_WAIT or finish_wait( ) are used, the
  kernel must remove the wait queue element from the list after the waiting process has
  been awakened.
** #define DECLARE_WAIT_QUEUE_HEAD(name)
*** include/linux/wait.h:
- 用自已来初始化链表.
** static inline void init_waitqueue_head(wait_queue_head_t *q)
*** include/linux/wait.h:
- 结果和DECLARE_WAIT_QUEUE_HEAD(name)一样.
** static inline int waitqueue_active(wait_queue_head_t *q)
*** include/linux/wait.h:
- 看队列是否为空
** static inline void __add_wait_queue(wait_queue_head_t *head, wait_queue_t *new)
*** include/linux/wait.h:
- 这个是加在队列前面的
** static inline void __add_wait_queue_tail(wait_queue_head_t *head, wait_queue_t *new)
*** include/linux/wait.h:
- 这个是加在队列尾的
** void fastcall __sched sleep_on(wait_queue_head_t *q)
*** kernel/sched.c:
- 就是改状态,加入队列,schedule,删除队列. 要注意加锁.
- sleep_on系列的函数是与等待队列相关的.
- 时间窗口出现在改状态和schedule之间可能会被唤醒.
- the sleep_on( )-like functions cannot be used in the common situation where one has to
  test a condition and atomically put the process to sleep when the condition is not
  verified; therefore, because they are a well-known source of race conditions, their use
  is discouraged.
** long fastcall __sched sleep_on_timeout(wait_queue_head_t *q, long timeout)
** long fastcall __sched interruptible_sleep_on_timeout(wait_queue_head_t *q, long timeout)
** void fastcall __sched interruptible_sleep_on(wait_queue_head_t *q)
** void fastcall prepare_to_wait(wait_queue_head_t *q, wait_queue_t *wait, int state)
*** include/linux/wait.h:
- 这个用于把current加入等待队列的。
- 注释有说为什么把设置进程状态放在加入队列的后面
- 要先判断wait->task_list为空的时候才把wait加入队列。为什么在sleep_on里不用呢?因为
  prepare_to_wait的应用场合不同，prepare_to_wait会放在一个循环里重复调用，但是finish_wait不会被放到循环里，看看__wait_event就知道了。
- 虽然在is_sync_wait里会检查wait是否为空，但进入prepare_to_wait是肯定不会为空的，所以is_sync_wait做了多余的事情。
** #define is_sync_wait(wait)	(!(wait) || ((wait)->task))
*** include/linux/wait.h:
- 有一段注释：Used to distinguish between sync and async io wait context: sync i/o typically specifies a NULL wait queue entry or a wait
  queue entry bound to a task (current task) to wake up. aio specifies a wait queue entry with an async notification
  callback routine, not associated with any task.为什么同步io可以指定一个NULL 的wait呢？
** void fastcall prepare_to_wait_exclusive(wait_queue_head_t *q, wait_queue_t *wait, int state)
*** include/linux/wait.h:
- 不同的是设置了exclusive标志。
** void fastcall finish_wait(wait_queue_head_t *q, wait_queue_t *wait)
*** kernel/wait.c:
- 用了list_empty_careful，为什么呢？只能用于调用list_del_init的情况，因为list_del_init里调用了INIT_LIST_HEAD
- sleep_on是状态->插入队列->schedule->删除队列;插入队列(prepare)（检测是否已插入）->状态
  (prepare)（检查同步）->schedule->状态(finish)->删除队列(finish)(先list_empty_careful)
- 有一个例子：
#+BEGIN_EXAMPLE
    DEFINE_WAIT(wait);
    prepare_to_wait_exclusive(&wq, &wait, TASK_INTERRUPTIBLE);
                                /* wq is the head of the wait queue */
    ...
    if (!condition)
        schedule();
    finish_wait(&wq, &wait);
#+END_EXAMPLE
** #define wake_up(x)			__wake_up(x, TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE, 1, NULL)
*** kernel/sched.c:
- 要知道linux是不能指定下一个切换到某个进程。
- wake_up也不能指定唤醒某个进程（把某个进程状态改成运行），注意只有一个参数x，但是找到一个
  被唤醒的进程后就会马上调用它的func，因为大部分的func是default_wake_function，会调用
  try_to_wake_up
- 等待队列是从第一个开始唤醒的，一个wait可以加入到队列头add_wait_queue也可以加到队列尾
  add_wait_queue_tail，同时还有互斥和非互斥的wait，所以可以用这些东西组合成一个有优先级的队
  列。

** #define wake_up_nr(x, nr)		__wake_up(x, TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE, nr, NULL)
** #define wake_up_all(x)			__wake_up(x, TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE, 0, NULL)
** #define wake_up_interruptible(x)	__wake_up(x, TASK_INTERRUPTIBLE, 1, NULL)
** #define wake_up_interruptible_nr(x, nr)	__wake_up(x, TASK_INTERRUPTIBLE, nr, NULL)
** #define wake_up_interruptible_all(x)	__wake_up(x, TASK_INTERRUPTIBLE, 0, NULL)
** #define wake_up_locked(x)		__wake_up_locked((x), TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE)
- 已经把队列给lock住了
** #define wake_up_interruptible_sync(x)   __wake_up_sync((x),TASK_INTERRUPTIBLE, 1)
** void fastcall __wake_up_sync(wait_queue_head_t *q, unsigned int mode, int nr_exclusive)
*** kernel/sched.c:
- 这个函数目前为止只是用于上一个宏，所以nr_exclusive一直是1，但是在实现的时候nr_exclusive为0的时候就不同步了，为什么呢？
** static void __wake_up_common(wait_queue_head_t *q, unsigned int mode, int nr_exclusive, int sync, void *key)
- sync这个参数是只是传给func而已。
- 如果想唤醒所有的进程而不管它是否互斥，那么nr_exclusive就是0，实现的方法是!--nr_exclusive
** clone
- 这个是C的库函数，它有多个参数但是它调用的sys_clone只有一个参数，转而调用的do_fork有多个参
  数。但是ARM又是不一样的，它的包含了很多参数。
- 关于fn和arg参数在ULK有：the wrapper function saves the pointer fn into the child's stack
  position corresponding to the return address of the wrapper function itself; the pointer
  arg is saved on the child's stack right below fn.
** fork
- 也是一个C库函数。
- ULK:The traditional fork( ) system call is implemented by Linux as a clone( ) system
  call whose flags parameter specifies both a SIGCHLD signal and all the clone flags
  cleared, and whose child_stack parameter is the current parent stack pointer. Therefore,
  the parent and child temporarily share the same User Mode stack.总之比clone就多了一个
  SIGCHLD和与父进程共用一个堆栈.
** vfork
- 也是一个C库函数。
- ULK:The vfork( ) system call, introduced in the previous section, is implemented by
  Linux as a clone( ) system call whose flags parameter specifies both a SIGCHLD signal
  and the flags CLONE_VM and CLONE_VFORK, and whose child_stack parameter is equal to the
  current parent stack pointer.总之比fork就多了CLONE_VM和CLONE_VFORK
** long do_fork(unsigned long clone_flags, unsigned long stack_start, struct pt_regs *regs, unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr)
*** kernel/fork.c:
- 注意参数的意思
- 如果clone_flags和current->ptrace的符合某些条件时，就算clone_flags不设置CLONE_PTRACE也给它加上。主要是看current_ptrace的设置。
- 关于调用ptrace_notify在ULK有这样说：If the parent process is being traced, it stores the
  PID of the child in the ptrace_message field of current and invokes ptrace_notify( ),
  which essentially stops the current process and sends a SIGCHLD signal to its
  parent. The "grandparent" of the child is the debugger that is tracing the parent; the
  SIGCHLD signal notifies the debugger that current has forked a child, whose PID can be
  retrieved by looking into the current->ptrace_message field.
- 在调用ptrace_notify时的参数在里面被赋给了task_struct->exit_code，为什么要这样呢？也赋给了
  si_code,这还可以理解
- 调的ptrace_notify的原因：因为父进程被跟踪而且要求被创建的子进程也要被跟踪，所以就调用了。
  调用完这个函数的过程中因调用schedule(do_notify_parent_cldstop())所以会停下。
- 这个函数是在哪里真正创建一个进程并开始以两个执行路径运行的呢？好像整个进程都是以current来
  运行的。那创建的子进程在什么时候运行呢？可能是在copy_process函数里把它插入到了某个运行队列里了。
- 若CLONE_VFORK设置了要在ptrace_notify之后才可以等待，子进程运行完。
** static inline int fork_traceflag (unsigned clone_flags)
*** kernel/fork.c:
- 在clone_flags里的最低8位是指定退出时所要发送的信号。
- 若系统调用是由vfork发起的且想跟踪vfork发起的创建的子进程就返回PTRACE_EVENT_VFORK;若子进程
  退出时所发的信号不是SIGCHLD(为什么要这个条件呢？)且想跟踪clone创建的子进程就返回PTRACE_EVENT_CLONE；若想跟踪由
  fork创建的子进程就返回PTRACE_EVENT_FORK.
- 为什么是CLONE_VFORK是要使用completion原语呢？因为vfork的man手册有一段这样的话：vfork()
       is a special case of clone(2).  It is used to create new processes without copying
       the page tables of the parent process.  It may be useful in performance-sensitive
       applica‐ tions where a child is created which then immediately issues an
       execve(2)vfork() differs from fork(2) in that the parent is suspended until the
       child terminates (either normally, by calling _exit(2), or abnormally, after
       delivery of a fatal signal), or it makes a call to execve(2).  Until that point,
       the child shares all memory with its parent, including the stack.  The child must
       not return from the current function or call exit(3), but may call _exit(2).
       Signal handlers are inherited, but not shared.  Signals to the parent arrive after
       the child releases the parent's memory (i.e., after the child terminates or calls
       execve(2)).
- CLONE_STOPPED:Forces the child to start in the TASK_STOPPED state.
- 若设置了CLONE_STOPPED,为什么还要设置PT_PTRACE才可以添加SIGSTOP的信号呢?
** void fastcall wake_up_new_task(task_t * p, unsigned long clone_flags)
*** kernel/sched.c:
- 再次说一下task_t->array是指向CPU运行队列里的某一个active或expire成员.
- 如何通过一个task_t来获得一个运行队列:从task_t里的thread_inof里的CPU来找到task是在哪一个
  CPU上,知道哪个CPU就可以找出相应的运行队列了.task_t里的run_list就是task_t->array链表里的一
  个结点.
- 会根据是否共用相同的VM和是否在同一个CPU来插入进程和父进程的相对位置。
- __activate_task会使用enqueue_task来把进程插入到相应的运行队列尾，而不是头。
- 在这个函数里current->array会有空的时候,是什么时候呢？
- 为什么不共享VM就要子进程运行先呢？注释有说明是因为可能运行exec，那么是不是子进程运行
  exec后会把所有的原来的VM删掉呢？
- 好像在cpu==this且CLONE_VM清除且current->array不为空时的情况下没有设置array->bitmap,这个是
  一个bug吗？在这里为什么要把子进程的prio设置成父进程的prio呢？难道仅是为了想在父进程之前运
  行而把它放在程父进程相同优先级的运行队列中？
- 它的this_rq为什么不是通过task_rq_lock来获取的呢？而是根据cpu==this_cpu来判断的呢？
- 为什么在不是同一个CPU时要重新计算timestamp呢？计算的方法是减去父进程所在运行队列的
  timestamp_last_tick再加上子进程所在运行队列的timestamp_last_tick
- __activate_task这个函数里会把进程加入到运行队列里的，虽然名子看起来不是这样子的，但结合参
  数一起还是可以看来的。
- 把一个进程加入到另外一个CPU之后还要看那个CPU需不需要重新调度。实现很简单，用被加入的进程
  的优先级（动态优先级）与CPU上的运行队列里的curr->prio比较即可。
- 为什么不实现CONFIG_SMP版和非CONFIG_SMP版的呢？像resched_task那样。
- set_need_resched()和resched_task()不一样的，前者只是设置了current的标志，而后者会让其它
  CPU的进程重新调度。
- 为什么要把current的运行队列锁住呢？
- 这个函数只有do_fork调用而已
** void ptrace_notify(int exit_code)
*** kernel/signal.c:
- ULK有解释：ptrace_notify( ), which essentially stops the current process and sends a
  SIGCHLD signal to its parent.
- si_signo的是SIGTRAP，且调的的ptrace_stop函数里的do_notify_parent_cldstop是用相应的
  CLD_TRAPPED
- 在这个函数里建立的siginfo_t是在ptrace_stop函数被放到last_siginfo里，在
  do_notify_parent_cldstop里建立的siginfo_t是发给跟踪进程的.
- 调的这个函数因ptrace_stop的schedule，所以可能会被调度.是在do_notify_parent_cldstop里唤醒
  父进程,在ptrace_stop调度。
- current重新可以运行后是马上看有没有挂起的进程。为什么这之前要把last_sigpending清掉呢？
** static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
*** kernel/signal.c:
- 这个函数的作用应该是在current被跟踪时用来停止current的,并通知跟踪进程
- 不知道为什么要自减group_stop_count
- task_t->last_siginfo是给跟踪用的,保存的东西有什么用呢?
- 为什么要设置current->exit_code呢?
- 把current的状态改成TASK_TRACED之后没有把它从运行队列中删除吗？
- 函数里是先解siglock的锁再加上siglock的锁
- 为什么那个PT_ATTACHED要非呢?好像不对的吧
- current->parent->signal不等于current->signal是不是说明current与current->parent不在同一个
  线程组呢?
- 为什么要各种条件不成立的时候再次设置进程为TASK_RUNNING状态呢？有注释说是跟踪进程已不在了。
** static void do_notify_parent_cldstop(struct task_struct *tsk, struct task_struct *parent, int why)
*** kernel/signal.c:
- 重新认识一下struct siginfo_t,结构体里的联合体用得有技巧，因为_kill->_pid和_sigchld->_pid
  的地址相同，_kill->_uid和_sigchld->_uid地址相同，所以只需提供访问_kill或_sigchld里其
  中_pid和_uid即可，所以只提供了访问了_kill->_uid和_kill->_pid的宏而没有_sigchld.si_errno是
  The error code of the instruction that caused the signal to be raised, or 0 if there was
  no error。si_code是A code identifying who raised the signal 。si_status是exit code.不知道
  si_utime和si_stime有什么用，保存什么的，但是它们分别被赋tsk->utime和tsk->stime,原来ULK里
  列出的si_code只是一部分，还有一些SIGILL类、SIGFPE类、SIGSEGV类、SIGBUF类的、SIGTRAP类的、
  SIGCHLD类的等。每次发信号时都要填这个结构体，在这个函数里因为要给发一个信号所以要填这个结
  构体,又因为发的是SIGCHLD信号，所以要填结构体中的联合体的SIGCHLD结构体。
- CLD_TRAPPED这个表示被跟踪进程被捕获，可能运行到了breakpoint,所以运行要停下来，这时候应该
  给跟踪进程发一个信号，所以在这个函数里要检查CLD_TRAPPED是否被置。但是为什么也要检查
  CLD_CONTINUED.
- 为什么是CLD_STOPPED时要这样设置si_status呢？是CLD_TRAPPED时要这样设置si_status呢?
- 既然要在两个判断之后才使用info为什么花那么多时间先设置info呢？
- 因为一个子进程只有一个父进程，所以__wake_up_parent函里使用的wait_chldexit等待队列最多只有
  一个进程，这样解释对吗？
- wait_chldexit是给wait4()系统调用用的，但是子进程只给父进程发一个SIGCHLD信号而已，父进程是
  怎么是子进程退出了呢？
- 这个函数的主要功能是什么呢？是给父进程发一个SIGCHLD信号，而且还必须与CLD_CONTINUED、
  CLD_STOPPED、CLD_TRAPPED相关的。
** static task_t *copy_process(unsigned long clone_flags, unsigned long stack_start, struct pt_regs *regs, long stack_size, int __user *parent_tidptr,int __user *child_tidptr, int pid)
*** kernel/fork.c:
- p->user这个成员是一个指针，就是说还是和父进程共用的。这是对的，因为创建子进程时的用户是与
  父进程的用户相同的
- nr_threads在这个函数里增加，在__unhash_process减，__unhash_process被release_task和
  unhash_process调用
- max_threads表示什么意思呢？它在fork_init里被初始化
- 我觉得nr_threads>=max_threads不应该放在nr_threads++之前，如果root调用fork足够多次且每次都
  在nr_threads>=max_threads这个比较之后且在nr_threads++之前那么nr_threads就会大于
  max_threads
- 在这里把tgid设置了pid,就是说创建一个进程时把子进程作一个新线程组的领头进程,是这样子吗?为
  什么呢?但是设置了CLONE_THREAD又不同了.
- 为什么要设置set_child_tid和clear_child_tid呢？clear_child_tid是什么来的，有一句主释：
  Clear TID on mm_release()?
- 创建的子进程是不能跟踪它运行后的系统调用的.
- 把父进程的执行域设置成了自已的执行域,为什么呢?
- 为什么要这样设置exit_signal呢?若没设置CLONE_THREAD,那么用clone_flags里的
- 要设置group_leader为子进程,好像不对的吧.是不对,在后面会因为CLONE_THREAD而做修改的
- 把cpus_allowed设置成与current的一样,设置子进程的cpu与current的一样.
- 若current有一个SIGKILL信号,那么它就不能创建子进程.
- 若设置了CLONE_PARENT或CLONE_THREAD的时候要把子进程的real_parent设置了current的
  reald_parent,为什么有CLONE_THREAD的要这样设置,正真创建子进程的current竟然不是current,
- 刚创建完的子进程的parent与real_parent是一样的.
- 若CLONE_THREAD设置了同是SIGNAL_GROUP_EXIT也设置了,那么是不能创建子进程的.
- 若CLONE_THREAD设置了那么把子进程的group_leader设置成current的group_leader
- SIGNAL_GROUP_EXIT和group_stop_count没有关联的吗?可以不设置SIGNAL_GROUP_EXIT但
  group_stop_count可以大于0?
- 若group_stop_count大于0说明一个全组的停止正在进行,那么就要把正创建的进程加入到停止组中.
- 有一个跟踪进程的被跟踪进程链表(task_struct->ptrace_list, task_struct->ptrace_childen)
- 子进程一定会被插入到PID hash表和TGID hash（tgid在上面被设置成正确的值了）表，但是为什么要
  在子进程为线程组领头进程时才会把子进程插入PGID hash表和SID hash表呢？
- 在这里居然还会检查p->pid是否为0，是否多此一举？
- 每个CPU都有一个进程个数计数器process_counts
- ULK有一句这样的话：If the child is a thread group leader (flag CLONE_THREAD cleared)。就
  是说CLONE_THREAD若不设置那么子进程就是线程组领头进程，若进程是一个线程而不是一个线程组领
  头进程那么它就不是一个进程组的成员，若进程是一个线程组领头进程那么它就是一个进程组的成员，
  那么一个进程怎样才可以成为进程组领头进程呢？
- 关于进程归属的问题总结ULK:若子进程是一个thread group leader(清CLONE_THREAD),就设tgid为
  pid(就是自已),设group_leader为自已(这个有点想不明白,源码的确的这样的.)那么除了把子进程插
  入到TGID,PGID之外还要插入到SID中.若子进程不是一个thread group leader(置CLONE_THREAD),那么
  tgid设为current->tgid(注意不是current,所以线程组不能嵌套),设group_leader为
  current->group_leader并把它插入到TGID中去,但是为什么子进程不是thread group leader了还要插
  入到TGID中呢？哦看错了，源码是这样的attach_pid(p, PIDTYPE_TGID, p->tgid);不是插p而是
  p->tgid那么每创建一个线程时领头线程不是都要被插一次，这点在ULK上表述有错。不是，我错了，
  的确的把子进程插入TGID中。要重新认识一下那4个链表。
** static struct task_struct *dup_task_struct(struct task_struct *orig)
*** kernel/fork.c:
- prepare_to_copy()在i386里用来关闭fpu，在arm里什么也不做。
- 就是分配了task_struct和thread_info并拷贝和设置之间的指针；再设置tsk->usage.
** static inline void copy_flags(unsigned long clone_flags, struct task_struct *p)
*** kernel/fork.c:
- 这个函数是被copy_process调用的，为什么要把PF_SUPERPRIV清掉呢？不能继承父进程的
  PF_SUPERPRIV吗？为什么把PF_FORKNOEXEC给置了？
- 由copy_process传入的clone_flags在do_fork可能对CLONE_PTRACE动了手脚.task_struct->ptrace是
  在这里设置的,在do_fork里用到,为什么不在do_fork做修改呢?隔太远了.
** static int copy_files(unsigned long clone_flags, struct task_struct * tsk)
*** kernel/fork.c:
- 一个后台程序可能不包含任何文件.
- 若设置了CLONE_FILES那么就用current的files,不用改.
- 
** static int count_open_files(struct files_struct *files, int size)
*** kernel/fork.c:
- 这种的计算方法是不是有的粗略了?
** static inline int copy_fs(unsigned long clone_flags, struct task_struct * tsk)
*** kernel/fork.c:
- CLONE_FS:ulk:Shares the table that identifies the root directory and the current working
  directory, as well as the value of the bitmask used to mask the initial file permissions
  of a new file (the so-called file umask ).
** static inline struct fs_struct *__copy_fs_struct(struct fs_struct *old)
*** kernel/fork.c:
- 主要的步骤的分配一个fs_struct再把old里的值拷贝过去
** static inline int copy_sighand(unsigned long clone_flags, struct task_struct * tsk)
*** kernel/fork.c:
- 若是CLONE_sighand或CLONE_THREAD其中一个设置就与父进程共享，即增加计数器就可以了。
- 若不共享，但还要把action的内容拷贝过来，为什么呢？所以无论共享与否都会把共享action
** static inline int copy_signal(unsigned long clone_flags, struct task_struct * tsk)
*** kernel/fork.c:
- 若CLONE_THREAD设置那么就共享进程的，增加计数器即可。
** static int copy_mm(unsigned long clone_flags, struct task_struct * tsk)
*** kernel/fork.c:
- 若current->mm为空的时候就不用拷贝也不分配了，为什么不分配了呢？
- 若设置了CLONE_VM就共享.若不共享,还会把父进程的mm给拷贝过来.再后来又修改了部分成员
** int copy_thread(int nr, unsigned long clone_flags, unsigned long esp, unsigned long unused, struct task_struct * p, struct pt_regs * regs)
*** arch/i386/kernel/process.c:
- 这个函数初始化了task_struct->thread_info结构体,其中有reg成员、栈、ip寄存器，使子进程被调
  度运行时在正确的栈和ip指针下运行。
- ULK:The value returned by the system call is contained in eax: the value is 0 for the
  child and equal to the PID for the child's parent. To understand how this is done, look
  back at what copy_thread() does on the eax register of the child's process.
** void fastcall sched_fork(task_t *p)
*** kernel/sched.c:
- 函数一开始把进程状态设置为运行,但到目前为止还没有把进程插入到运行队列,所以还不会被调度.但
  可以不可以通过把它插入到一个等待队列来获得运行呢?
- 给子进程分时间片时为什么current的时间片要先加1呢?current->time_slice不可能是0;若是1的话,
  如果不加1,那么子进程的时间就是0,又因为current的时间片又会用移位的方式重新调整,所以若是1,
  最后父和子进程的时间片都是0.用这种计算方式无论如何都不会增加和减少原来current的时间片.
- 调整之后的current时间片若为0那么会马上开始定时器的调度.
** NORET_TYPE void do_group_exit(int exit_code)
*** kernel/exit.c:
- SIGNAL_GROUP_EXIT是该线程组中所有的线程都要设置的吗？还是只是调用这个函数的线程才会设置。
  不是这样的，task_struct->signal是线程共享的。
- 这代码实现了退出代码的传递性，就是第一个调用该函数的线程所使用的exit_code参数才会被一值采
  用。
** void zap_other_threads(struct task_struct *p)
*** kernel/signal.c:
- SIGNAL_GROUP_EXIT不是在do_group_exit里设置了吗？为什么又要在这里设置SIGNAL_GROUP_EXIT呢？
  多此一举吗？
- 要把group_stop_count清零。所以group_stop_count是从0开始计数的。
- thread_group_exit不是在do_goup_exit里查过了吗？这里是不是多此一举呢？
- 在copy_process里可以看出线程的group_leader与领头线程的一样。但这里为什么有不相等的情况呢？
  一个线程可以不与领头线程在相同的进程组吗？可以从注释上看出若线程执行execve或类似的东西的
  时候不在同一进程组
- 不在同一进程组时要设exit_signal为-1呢？就算不在同一线程组也要发SIGKILL信号给它。
- 会把被杀线程的SIGSTOP,SIGSTP,SIGTTIN,SIGTTOU的信号删掉。
** void signal_wake_up(struct task_struct *t, int resume)
*** kernel/signal.c:
- ULK:to notify the process about the new pending signal
- 若想恢复执行，那么就不管进程的状态是TASK_INTERRUPTIBLE，TASK_STOPPED还是TASK_TRACED.
- 会调的wake_up_state,转而调用try_to_wake_up来唤配进程。若在其它CPU会发一个CPU间中断让它调
  度。
** fastcall NORET_TYPE void do_exit(long code)
*** kernel/exit.c:
- 在能在中断上下文调的，不能对进程0进程1调用
- 按照字面意思，PT_TRACE_EXIT应该是指跟踪进程退出，就是在退出时通知跟踪进程。
** static void exit_notify(struct task_struct *tsk)
*** kernel/exit.c:
- 有一个调用exit同时该进程被选中来执行一个线程组信号。这时它要找其它线程来处理。
- 有注释：Check to see if any process groups have become orphaned as a result of our
  exiting, and if they have any stopped jobs, send them a SIGHUP and then a SIGCONT.
  (POSIX 3.2.2.2)
- 如果被杀进程的exit_signal不等于SIGCHLD且exit_signal不为空，安全域或执行域被修改且没有
  KILL权限那么改exit_signla为SIGCHLD。为了是让父进程知道子进程已死。
- 进入这个函数之后，退出进程有可能在EXIT_ZOMBIE状态，也有可能在EXIT_DEAD状态，如果进入
  EXIT_DEAD了，那么之后会调用release_task.若没在出退信号且不被跟踪或在进行组退出就是
  EXIT_DEAD,否则是EXIT_ZOMBIE.如果在这里被设置成EXIT_ZOMBIE,那么会在那被设成EXIT_DEAD呢？好
  像是如果在EXIT_ZOMBIE时，就表明等待父进程调用wait类函数。
- 在这里会把forget_original_parent收集到的子进程给release_task掉。
- 在这个函数一定会把tsk->flags设为PF_DEAD，说明无论是EXIT_DEAD还是EXIT_ZOMBIE,那是PF_DEAD.
- 想到一个问题：release_task之后应该是所有的内存空都被收回了，但是为什么被退出的进程还可以
  运行呢？因为内存空间被收回后并没有把内存空间的内容清掉且这些内存没有被分配，因为已把抢占
  给禁止了，所以进程的代码代和数据都没被破坏。好像上面那个解释是错的，因为ULK：The
  release_task( ) function detaches the last data structures from the descriptor of a
  zombie process; it is applied on a zombie process in two possible ways: by the
  do_exit()function if the parent is not interested in receiving signals from the child,
  or by the wait4( ) or waitpid( ) system calls after a signal has been sent to the
  parent. In the latter case, the function also will reclaim the memory used by the
  process descriptor,while in the former case the memory reclaiming will be done by the
  scheduler (see Chapter7).
** static inline void forget_original_parent(struct task_struct * father, struct list_head *to_release)
*** kernel/exit.c:
- ULK：All child processes created by the terminating process become children of another
  process in the same thread group, if any is running, or otherwise of the init process.
- 里面有一个child_reaper是被初始化为init_task的。
- 要处理这个进程的两个进程链表：子进程链表，跟踪进程链表。在task_struct->children里这两种的
  进程那包含了。
- 有注释：If something other than our normal parent is ptracing us, then send it a SIGCHLD
  instead of honoring exit_signal.  exit_signal only has special meaning to our real
  parent.被杀进程要是被跟踪，就发SIGCHLD，否则且exit_signal不为空且所在的线程组没有其它线程
  (thread_group_empty(tsk)是指tsk作为一个线程所在的线程组没有其它线程，不是指以tsk作为线
  程组领头线程的线程组没有其它线程)（为什么要这个条件呢？）
** static inline void reparent_thread(task_t *p, task_t *father, int traced)
*** kernel/exit.c:
- exit_signal等于-1是什么意思,表示没有任何信号，就是初始值，不能用0，这个好像用来测试的。
- 若子进程有退出信号，那么把它改成SIGCHLD,为什么要这样子做呢？
- pdeath_singal是在ULK：The signal sent when the parent dies时候发的。但是发给谁呢？从代码
  看好像是发给自已,从forget_original_parent来看好像发给父进程的.
- 在task_struct里关于跟踪的链表也有两个：ptrace_list和ptrace_children.
- 在这里father是正在退出的进程,在进入这个函数之前real_parent被改了，无论是有没跟踪的。
- 参数traced说明的是父进程有没有被跟踪。
- 如果父进程是被跟踪的且p的parent和real_parent不相同，那么就把p插入到real_parent的
  ptrace_children中,但什么时候父进程是被跟踪的且parent与修改之后的real_parent是相同的呢？好
  像这样是不可能的吧，因为在以参数trace=1调用之前p是在father->ptrace_children链表里的，所以
  p->parent一定是father，又因为在调用reparent_thread () 之前调用了choose_new_parent把
  p->real_parent改成了不可能为father的reaper,所以在reparent_thread里是不可能有
  p->parent==p->real_parent的,如果有可能的话，那么可能是p虽在father->ptrace_children里但是
  p->parent不等于father.
- ptrace不为0是什么意思，为0又是什么意思。
- 如果进程A在进程B的children中，那么进程A的real_parent一定是进程B吗？
- 如果进程A在进程B的ptrace_children中，那么进程A的parent一定是进程B吗？
- 不知道为什么在traced假的时候要设p->ptrace为0而且还把p->parent改为p->real_parent，如果是这
  样的话，那么有可能有这样一种情况：p->parent和p->real_parent不相同(p被p->parent跟踪)且它的
  real_parent正被杀成为father参数且又先以traced=0调用reparent_thread ()，这时会在reparent里
  把p->ptrace设为0，把p->parent设为p->real_parent,但一直没有从p->parent的ptrace_children把
  p删掉，这合理吗？
- 在这个函数里如果发现有僵死进程且有退出信号那么就通知父进程，为什么还要加多一个判断线程组是否为空呢？
- 关于p->state==TASK_TRACED 有注释:If it was at a trace stop, turn it into a normal stop
  since it's no longer being traced.
- 又有不明白了，本来p和father是父子关系，按理说应该在同一个进程组，但是为什么还要判断是否在
  同一个进程组呢？可以这样的。孤儿进程组： 一个进程组中的所有进程的父进程要么是该进程组的一
  个进程，要么不是该进程组所在的会话中的进程。 一个进程组不是孤儿进程组的条件是，该组中有一
  个进程其父进程在属于同一个会话的另一个组中。函数里有一个判断孤立进程组的代码？又有一个问
  题：在同一个进程组里的任意一个进程都与同组中其它至少一个进程有父子或兄弟关系吗？
- 在forget_original_parent里以traced为0调用reparent_thread时的father是p的real_parent,在这种
  情况下，在reparent_thread里会把对p的跟踪去掉，换句话说就是如果一个进程A的父进程
  real_parent被杀掉，那么进程A就不能再被跟踪和去跟踪了，因为p->ptrace被清和p->parent设为
  p->real_parent。
- 如果进程A的父进程被杀掉，且进程A被跟踪且是EXIT_ZOMBIE状态，且没有退出信号，这种情况为什么
  要收集这些进程呢？
- 在forget_original_parent里以traced为1调用reparent_thread时的father是p的parent（可能与
  real_parent一样），且p->parent不等于p->real_parent,在这种情况下，reparent_thread里会把
  p->ptrace_list插入到p->real_parent->ptrace_children中，但p->real_parent可能不是一个跟踪函
  数，为什么要这样做呢？有这样的注释：Preserve ptrace links if someone else is tracing
  this child.
** void ptrace_untrace(task_t *child)
*** kernel/ptrace.c:
- 也不是一定是切回TASK_STOPPED状态，还要看看是不是有停止信号。
** void release_task(struct task_struct * p)
*** kernel/exit.c:
- 在这里p->ptrace还有可能不为0，这是会调用__ptrace_unlink把p->trace改为0
- 为什么如果这个函数被跟踪就要脱离跟踪呢?而且是在release_task里做
- ULK关于task_struct->parent的说明：this is the process that must be signaled whn the
  child process terminates。
- 看了ULK的一段话:If the process is not a thread group leader, the leader is a zombie, and
  the process is the last member of the thread group, the function sends a signal to the
  parent of the leader to notify it of the death of the process.和看了源码,有一个结
  论:task_struct->group_leader是线程组的领头进程的task_struct.为什么要这样的需求呢?
- 通知已在EXIT_ZOMBIE状态的进程还有用吗?它会做出响应.
- 为什么thread_group_empty(leader)为true时表示被杀进程是最后一个线程,因为被杀进程
  在_unhash_process里被从PIDTYPE_TGID中删除了.
- 在这里调用了put_task_struct回收task_struct了
- 有注释:If we were the last child thread and the leader has exited already, and the
  leader's parent ignores SIGCHLD, then we are the one who should release the leader.所以在
  最后p又会回到函数的开始来把leader删除掉.
** void __ptrace_unlink(task_t *child)
*** kernel/ptrace.c:
- 有一个问题：silbing是一定与real_parent有关系的吗？如果parent与real_parent不相等就和
  parent没有任何关系吗？如果是这样，那为什么还要在这个函数里调同REMOVE_LINKS(child)呢？因为
  REMOVE_LINKS是与real_parent有关的.
- 
** void __exit_signal(struct task_struct *tsk)
*** kernel/signal.c:
- atomic_dec_and_test(v):Subtract 1 from *v and return 1 if the result is zero; 0
  otherwise
- 为什么没有其它进程用signal之后还可以找到next_thread呢？
- 关于group_exit_task有注释： notify group_exit_task when ->count is equal to notify_count；
  everyone except group_exit_task is stopped during signal delivery of fatal signals,
  group_exit_task processes the signal.
- notify_count是通知group_exit_task的阀值，有这种需求吗？
- flush_sigqueue(tsk->pending)是一定的，但是共享的要在signal_struct使用计数为0的时候才flush.
- 如果没有人用signal_struct会在最后回收signal_struct结构体。
** void __exit_sighand(struct task_struct *tsk)
*** kernel/signal.c:
- 这个函数比较简单，没人使用就直接回收。
** static void __unhash_process(struct task_struct *p)
*** kernel/exit.c:
- 减nr_threads, 从PIDTYPE_PID, PIDTYPE_TGID,中删除， 若是线程组领头进程就从PIDTYPE_PGID和
  PIDTYPE_SID中删除，从进程链表中删除。
- 要为线程组领头进程才可以减process_counts,为什么会这样呢?可能创建一个非领头线程时不会增加
  process_coun
- 在这里有可能p->pid为空吗?
** void fastcall sched_exit(task_t * p)
*** kernel/sched.c:
- 用来修改父进程的时间片和平均睡眠时间.注意父进程是parent而不是real_parent
- 有注释:Potentially available exiting-child timeslices are retrieved here - this way the
  parent does not get penalized for creating too many threads.
** void disable_irq(unsigned int irq)
*** kernel/irq/manage.c:
- 这个函数要同步的，看是否正在执行这个中断函数。所以进入中断函数之后不能禁止本中断，这可能是
  为什么要在进入该中断函数之前系统会自已禁止中断。
** void disable_irq_nosync(unsigned int irq)
*** kernel/irq/manage.c:
- depth是先判断再增加的
- 这个函数可以多次被调用，仅是在depth上有变化。
** void synchronize_irq(unsigned int irq)
*** kernel/irq/manage.c:
- 这里的这个是在多处理器的情况下实现的，在非多处理器的情况下的实现在
  include/linux/hardirq.h下，就是一个barrier而己。
- 在进行处理中就relax cpu.
** void enable_irq(unsigned int irq)
*** kernel/irq/manage.c:
- 在case 1时不用break,我还以为depth没有减少
- 虽然在case 1时会挽回丢失的中断，但是已经晚了，因为中断不是在被应答之后马上处理的，这种情
  况有点意思，CPU A在接收到中断后接着CPU B才禁止中断，但是因为中断丢失所以要在CPU B禁止之后
  的不确定时间后才执行中断。
- 有IRQ_PENDING和IRQ_DISABLE就表明有中断丢失了
** fastcall unsigned int __do_IRQ(unsigned int irq, struct pt_regs *regs)
*** kernel/irq/handle.c:
- 在这里会增加kstat->irqs[irq],kstat是per_cpu变量。
- 为什么在这个函数里还要检查IRQ_DISABLE和IRQ_INPROGRESS呢？
- 在这个函数里会把IRQ_PENDING清掉，若IRQ_DISABLE或IRQ_INPROGRESS设置了也有可能会把
  IRQ_PENDING设置了。
- 相同的中断处理函数有可能正在别的CPU上执行，为什么不推到接收的那CPU上运行该中断处理
  函数呢？ULK：This leads to a simpler kernel architecture because device drivers'
  interrupt service routines need not to be reentrant (their execution is
  serialized). Moreover, the freed CPU can quickly return to what it was doing, without
  dirtying its hardware cache; this is beneficial to system performance.
- 那个死循环里处理特点是可以在执行这个函数的过程中处理别的CPU刚刚接收到的相同的中断。但是假
  如有多个相同的中断发生，那么只有一个未决的中断,这个未决的中断在handle_IRQ_event里发生（设
  置IRQ_PENDING）有注释：* This applies to any hw interrupts that allow a second instance
  of the same irq to arrive while we are in do_IRQ or in the handler. But the code here
  only handles the _second_ instance of the irq, not the third or fourth. So it is mostly
  useful for irq hardware that does not mask cleanly in an SMP environment.
- 如果IRQ_PER_CPU被设置了,那么就不用加锁了,也不用处理IRQ_PENDING, IRQ_INPROGRESS所有这些标志.
** int request_irq(unsigned int irq, irqreturn_t (*handler)(int, void *, struct pt_regs *), unsigned long irqflags, const char * devname, void *dev_id)
*** kernel/irq/manage.c:
- 是SA_SHIRQ时那么dev_id就不能为空.
- 基本是用参数初始化一个irqaction之后调用setup_irq()
** int setup_irq(unsigned int irq, struct irqaction * new)
*** kernel/irq/manage.c:
- 不能
** void open_softirq(int nr, void (*action)(struct softirq_action*), void *data)
*** kernel/softirq.c:
- 就是在softirq_vec的第nr个元素下设置data和action
** void fastcall raise_softirq(unsigned int nr)
*** kernel/softirq.c:
- 仅是调用了raise_softirq_irqoff
- 执行软中断是有检测点的(local_bh_enable,do_IRQ等),所以raise_softirq之后不会马上进入软中断.
** inline fastcall void raise_softirq_irqoff(unsigned int nr)
*** kernel/softirq.c:
- 调用了__raise_softirq_irqoff.
- 若不在中断上下文且没禁止软中断就马上调用wakeup_softirqd用线程来执行软中断
- ULK:If we're in an interrupt or softirq, we're done (this also catches softirq-disabled
  code). We will actually run the softirq once we return from the irq or softirq.
** #define __raise_softirq_irqoff(nr)
*** include/linux/interrupt.h:
- 主要是用local_softirq_pending获取__softirq_pending来将相应的位置1.
- 所以在pending了某个软中断之后多次raise_softirq()它是没有效果的.
** #define in_interrupt()		(irq_count())
*** include/linux/hardirq.h:
- 这个为1表明是在中断也可能是禁止了中断.
** asmlinkage void do_softirq(void)
*** kernel/softirq.c:
- 若抢占禁止那么一开始就要退出去,禁止枪占时不处理软中断.
** asmlinkage void do_softirq(void)
*** kernel/softirq.c:
- 在raise的时候会把__softirq_pending的位给置了,那在哪里清呢?是在这里.
- 在执行软中断函数的时候是打开软中断的,没有禁止.
- 在这个函数里会把所有pending的软中断都处理掉.
- 轮询完一次后发现又有新的软中断就又重新开始,但重新开始的次数是有限的,当次数到限后还有
  pending的软中断那么就用线程来处理了.
- 因为是轮询整个softirq_vec,所以优先级的区别就没那么大了.
** static int ksoftirqd(void * __bind_cpu)
*** kernel/softirq.c:
- 这个函数只有在被通知退出的时候才会退出,退出的结果是线程也终止.
- 在执行do_softirq()前要禁止抢占,将进程状态设为运行,执行do_softirq()后要使能抢占,将进程状态
  设为可中断,
** int kthread_should_stop(void)
*** kernel/kthread.c:
- 这个函数什么意思呢?
- 这个函数会在内核线程里用循环使用这个函数来判断是否应该退出线程
- 这个函数的实现比较简单，就是把线程停止信息中(struct kthread_stop_info)的停止进程与
  current比较
- 但是只有一个struct kthread_stop_info的全局变量，所有的进程都用这个变量，但多个进程都用这
  个变量的话若是多个进程都要禁止线程执行不是会出问题吗？
- 会不会在多个进程中都会执行相同的线程呢？如在进程A进入内核态时执行了线程C，在线程C还没有被
  退出时切换到了进程B，在进程B进入内核态时又执行了线程C，这时就会有两个进程执行线程C了。关
  键要看kthread_stop()什么时候调用了。
** int kthread_stop(struct task_struct *k)
*** kernel/kthread.c:
- 因为thread_stop_info引用了stask_struct结构体，所以就要调用get_task_struct()
- 在这个函数里用了init_completion()来初始化了kthread_stop_info.done,且调用了
  wait_for_completion(),但是在ksoftirqd这个线程函数里没有相应地调用complete(),也没有设置相
  应的kthread_stop_info.err
** struct task_struct *kthread_create(int (*threadfn)(void *data), void *data, const char namefmt[], ...)
*** kernel/kthread.c:
- 这个函数用来创建一个线程，是用工作队列来运行线程函数的，用completion来同步创建完成而不是
  同步创建开始，其实给工作队列执行的函数还不是线程函数，还是一个中间过程而已。执行的函数是
  keventd_create_kthread,被执行的函数在它的参数create里。
- 为什么要先判断helper_wq呢?因为工作队列的创建也是用到这个函数的,执行工作队列里的那些工作是
  在通过创建一个线程来执行的.但是又因为创建内核线程也是用工作队列来完成的
  (keventd_create_kthread()),所以这个先有鸡还是先有蛋的问题就出来了.
** static void keventd_create_kthread(void *_create)
*** kernel/kthread.c:
- 在这里没有调用线程的执行函数，而是以线程的执行函数来创建一个内核线程，是调用
  kernel_thread()创建内核线程的。
- 创建完成之后要等待创建开始的completion.
- 最后要complete创建远成以通知kthread_create().
** int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags)
*** arch/i386/kernel/process.c:
- 这个函数是与架构相关的，与sys_clone的类似，里面调用了do_fork来创建一个线程，被创建的这个
  线程所执行的函数还不是我们要执行的函数，还是一个系统函数kthread函数。
- 就i386的架构来看，执行的函数是先是kernel_thread_helper,再在里面调用kthread(),返回后而调用
  do_exit(),所以线程函数执行完返回到kthread()，kthread()再返回到
  kernel_thread_helper,kernel_thread_helper再调用do_exit();
** static int kthread(void *_create)
*** kernel/kthread.c:
- 在这个函数里会调用我们所要执行的函数
- 这个内核线程会屏蔽所有的信号。
- 为什么在执行线程函数之前要以TASK_INTERRUPTIBLE把current给切换出去呢？所以也可以看出创建完
  线程还有一点延时才执行线程函数。
- 为什么要在执行schedule()之前complete创建开始完成。
- 因为先调用kthread_should_stop再调用线程函数，所以可能一次都没执行线程函数就终止了线程。
- 所以创建内核线程的函数执行顺序是kthread_create创建一个工作队列的工作执行
  keventd_create_kthread(),keventd_create_kthread()调用与架构相关的
  kernel_thread(),kernel_thread()调用do_fork()来执行kthread(),kthread()里会调用要执行的线程
  函数，kthread()函数会等待线程的终止。
- 执行软中断函数的方式也是以一个独立的软中断线程为载体执行的，以kksoftirqd函数为参数调用
  kthread_create,ksoftirqd()这个函数是被kthread()这个函数调用的，有意思的一点是kthread()使
  用了kthread_should_stop()判断是否退出循环，ksoftirqd()也使用了，但从代码的设计看这是必要的。
** __init int spawn_ksoftirqd(void)
*** kernel/softirq.c:
- 创建当前CPU的软中断线程,要创建多个CPU的ksoftirqd线程时就要调用多次了。
- 先用CPU_UP_PREPARE调用cpu_callback()，再用CPU_ONLINE调用cpu_callback()
- 这些线程是在哪个进程的内核栈中执行的呢?这个进程会不会退出呢?这个线程应该是在init进程的内
  核栈里执行的.好像这些线程又不是用内核栈的?是的,内核线程也一个进程,只不过它在内核运行,一个
  进程的执行怎么会用到其它进程的栈呢?使用内核栈的都是系统调用和中断执行之类的.
- 那么线程是怎样被调度的呢?与用户进程一样吗?
** void kthread_bind(struct task_struct *k, unsigned int cpu)
*** kernel/kthread.c:
- 原来把一个进程绑定到特定的CPU执行是那么容易就实现了的。
- 这个函数的作用就是把线程k绑定到第cpu个cpu上执行.
- 绑定之前要先说线程先停下来.
- 绑定的方法就是设置线程k的cpu再设置cpumask.
** static int __devinit cpu_callback(struct notifier_block *nfb, unsigned long action, void *hcpu)
*** kernel/softirq.c:
- 这个函数只是用来给软中断用的.
- 根据kthread_should_pending()来决定是否退出。
- 为CPU_UP_PREPARE时就创建线程,再绑定到一个CPU上,为CPU_ONLINE时就唤醒一个线程.
- 这个函数创建的线程是调用ksoftirqd这个函数的.软中断只需一个线程就可以了,ksoftirqd里调用
  do_softrirq(),所以它会轮询所有等级的软中断.执行do_softirq()会禁止抢占。
- 每个CPU都有一个执行本地CPU的所有等级软中断的内核线程(ksoftirqd()),而执行HI_SOFTIRQ和
  TASKLET_SOFTIRQ这些等级的软中断时会执行完tasklet函数链表中函数.
** void __init softirq_init(void)
*** kernel/softirq.c:
- 就是打开了TASKLET_SOFTIRQ和HI_SOFTIRQ而已,与其它的软中断无关了,也就这两个软中断是提供给内
  核开发者用的.
- 被添加到这两个软中断函数是用链表的形式关联的.
- struct tasklet_head是struct tasklet_struct里next的头结点.
** void fastcall __tasklet_schedule(struct tasklet_struct *t)
*** kernel/softirq.c:
- 新加入的tasklet是放在链表头的,但执行的时候也是从链表头开始执行的,就是先进后出(堆栈)
- 插入后会raise,就像向一个工作队列里添加一个工作之后马上唤醒处理该工作队列的线程。
** static inline int tasklet_trylock(struct tasklet_struct *t)
*** include/linux/interrupt.h:
- 看tasklet是否在TASKLET_STATE_RUN的状态,主要用来防止一个tasklet在其它CPU被执行,本地CPU不会
  嵌套tasklet吗?执行tasklet函数之前没有禁止抢占.
- 禁止抢占就是禁止进程切换禁止调度，不能禁止中断，在中断里是不能进行调度的。
** static inline void tasklet_unlock(struct tasklet_struct *t)
- 清掉TASKLET_STATE_RUN状态,可以看出tasklet用来防止本地CPU嵌套执行相同的tasklet函数(不是同
  一等级的tasklet)是用tasklet_struct->state是否在TASKLET_STATE_RUN决定的,所以在运行tasklet
  函数时是可以被中断的.
** static inline void tasklet_schedule(struct tasklet_struct *t)
*** include/linux/interrupt.h:
- 要先看这个tasklet是否正在被调度,若是就不能再把这个tasklet插到tasklet的运行链表里了(就是调
  用__tasklet_schedule()),所以正在schedule的函数不能在插入到运行链表中.
** static void tasklet_action(struct softirq_action *a)
*** kernel/softirq.c:
- 这个函数就是TASKLET_SOFTIRQ这个等级所要的执行的函数,这个函数会轮询tasklet_vec这个链表中所
  有的tasklet函数.
- 每执行完这个函数就会把所有的tasklet函数执行完,再等到下一次执行TASKLET_SOFTIRQ这个等级的软
  中断时就又会执行这个函数.
- tasklet_trylock(),tasklet_unlock(),tasklet_unlock_wait()这些函数是与
  TASKLET_STATE_SCHED/RUN有关的,tasklet_disable_nosync(),tasklet_disable(),tasklet_enable()这
  些是与tasklet_struct->count有关的,为什么要两个标志呢?前者是用来防止同一个tasklet在多个
  CPU执行的,而count可以防止同一个tasklet在同一个CPU嵌套执行,因为执行一个tasklet时是没有禁止
  中断的,所以不用count的话可能会同一个tasklet在同一个CPU嵌套执行(这个说法错误,同一个
  tasklet是不可能被嵌套执行的),使用count是可以使得即使某个tasklet被插入了也可以使它不被执
  行.两者的区别可能是另一种情况：TASKLET_STATE_SCHED/RUN表明的是tasklet有没有运行，所以
  tasklet_trylock(),tasklet_unlock(),tasklet_unlock_wait()这些只能用于执行tasklet的前后，而
  tasklet_struct->count是用来显示禁止tasklet执行的,不管在TASKLET_STATE_SCHED还是在
  TASKLET_STATE_RUN，同时tasklet_disable()会调用tasklet_disable_nosync()和
  tasklet_unlock_wait()这说明这个函数会被阻塞，要在为TASKLET_STATE_SCHED时才可以。
- 从代码可以看出如果一个tasklet在其它的CPU上正在被执行或被禁止时会把这个tasklet重新插到链表
  头,等着下一次执行tasklet_action时再执行,因为tasklet_action()下一次被调用的时候可能是在
  do_softirq()函数里的下一次循环中所以会很快被调用,也有可以是下一次进入从ksoftirqd()进入
  do_softirq()的时候.
- ULK:using two kinds of non-urgent interruptible kernel functions: the so-called
  deferrable functions, and those executed by means of some work queues.这可以看出软中断函
  数是可以被中断的.但其实不然,因为在调用__do_softirq()之前已经把中断给禁止了(这种说法是错误
  的,禁止的是抢占而不是中断)
- ULK:interrupt context : it specifies that the kernel is currently executing either an
  interrupt handler or a deferrable function.禁止抢占了就是在中断上下文吗?,禁止中断了也是在
  中断上下文吗?可能叫临界区,中断上下文与临界区是不一样的.临界区应该包含中断上下文的意思,都不能调度不能休眠.
- Softirqs are statically allocated, while tasklets can also be allocated and initialized
  at runtime.
- 因为在执行__do_softirq()时已经禁止抢占但没有禁止中断,所以执行可延迟函数时是不能做调度和休
  眠的,但是可以被中断,所以软中断是执行在中断上下文的.
** static void tasklet_hi_action(struct softirq_action *a)
*** kernel/softirq.c:
- 与上一个类似
** #define in_interrupt()		(irq_count())
*** include/linux/hardirq.h:
- in_interrupte()判断的是Softirq counter域和Hardirq counter是否为正,不检查Preemption
  counter域,而preempt_disable()增加的是Preemption counter域,所以in_interrupte()和
  preempt_disable()是不相干的.
** struct workqueue_struct *__create_workqueue(const char *name, int singlethread)
*** kernel/workqueue.c:
- 与工作队列相关的结构体和变量:struct workqueue_struct,struct cpu_workqueue_struct(这个结构
  体包含在struct workqueue_struct中,wq成员指回包含它的struct workqueue_struct),workqueues工
  作队列链表
- 为什么当创建非单个CPU的工作队列时会把要创建的工作队列插入到workqueues里而创建单个CPU的工
  作队列时就不用呢?又在什么地方删除呢?
- 调用了create_workqueue_thread()创建工作队列.创建之后马上唤醒它。所以主要就两个任务：创建后唤醒。
** static struct task_struct *create_workqueue_thread(struct workqueue_struct *wq,
*** kernel/workqueue.c:
- 初始化完cpu_workqueue_thread结构体后调用kthread_create()创建一个线程调用worker_thread(),
  传以初始化完的cpu_workqueue_thread.kthread_create()创建线程的方式用了工作队列.
** static int worker_thread(void *__cwq)
*** kernel/workqueue.c:
- 进入这个函数时已经是在新创建的内核线程里执行了
- 这里要把线程状态加多一个PF_NOFREEZE状态,这个状态有什么用呢?用来指明这个线程在休眠时不能冻
  结,/linux/Documentation/power/freezing-of-tasks.txt有说明.
- 在这个函数里就是一直循环执行已插入工作队列的工作,直到这个线程被要求停止
  (kthread_should_stop())
- 把一个没有执行函数的wait_queue_t插入到struct cpu_workqueue_struct->more_work是什么意思呢?应
  该是这样的:这个wait_queue_t的task被设为current了,就是这个执行工作队列的内核线程,所以要想
  执行这个工作队列的工作可以wake_up这个more_work里的进程,是这个意思吗?ULK: more_work:Wait
  queue where the worker thread waiting for more work to be done sleeps.调用schedule()把当
  前线程加入到more_work()当schdule()返回后就从more_work删掉当前进程.虽然more_work是一个等待
  队列,但是并没有用到等待队列比较关键的东西(用wake_up类函数唤醒进程),仅仅是把一个有current
  的waitqueue插入到more_work而没有任何作用.不是这样的,在__queue_work()函数里有调用
  wake_up()把more_work的进程全唤醒.
- 因为这个函数是在一直循环执行的, 但是它是在一开始就用current定义了wait这个waitqueue,而
  current就是新创建的内核进程，所以current进程运行就会执行工作，在__queue_work里会在把一个
  工作插入工作队列之后马上唤醒current.但是为什么要在while循环里把wait加到more_work里又把它
  删除呢？就是在调度之前，在current状态为TASK_INTERRUPTIBLE的时候会把wait加到more_work里，
  而调度完之后会把wait从more_work里删除而把状态改为TASK_RUNNING。
- 好像只有current在more_work里.不会有其它进程了。
- 好像有一个BUG：在把wait从more_work里删除之后more_work可能为空了，但是queue_work这个函数不
  管有没有空都会从more_work里唤醒进程。这个BUG是不存在的，因为queue_work就是会把工作插入到
  当前的CPU的，所以执行这个函数的current（B）一定不是处理工作队列那个current（A），所以A已
  经是在调用schudule中，所以A一定是被插入到了more_work中，所以queue_work里调用wake_up是没有
  问题的,在remove之后再到add之前内核线程是不会切换出去的,即使产生了中断,在内核态时如果不调
  用schudle自动放弃，否则是不会被切到其它进程的。所以在run_workqueue()里执行的工作是在内核
  线程的上下文执行的.
** int fastcall queue_work(struct workqueue_struct *wq, struct work_struct *work)
*** kernel/workqueue.c:
- 一个工作被插入工作队列之后执行之前是不能再被插入的,这点和tasklet是一样的.
- 被插入的工作只会被插入到当前的CPU,不是所有的CPU.
** static void __queue_work(struct cpu_workqueue_struct *cwq,
*** kernel/workqueue.c:
- 在queue_work里找到CPU后在这个函数里设置wq_data,这个要找到CPU后才可以设置.
- insert_sequence在这里自加
- 会把more_work里的进程给唤醒以执行工作函数.
** static inline int is_single_threaded(struct workqueue_struct *wq)
*** kernel/workqueue.c:
- 若一个工作队列不是单CPU的，那么会把workqueue_struct.list插入到workqueues这个全局变量,难道
  workqueues仅仅是把所有非单CPU工作队列链在一起的作用吗？从代码看好像这样链也没什么作用。现
  在发现是有用的,因为struct workqueue_struct这个结构体里有一个cpu_wq成员是一个数组,就是说分
  配一个workqueue_struct结构体的时候就会分配整个数组,但是为了分辨一个workqueue_struct变量是
  一个CPU用的还是多个CPU用的,所以把所有的非单CPU的工作队列全放到一个链表里,以便对一个工作队
  列操作时可以根据该workqueue_struct是否被链到workqueues链表而作出不同的操作.
** static inline void run_workqueue(struct cpu_workqueue_struct *cwq)
*** kernel/workqueue.c:
- 注释说run_depth是防止run_workqueue()函数嵌套的,但是从代码看没有嵌套的可能啊.就算在工作函
  数中进行了休眠也不可能被嵌套的啊,因为CPU与cpu_workqueue_struct与内核线程是绑定的,而且
  run_workqueue是一个静态的函数所以不能被外部调用,在可能用的范围内也出现不了嵌套啊.出现了就是一个BUG.
- 执行这个函数一次会把worklist里的所有工作都处理掉。
** static void flush_cpu_workqueue(struct cpu_workqueue_struct *cwq)
*** kernel/workqueue.c:
- 如果是参数cpu_workqueue_struct是当前CPU的,那么就调用run_workqueue()这个是不会出现
  run_workqueue()嵌套的.
- 这里把当前的insert_sequence保存下来与remove_sequeuece比较来判断是否某个cpu_workqueue已经
  没有工作可以执行,但是为什么要用这种方式呢?直接用一个原子变量不行吗?或用一个加锁的计数器不
  行吗?但因为访问insert_sequence和remove_sequeuece都获得了自旋锁，所以也不会出问题。
- 如果调这个函数所在的CPU不与cpu_workqueue_struct所属的CPU不是同一个就不会调用
  run_workqueue()仅仅是调用了schdule()因为所以工作一定要在指定的CPU执行，这样也可以防止
  run_workqueue()嵌套执行。
- 在这里会使用work_done这个等待队列来实现同步，在run_workqueue()会wake_up这个工作队列。
  work_done就只是这个作用而已。
** int fastcall queue_delayed_work(struct workqueue_struct *wq, struct work_struct *work, unsigned long delay)
*** kernel/workqueue.c:
- 实现延时执行的方法就是定时器插入工作。在时间到来的时候调用delayed_work_timer_fn()来把工作
  插入工作队列。虽然把工作插入之后会马上调用wake_up把more_work唤醒，但是这个是有比较大的延
  迟的。
- 在没有把工作插入工作队列之前已经把work.pending给设置了，这个合适吗？合适的，因为不这样可
  能有多个定时器同时在等着把工作插入工作队列。
** #define get_cpu()		({ preempt_disable(); smp_processor_id(); })
** #define put_cpu()		preempt_enable()
*** include/linux/smp.h:
- 先调用preempt_enable_no_resched()递减抢占计数器然后再调用preempt_check_resched()判断是否
  要切换该进程来调用preempt_schedule().
** #define put_cpu_no_resched()	preempt_enable_no_resched()
** asmlinkage void __sched preempt_schedule(void)
*** kernel/sched.c:
- 
** #define DEFINE_PER_CPU(type, name)
*** include/asm-generic/percpu.h:
- 为什么在多核处理器下多单核处理器下多加了一个指定段的编译属性就可以实现给每个CPU分配变量了？
- 就像声明一个全局变量一样，因为这些全局变量都有一个per_cpu作为开头，所以以后声明变量时要注意
  了。
** #define per_cpu(var, cpu) (*RELOC_HIDE(&per_cpu__##var, __per_cpu_offset[cpu]))
*** include/asm-generic/percpu.h:
- 获取第cpu个的var变量。
** #define __get_cpu_var(var) per_cpu(var, smp_processor_id())
*** include/asm-generic/percpu.h:
- 用per_cpu实现的
** #define get_cpu_var(var) (*({ preempt_disable(); &__get_cpu_var(var); }))
-　比上一个多了一个禁止抢占
** #define put_cpu_var(var) preempt_enable()
*** include/linux/percpu.h:
- 打开抢占而已。name不使用
** #define alloc_percpu(type)
*** include/linux/percpu.h:
- 这个是动态分配的，直接调用__alloc_percpu
** static inline void *__alloc_percpu(size_t size, size_t align)
*** include/linux/percpu.h:
*** mm/slab.c:
- 是单核的话就直接用kmalloc分配，是多核也用kmalloc分配，但分配的是struct percpu_data结构，
  再用kmalloc_node来根据每个CPU各自所用的内存结点来分配。
** #define spin_lock_init(lock)	do { (void)(lock); } while(0)
*** include/linux/spinlock.h:
- 这是单核的定义.
** #define spin_lock_init(x)	do { *(x) = SPIN_LOCK_UNLOCKED; } while(0)
*** include/asm-i386/spinlock.h:
- 这是多核的的定义.
** #define spin_lock(lock)		_spin_lock(lock)
*** include/linux/spinlock.h:
- 这个的定义没有分单多核.这个函数与ULK说的是不一样的,竟然调用preempt_enable()的地方不一样,
  应该在spin_unlock里调用的把.看错ULK了,在spin_lock里调用preempt_enable()是在可抢占内核里实
  现的.如果在不可抢占的内核中会一直自旋,不放弃CPU.
- pause指令相当于rep;nop.
** #define _spin_lock(lock)
*** include/linux/spinlock.h:
- 这是单核的定义,三步:禁止抢占,调_raw_spin_lock,调__acquire.
- 为什么要禁止抢占呢?这样可以防止自已自动放弃CPU.
** void __lockfunc _spin_lock(spinlock_t *lock) __acquires(spinlock_t);
- 也上单核的操作方式
** #define _raw_spin_lock(lock)	do { (void)(lock); } while(0)
*** include/linux/spinlock.h:
- 这是单核的方式
** static inline void _raw_spin_lock(spinlock_t *lock)
*** include/asm-i386/spinlock.h:
- 多核的与架构有关,用汇编实现的.
** #define spin_unlock(lock)	_spin_unlock(lock)
*** include/linux/spinlock.h:
- 这个不分单多核.
** #define _spin_unlock(lock)
*** include/linux/spinlock.h:
- 这是单核的实现,就三步:调用_raw_spin_unlock,打开抢占,调用__release
** void __lockfunc _spin_unlock(spinlock_t *lock)
*** kernel/spinlock.c:
- 与单核的一样.
** #define spin_unlock_wait(lock)	(void)(lock)
*** include/linux/spinlock.h:
- 这是单核的实现
** #define spin_unlock_wait(x)	do { barrier(); } while(spin_is_locked(x))
*** include/linux/spinlock.h:
- 这是多核的实现
- 死循环调用spin_is_locked
** #define spin_is_locked(lock)	((void)(lock), 0)
*** include/linux/spinlock.h:
- 这是单核的实现
** #define spin_is_locked(x)	(*(volatile signed char *)(&(x)->slock) <= 0)
*** include/asm-i386/spinlock.h:
- 这个是多核的实现,就只是一个判断而已.
** #define rwlock_init(lock)	do { (void)(lock); } while(0)
*** include/linux/spinlock.h:
- 这是单核的实现。
** #define rwlock_init(x)	do { *(x) = RW_LOCK_UNLOCKED; } while(0)
*** include/asm-i386/spinlock.h:
- 这是多核的实现。
- 0x01000000为可读可写，当想读时就将它减1，为0x00ffffff，为0x00000000时是已加上了写锁。
- 像这些自旋锁的实现，要根据是否是单多核，是否配置为可抢占。
** void __lockfunc _spin_lock(spinlock_t *lock)
*** kernel/spinlock.c:
- 在这个头文件里实现了_read_lock(), _read_lock(), _spin_lock_irqsave(), _spin_lock_irq(),
  _spin_lock_irq(), _spin_lock_bh(), _read_lock_irqsave(), _read_lock_irq(),
  _read_lock_bh(), _write_lock_irqsave(), _write_lock_irq(), _write_lock_bh(),
  _spin_lock(), _write_lock()这些函数的可抢占版和非抢占版。而这些函数里面调用的前面有_raw字
  样的就是被实现了单核版和多核版，单核版在include/linux/spinlock.h里实现的是单核版，多核版
  在特定的架构的spinlock.h文件里实现。
- 抢占版的都会调用cpu_relax()和使用break_lock成员。抢占版的会打开抢占，允许其它进程抢占，自
  旋锁不再自旋。
- 这类函数的调用关系层是以spin_lock为例：spin_lock() -> _spin_lock()(加一个下划线前缀) ->
  _raw_spin_lock()
- 关于_spin_lock()类函数的可抢占版和非抢占版的所在的文件的定义：要使用自旇锁就要包含文件
  include/linux/spinlock.h(A文件),在文件A定义了单核版的_spin_lock()宏和多核版的_spin_lock()函
  数声明，单核版的_spin_lock()没有可和非可抢占版之分,多核版的可抢占版和非抢占版
  的_spin_lock()的实现都在kernel/spinlock.c里(注意:实现的函数的用宏的方式,所以cscope找不到
  的).单核版的_spin_lock()里调用的_raw_spin_lock()在文件A里定义,单核版的_spin_lock()调用
  的_raw_spin_lock()是有调试版和非调试版的;多核版的_spin_lock()的可抢占版调
  用_raw_spin_lock(),这个_raw_spin_lock()不是单核版那个,而是在include/asm-i386/spinlock.h里
  定义的那个,这个_raw_spin_lock()会用到pause指令(rep;nop),而多核版的_spin_lock()的非可抢占
  版(!CONFIG_PREEMPT)没调用_raw_spin_lock(),而是调用了cpu_relax()而且在调用cpu_relax()之前还使
  能抢占,cpu_relax()也是用rep;nop指令的.
- 单核版的_spin_lock() -> 禁止抢占后调用有调试版的_raw_spin_lock(); 多核版的可抢占版
  的_spin_lock() -> _raw_spin_lock()(架构相关), 多核版的非可抢占版的_spin_lock() -> 使能抢
  占再调用cpu_relax().
** #define seqlock_init(x)	do { *(x) = (seqlock_t) SEQLOCK_UNLOCKED; } while (0)
*** include/linux/seqlock.h:
- #define SEQLOCK_UNLOCKED { 0, SPIN_LOCK_UNLOCKED }
** static inline void write_seqlock(seqlock_t *sl)
*** include/linux/seqlock.h:
- seqlock_t这个锁只是防止多个写操作,与读无关.
- 把sequence自加。
** static inline void write_sequnlock(seqlock_t *sl) 
*** include/linux/seqlock.h:
- 又把sequence自加。
** static inline int write_tryseqlock(seqlock_t *sl)
*** include/linux/seqlock.h:
- 用了spin_trylock(),写是用锁的
** static inline unsigned read_seqbegin(const seqlock_t *sl)
*** include/linux/seqlock.h:
- 返回sequence，读是不用锁的
** static inline int read_seqretry(const seqlock_t *sl, unsigned iv)
*** include/linux/seqlock.h:
- iv为奇数表示正在写，写的锁没有解，sl不等于iv表示已被修改过。这两种情况都要重新执行。
** #define rcu_read_lock()		preempt_disable()
*** include/linux/rcupdate.h:
- 就只是禁止抢占而已
** #define rcu_read_unlock()	preempt_enable()
*** include/linux/rcupdate.h:
- 就只是使能抢占而已
- RCU锁和seq锁有一个区别是:RCU锁可以使用旧的数据作处理,不管数据是否被改变,而seq锁不能,如果
  在处理完之后发现被保护的数据被改变就要重新用新的数据再做一次处理.
** void fastcall call_rcu(struct rcu_head *head, void (*func)(struct rcu_head *rcu))
*** kernel/rcupdate.c:
- 把head插到nxttail这个链表的尾部.
- 这个函数把一个新的释放rcu旧数据的回调函数加到rcu_data这个per-cpu变量的nxttail这个成员的链
  表里去.
- 不是一个CPU经过了静止状态就调用所有的回调函数,而是所有的CPU都经过一次静止状态之后就执行一
  个tasklet来把所有在nxttail里的callback函数执行一次来释放旧的rcu数据,那么回调函数是怎么知
  道自己要释放的数据是什么呢?从回调函数的参数是struct rcu_head可以启发到被释放的数据度该是
  一个结构体,这个结构体里至少有一个struct rcu_head类型的成员,而这个成员就是做为rcu_head参数
  的那个,也是被链到nxttail的,所以可以从nxttail里把存放callback函数的struct rcu_head传给回调
  函数,回调函数再用container_of找到要释放的结构体就可以了.
** void synchronize_rcu(void)
*** kernel/rcupdate.c:
- 这个函数用completion来同步,等待所有CPU经过静止状态.
- 这个函数的实现就是把一个唤醒自己的函数插入到rcu_tasklet里.
- 有一个疑问:是不是被complete之后可能还有callback函数在tasklet里呢?可能有,这个函数的作用只
  是说经过了一个静止状态,而不是说返回之后就没有callback函数在tasklet里了.所以这个函数可以这
  样用:write一个rcu之后调用这个函数,这个函数返回之后可以读到最新的rcu数据没有延时太长的时间.
** void rcu_check_callbacks(int cpu, int user)
*** kernel/rcupdate.c:
- 这个函数有什么用呢?
** static void rcu_process_callbacks(unsigned long unused)
*** kernel/rcupdate.c:
- 就是调用__rcu_process_callbacks(),有软中断和非软中断之分.
** static void __rcu_process_callbacks(struct rcu_ctrlblk *rcp, struct rcu_state *rsp, struct rcu_data *rdp)
*** kernel/rcupdate.c:
- 在curlist不为空和完成的rcu(rcu_ctrlblk.completed)回收不小于rcu_data.batch的要求时就将
  rcu_data.curlist的移到rcu_data.donetail中去并把rcu_data.curlist清空,这个rcu_data.donetail有什么用
  呢?rcu_data.completed是在哪里加的呢?
- 如果rcu_data.nxtlist不空且rcu_data.curlist为空(已经移到了donetail里去了),就把nxtlist移到
  curlist里去并清空nxtlist.这三个链表nxtlist,curlist,donelist就是这种关系了.设置本cpu的
  batch号为当前cur的下一个
- RCU是怎么确定所有的CPU都不同时在RCU读锁里呢?经过的静止状态只是一个过去的状态而已.好像是这
  样的:一个CPU经过静止状态之后就等待所有的CPU经过所有的静止状态,等到所有的CPU都经过静止状态
  之后就可以把新的数据替换旧的数据.
- rdp->quiescbatch = rcp->cur 标识 quiesc period 的开始， rdp->qs_pending = 1， 标识一个
  quiesc period 尚未结束; rdp->passed_quiesc = 0 则是 cpu queisc 结束指示符， 当内核代码执
  行诸如抢占动作前， 会将这个变量置 1， 在后面的时钟中断处理中， 如果发现这个值为 1， 则将
  rdp->qs_pending 置 0 标识quiesc period 的结束， 并将 cpu 在 rcp->cpumask 中的位清除， 以
  表示本 cpu 同意 grace period 结束， 至于能否结束， 则要看其他的 cpu 是否同意。
  rdp->passed_quiesc = 0 还有一个作用是将 quiesc period 开始之前就 (多次) 置位的
  passed_quiesc 的动作取消。
- grace period 的开始代表的是 rcu 观察到至少一个 cpu 已经完成了至少一次数据更新操作，但可能
  善后工作还没有做， 例如上面说的释放旧数据； 而 grace period 的结束， 则代表者 rcu 认为所
  有的其他 cpu 都不再引用写者持有的旧数据了， 因此， 可以安全释放这份数据。 grace period 是
  上一轮 grace period 结束后， 第一次观察到一个 cpu 完成数据更新操作为开始的， 这时所有
  cpu 上一轮 quiesc period 都已经结束， 都处于停止状态。 grace period 一旦启动， 则后继的肯
  定是各个 cpu 各自的 quiesc period 的启动， 停止； grace period 结束于最后一个 quiesc
  period 的结束之后。 在 grace period 执行期间， 如果其他 cpu 上也出现了写者数据更新操作，
  则视这个 cpu 上的 quiesc period 启动与否而有不同行为， 如果没有启动， 则可以认为这个更新
  操作属于这个已启动的 grace period, 否则， 则将其归类于下一个 grace period。 但这个分类并
  不是 100% 正确， 会将本该分在这个 grace period 的结果分在了下一个 grace period, 这是 smp
  系统的缓存一致性决定的， 存在偶然因素， 但产生的结果不是不可接受的 ---- 即不会引起旧数据
  的提前释放， 只会引起其释放延迟， 这个在 rcu 目标应用场景中， 是可以接受的。
- 在退出所有读操作的那一瞬间， 那就不再引用了， 那么， 在那一瞬间之后呢， 会不会再次引用这
  些旧数据？ 不会， 因为它就算再读相同的数据， 读到的也不过是写者已经更新的新数据。 最终的
  结果就是， 只要发生了一次抢占， 则本 cpu 就会同意 grace period 的结束， 也就是说， 所有写
  者不用再担心运行在这个 cpu 上的代码引用它的旧数据。 那么当最后所有 cpu 都退出 quiesc
  period 的时候， 只会剩下写者自己持有旧数据， 它可以任意操作旧数据了。
- 写者修改数据前首先拷贝一个被修改元素的副本，然后在副本上进行修改，修改完毕后它向垃圾回收
  器注册一个回调函数以便在适当的时机执行真正的修改操作。等待适当时机的这一时期称为grace
  period，而CPU发生了上下文切换称为经历一个quiescent state，grace period就是所有CPU都经历一
  次quiescent state所需要的等待的时间。垃圾收集器就是在grace period之后调用写者注册的回调函
  数来完成真正的数据修改或数据释放操作的。https://www.ibm.com/developerworks/cn/linux/l-rcu/
- 因为 call_rcu_bh将把 softirq 的执行完毕也认为是一个 quiescent state，因此如果修改是通过
  call_rcu_bh 进行的，在进程上下文的读端临界区必须使用这一变种。
- 因为donelist一开始是赋初值的,所以就算在执行的过程中对链表进行增删改查也不用赋为NULL
- rcu_data.batch大于rcu_ctrlblk.completed时(就是rcu_data.batch == rcu_ctrlblk.completed+1)
- 如果nextlist里有数据且curlist里没有数据,那么当前CPU就会等待从当前时间开始的下一个完整的
  grace period,如果所等行待的grace period结束了(rcu_data.batch>=rcu_ctrlblk.completed)且
  rcu_data.curlist不为空,那么就会把curlist赋给donelist并在这个函数的最后调用rcu_do_batch()
  来处理所有的回调函数.
** static inline void rcu_qsctr_inc(int cpu)
*** include/linux/rcupdate.h:
- 当在CPU上发生进程切换时，函数rcu_qsctr_inc将被调用以标记该CPU已经经历了一个quiescent
  state。该函数也会被时钟中断触发调用。rcu_qsctr_inc函数的确在schedule()里被调用.
- 就是把per cpu变量rcu_data.passed_quiesc改为1.
- quiesc period 与 grace period 的关系， 就是 quiesc 从来都是在 grace period 开始之后开始，
  在 grace period 结束之前结束。
** void rcu_check_callbacks(int cpu, int user)
*** kernel/rcupdate.c:
- 时钟中断触发垃圾收集器运行，它会检查：否在该CPU上有需要处理的回调函数并且已经经过一个
  grace period；否没有需要处理的回调函数但有注册的回调函数；否该CPU已经完成回调函数的处理；
  否该CPU正在等待一个quiescent state的到来；如果以上四个条件只要有一个满足，它就调用函数
  rcu_check_callbacks。
- idle_cpu(cpu)说明第cpu正在执行idle进程.
- 检查CPU是否经历了一个quiescent state:1.当前进程运行在用户态;2.当前进程为idle且当前不处在
  运行softirq状态，也不处在运行IRQ处理函数的状态；
- 通过调用函数rcu_qsctr_inc标记该CPU的数据结构rcu_data和rcu_bh_data的标记字段passed_quiesc，
  以记录该CPU已经经历一个quiescent state。
- 函数rcu_check_callbacks将调用tasklet_schedule，它将调度为_该_CPU设置的tasklet rcu_tasklet，
  每一个CPU都有一个对应的rcu_tasklet.
- rcu_process_callbacks可能做以下事情：1． 开始一个新的grace period；这通过调用函数
  rcu_start_batch实现。2． 运行需要处理的回调函数；这通过调用函数rcu_do_batch实现。3． 检查
  该CPU是否经历一个quiescent state；这通过函数rcu_check_quiescent_state实现
** static void rcu_do_batch(struct rcu_data *rdp)
*** kernel/rcupdate.c:
- rcu_data.donelist才是被tasklet执行的回收rcu函数,不是rcu_data.curlist.
- 最终会在这个函数里调用回收函数.
- 只有在__rcu_process_callbacks()里检测到donelist不为空时才调用rcu_do_batch()
- 每调用里面的一个函数就是把一个旧数据释放掉.
- 里面的maxbatch是每次执行tasklet时调用的回调函数的个数,为什么要这个东西而不是一次调用所有
  的回调函数呢?
- 如果donelist为空就把&donelist赋给donetail,否则就用tasklet_schedule再调度这tasklet.
- 在这里,注意每次调用的回调函数有最大值限制.这样做主要是防止一次调用过多的回调函数而产生不
  必要系统负载.http://blog.chinaunix.net/uid-12260983-id-2952617.html
** static void rcu_check_quiescent_state(struct rcu_ctrlblk *rcp, struct rcu_state *rsp, struct rcu_data *rdp)
*** kernel/rcupdate.c:
- 调用函数rcu_check_quiescent_state检查该CPU是否经历了一个quiescent state,如果是并且是最后
  一个经历quiescent state的CPU，那么就结束grace period，并开始新的grace period。如果有完成
  的grace period，那么就调用rcu_do_batch运行所有需要处理的回调函数。
- rcu_data.quiescbatch(Batch # for grace period)不等于rcu_ctrlblk.cur(Current batch
  number)就说明当前CPU所在的quiesc period不是在全局的grace period里的,注释里说start new
  grace period,这个应该不正确应该是quiesc period。因为不等了，也说明了开始了一个全局的
  grace period之后，当前CPU还没经过一个quiesc period,所以就要开始一个quiesc period,而开始一
  个quiesc period就是要把rcu_data里的三个变量设置一下：qs_pending设为1（标识一个quiesc
  period 尚未结束,qs_pending只在这个函数被修改），passed_quiesc设为0（在经过quiesc period时设为1，schedule()调用
  rcu_qsctr_inc()转而设passed_quiesc为1，但和qs_pending有什么区别呢？）,quiescbatch设为rcu_ctrlblk.cur指定所开始的这个
  quiesc period是在第cur个grace period里的。
- batch这个词在这里的指第几批grace period.
- 若qs_pending为0，表明对于这个CPU来说已经经过了第quiescbatch个grace period了。
- qs_pending和passed_quiesc还是有一点不同的:qs_pending - 0, passed_quiesc - 0这种情况是不可
  能的,qs_pending - 0, passed_quiesc - 1:schedule()把passed_quiesc设为1了,之后也调用了这个
  函数,但在开始一个新的grace period之前就会出现这种情况.qs_pending - 1, passed_quiesc - 0:
  因发现又开始了一个新的grace period,所以当前CPU又要开始重新检查一个quiesc state,这种情况就
  是在这个函数一开始时设置的.qs_pending - 1, passed_quiesc - 1:开始一个quiesc后也执行了
  schedule()但还没有进行这个函数rcu_check_quiescent_state()
- 搞明白rcu_data和rcu_ctrlblk里面的成员就差不多了.
- 函数的功能就是若发现开始了一个新的grace period就开始一个新的quiesc period等待经过一个静止
  状态,否则看是否经过了静止状态,若经过了静止状态就清sq_pending.
- 对这个函数和里面调用的所有的函数层层解开之后功能就是：有可能开始一个新的quiesc period;有
  可能标识当前的CPU已经经过了静止状态；有可能因为当前CPU经过了静止状态后同时发现自已是最后
  一个经过静止状态的CPU而可能因为还有下一batch而开始一个新的grace period.
** static void cpu_quiet(int cpu, struct rcu_ctrlblk *rcp, struct rcu_state *rsp)
*** kernel/rcupdate.c:
- cpus_empty()参数全为空的时候就为真。所以rcu_state.cpumask为空的话，就说明所有的CPU都经过
  了当前第batch的grace period.当所有的CPU都经过静止状态时就把rcu_ctrlblk.completed给设为
  rcu_ctrlblk.cur，所以可以通过这两个是否相等判断是否正在等待下一个grace period.
- 这个函数主要是一个CPU经过静止状态的时候调用的（当经过一次静止状态时有被
  rcu_check_quiescent_state调用）。
** static void rcu_start_batch(struct rcu_ctrlblk *rcp, struct rcu_state *rsp,
*** kernel/rcupdate.c:
- 这个函数会根据传入的参数next_pending来修改rcu_ctrlblk.next_pending.在cpu_quiet()调用的
  rcu_start_batch()是以next_pending为0调用的，因为在cpu_quiet()调用rcu_start_batch()时一定
  是最后一个cpu经过了静止状态,就因为这个所以要以next_pending为0调用rcu_start_batch()吗?
- 如果rcu_ctrlblk.next_pending为1但是rcu_ctrlblk.completed不等于rcu_ctrlblk.cur时是不会改变
  rcu_ctrlblk.cur的,因为rcu_ctrlblk.completed不等于rcu_ctrlblk.cur说明当前批的grace period
  还没有结束,所以即使有下一批的回收挂起,也不能把改变cur而开始下一个grace period.如果
  rcu_ctrlblk.next_pending为0但是rcu_ctrlblk.completed等于rcu_ctrlblk.cur时也不能改变
  rcu_ctrlblk.cur,因为rcu_ctrlblk.completed等于rcu_ctrlblk.cur说明当前已经不在grace period
  里了,但因为next_pending为0即没有下一批需要回收的rcu,所以也不能设置rcu_ctrlblk.cur以开始一
  个新的grace period.开始下一个grace period(递加rcu_ctrlblk.cur)时前会清掉
  rcu_ctrlblk.next_pending,
- 到目前为止rcu_ctrlblk结构体里的cur,completed,next_pending成员都已经明白什么意思
  了,rcu_data结构体里的quiescbatch,passed_quiesc,qs_pending,donelist,donetail也明白什么意思
  了.
- 因为rcu_qsctr_inc()会在schedule()和rcu_check_callbacks()里调用,而且rcu_check_callbacks()
  又在定时器中断处理程序里调用，所以比较明了在哪里会去确定是否经过静止状态。
- 在next_pending不为假时才会开始一个grace period.
- 读者是可以嵌套的.也就是说rcu_read_lock()可以嵌套调用.
- The Linux kernel offers a number of RCU implementations, the first such implementation
  being called "Classic RCU". More material introducing RCU may be found in the
  Documentation/RCU directory in any recent Linux source tree, or at Paul McKenney's RCU
  page. Linux RCU的第一个实现
- 将rcp->next_pending置为1.设置这个变量主要是防止多个写者竞争的情况
- 如果CPU 1上有进程调用rcu_read_lock进入临界区,之后退出来,发生了进程切换,新进程又通过
  rcu_read­_lock进入临界区.由于RCU软中断中只判断一次上下文切换,因此,在调用回调函数的时候,仍
  然有进程处于RCU的读临界区,这样会不会有问题呢?只要使用被RCU保护数据的方法正确就不会有问题,引
  用时要用rcu_dereference()函数,rcu_dereference()函数里定义了一个新的局部变量来对保护指针的
  引用,所以一下进入临界区的时候就是最新的数据了如:
  #+BEGIN_EXAMPLE
  void foo_update_a(int new_a)//这个是更新数据
  {
  struct foo *new_fp;
  struct foo *old_fp;
  
  new_fp = kmalloc(sizeof(*new_fp), GFP_KERNEL);
  spin_lock(&foo_mutex);
  old_fp = gbl_foo;
  *new_fp = *old_fp;
  new_fp->a = new_a;
  rcu_assign_pointer(gbl_foo, new_fp);
  spin_unlock(&foo_mutex);
  synchronize_rcu();
  kfree(old_fp);
  }

  int foo_get_a(void)//这个是引用数据,不能使用gbl_foo直接引用.
  {
  int retval;
  
  rcu_read_lock();
  retval = rcu_dereference(gbl_foo)->a;
  rcu_read_unlock();
  return retval;
  } 
  #+END_EXAMPLE
** static inline void init_MUTEX (struct semaphore *sem)
*** include/asm-i386/semaphore.h:
- 就是调用sema_init这个函数.
** static inline void init_MUTEX_LOCKED (struct semaphore *sem)
*** include/asm-i386/semaphore.h:
- 就是调用sema_init这个函数.
** static inline void sema_init (struct semaphore *sem, int val)
*** include/asm-i386/semaphore.h:
- 初始化struct semaphore里的三个成员,count为参为val,sleepers(ULK:Stores a flag that
  indicates whether some processes are sleeping on the semaphore.)为0,wait(ULK:Stores the
  address of a wait queue list that includes all sleeping processes that are currently
  waiting for the resource.)用init_waitqueue_head初始化.
** #define DECLARE_MUTEX(name) __DECLARE_SEMAPHORE_GENERIC(name,1)
*** include/asm-i386/semaphore.h:
- 编译时声明
** static inline void up(struct semaphore * sem)
*** include/asm-i386/semaphore.h:
- 用汇编实现，两步：1.把计数器加1，2.计数器大于0就调用__up_wakeup().
** ".globl __up_wakeup\n"
*** arch/i386/kernel/semaphore.c:
- 这个函数全用汇编实现，就连函数名也是。
- 就是把__up()这个函数的参数压入栈后调用__up()，返回后再出栈。
** static fastcall void __attribute_used__  __up(struct semaphore *sem)
*** arch/i386/kernel/semaphore.c:
- 直接调用调用wake_up()，所以可以看出信号量是用等待队列实现的，可以得出它的性能如何。
** static fastcall void __attribute_used__ __sched __down(struct semaphore * sem)
*** arch/i386/kernel/semaphore.c:
- 这个函数与down()函数结合可以看出：如果进程A获取信号X后因为count为0而进入__down(),这时A成
  为了第一个等待信号A的进程，后来进程B也因为获取信号X进入休眠，但有可能进程B先获得信号量。
- 理解这个函数sem->count, sem->sleepers之间的关系的例子：当sleepers为1,count为-1时进入
  down()之后会把count自减1为-2，接着进入__down(),接着在__down()里会把sleepers自加为2，经过
  atomic_add_negative之后count就为-1，所以为-1并不表明只有一个进程在等待，接着又把sleepers
  改为1，所以这也表明sleepers为1也不说明只有一个睡眠进程,如果这时有一个进程up了，那么count
  会为0,这时因为sem->sleepers为1，所以atomic_add_negative()为假，接着把sem->sleepers改为0，
  这时只有一个进程在等待了，且sem->count为0,当这个等待的进程被唤醒之所再进入
  atomic_add_negative()时，因为sem->sleepers为0,sem->count为0所以atomic_add_negative()为真，
  所以会继续等待，且sem->count为-1了,接着sem->sleepers改为了1,再次执行
  atomic_add_negative()时还是为真。
- 其实信号量有使用等待队列里的锁来保护整个信号量结构体的访问。所以不会对struct semaphore有
  竞争访问，若有竞争访访问，会在一个地方有问题：若进程A是第一个等待某个信号量的进程，进程A
  在某一个时刻执行完atomic_add_negative之后在sem->sleepers=1之前可能被切换去出执行进程B，这
  时B又要调用down()获取这个信号量,down()会在一开始把sem->count自减1，接着进入__down()，在执
  行完sem->sleepers++之后被切换出去执行A，而这时sem->sleepers为2，但是恢复执行A之后会执行
  sem->sleepers=1这一句，所以当B再次恢复执行时就是执行int sleepers = sem->sleepers,而
  sem->sleepers已被改成了1而不是恢复执行前的2，所以在某个进程执行up()之前sem->count是-2，当
  某个进程真的执行up()时，按理说应该会唤醒一个进程，但是因为sem->count原来为-2所以最终也没
  有唤醒进程。所以必须有一个锁给以保护才可以,这个锁就是sem->wait->lock自旋锁了。
** static inline int down_trylock(struct semaphore * sem)
*** include/asm-i386/semaphore.h:
- 这个函数在一开始把sem->count减-1,如果为负数就进入__down_failed_trylock宏，转而直接调
  用__down_trylock()
** static fastcall int __attribute_used__ __down_trylock(struct semaphore * sem)
*** arch/i386/kernel/semaphore.c:
- 在一开始把sleepers赋予了sem->sleepers+1，接着再用atomic_add_negative()把sleepers加到
  sem->count里去。因为sleepers是从sem->sleepers加多了1，所以这个1把sem->count在
  down_trylock()里减的1给抵消了。
** static fastcall int __attribute_used__ __sched __down_interruptible(struct semaphore * sem)
*** arch/i386/kernel/semaphore.c:
- 这个函数与__down()类似，多了一个检查信号量的步骤（因为是interruptible的等待，可以被信号唤
  醒），还有一个地方不一样就是设置进程状态为TASK_INTERRUPTIBLE.
** static inline void init_rwsem(struct rw_semaphore *sem)
*** lib/rwsem-spinlock.c:
*** include/asm-i386/rwsem.h:
- linux通用的struct rw_semaphore和i386里的struct rw_semaphore是不同的。
- struct rw_semaphore里的wait_list是一个struct rwsem_waiter的链表，rwsem_waiter->flags表明
  了rwsem_waiter->task是读的还是写的。
- rw_semaphore->count的定义有点复杂：ULK:(Stores two 16-bit counters. The counter in the
  most significant word encodes in two's complement form the sum of the number of
  nonwaiting writers (either 0 or 1) and the number of waiting kernel control paths. The
  counter in the less significant word encodes the total number of nonwaiting readers and
  writers.)
** void fastcall __sched wait_for_completion(struct completion *x)
*** kernel/sched.c:
- ULK在complete一节一开始所举的例子是有会出现吗？up()是用汇编实现的，实现的时候是一开始就自
  加了sem->count,转而进入__up_wakeup(),这个函数在最后调用__up(),转而调用__wake_up()用
  sem->wait作为参数,在__wake_up()里先把sem->wait->lock给锁上之后就以非同步的方式调
  用__wake_up_common()，一定要用非同步的方式，因为现在持有自旋锁，__wake_up_common()退出之
  后就解sem->wait->lock锁，而ULK说的被抢占的情况只能发现在这个解锁之后，但解锁之后就是退
  到__up()再直接退到__up_wakeup()再直接退到up(),所以就算在解锁之后被等待信号量的进程抢占了
  之后把信号量结构体释放也不会有问题，因为在解锁之后不会再被调用。
- 与信号量的区别就是：信号量的sem->wait->lock不会完全保护sem->count的访问，因为在up()和
  down()的一开始在没有加锁的情况下就修改了sem->count,而wait_for_completion()和complete()是
  在加了锁之后才会访问completion->done.
- completion的等待都是用WQ_FLAG_EXCLUSIVE插入的，被插入的等待是放在队列尾的，是把进程的状态
  改为TASK_UNINTERRUPTIBLE的
- 如果在进入函数时发现done大于0时就不会进入休眠，这点与信号量是一样的。
- 信号量和completion都是用等待队列来实现同步的。
** unsigned long fastcall __sched wait_for_completion_timeout(struct completion *x, unsigned long timeout)
*** kernel/sched.c:
- 不同的是调用了schedule_timeout()而不是schedule(),在发现超时就会马上退出而不再获取。
- schedule_timeout()是与schedule()一样来处理切换的吗？而不会管时间来调度，就是说不会因为时
  间到了而调度某个进程，是在这某个进程被切回来执行之后而判断与所要求的切回时间有多大的差距。
** int fastcall __sched wait_for_completion_interruptible(struct completion *x)
*** kernel/sched.c:
- 这个的区别就是把进程的状态改成TASK_INTERRUPTIBLE，在改成这个状态之前和
  down_interruptible()一样也会检查是否还有未处理的信号。
** #define local_irq_disable() 	__asm__ __volatile__("cli": : :"memory")
*** include/asm-i386/system.h:
- i386就是用一个指令把本地的中断给禁止了，
** #define irqs_disabled()
*** include/asm-i386/system.h:
- 查看本地中断传递是否被禁止.ULK:yields the value one if the IF flag of the eflags
  register is clear, the value one if the flag is set.
** #define local_bh_disable()
*** include/linux/interrupt.h:
- 在preempt_count的软中断位置了加1，所以若要使能软中断就要使local_bh_disable()和
  local_bh_enable()的调用次数匹配。这点与local_irq_save()和local_irq_restore()不一样。
** #define time_after(a,b)
*** include/linux/jiffies.h:
- a的时间在b之后就为真。
- http://decimal.blog.51cto.com/1484476/410673 若b是固定的，那么无论b从哪里开始，只要开始时
  a等于b，且a是在递增的且递增的次数小于有符号整型的最大值，那么这个宏就是安全的，对于
  HZ=100，数据长度是32位的，2147483647/100秒 = 0.69年 = 248.5天才会出现不正确的判断。
- jiffies_64要溢出需要几百万年，这样就可以保存从开机到现在所经过的时间了。
** static inline u64 get_jiffies_64(void)
*** kernel/time.c:
*** include/linux/jiffies.h:
- 可以通过BITS_PER_LONG来判断。
- 若BITS_PER_LONG不是64位的，那么就要用顺序锁来读取jiffies_64了.
** struct timespec
*** include/linux/time.h:
- tv_sec成员是秒，从1970-7-1开始计算起。
- tv_nsec是纳秒
** void __init time_init(void)
*** arch/i386/kernel/time.c:
- 从cmos获取的值赋给了xtime.tv_sec
- xtime.tv_nsec设了一个特殊的值以在5min之后就会溢出。
- 设置单调时间，但是看不懂这个设置什么含义.
- 选择时间对象.
- 设置时间中断处理函数。
** irqreturn_t timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
*** arch/i386/kernel/time.c:
- 这个是时钟中断函数，注意它那执行了哪些函数。
- mark_offset()这个函数主要就是更新jiffies_64并记录相对应的
- ULK:a few timer interrupts can be lost, for instance when interrupts remain disabled for
  a long period of time; in other words, the kernel does not necessarily update the xtime
  variable at every tick. However, no tick is definitively lost, and in the long run,
  xtime stores the correct system time. The check for lost timer interrupts is done in the
  mark_offset method of cur_timer; 禁止中断会把产生的中断丢失，原来mark_offset真的是来防止
  时间中断丢失。这里有关如何使用tsc来防止中断丢失：http://book.51cto.com/art/200810/93782.htm
- 好像只有在调用这个函数的时候才会增加jiffies_64啊且在增加jiffies_64之后很快就会在下面所调
  用的update_times()函数里把wall_jiffies给补上，若是这样就只有在timer_interrupt()函数里才会
  出现jiffies_64比wall_jiffies大的情况，但是为什么在do_gettimeofday()会用jiffies减
  wall_jiffies呢？
- 接着调用do_timer_interrupt().
- 时钟中断：由系统定时硬件以周期性的间隔产生,hz：上述间隔由hz的值设定，hz是一个与体系结构相关的常数
- 全局变量xtime所维持的当前时间通常是供用户来检索和设置的，而其他内核模块通常很少使用它（其
  他内核模块用得最多的是jiffies），因此对xtime的更新并不是一项紧迫的任务，所以这一工作通常
  被延迟到时钟中断的底半部（bottom half）中来进行。由于bottom half的执行时间带有不确定性，
  因此为了记住内核上一次更新xtime是什么时候，Linux内核定义了一个类似于jiffies的全局变量
  wall_jiffies，来保存内核上一次更新xtime时的jiffies值。好像更新xtime不是在底半部做的，因为
  更新xtime.tv_nsec是在update_wall_time_one_tick()做的,而是在update_wall_time()被调用，
  update_wall_time_one_tick()更新xtime.tv_nsec，update_wall_time()更新xtime.tv_sec。
** static inline void do_timer_interrupt(int irq, void *dev_id, struct pt_regs *regs)
*** arch/i386/kernel/time.c:
- 只是调用了do_timer_interrupt_hook()
** static inline void do_timer_interrupt_hook(struct pt_regs *regs)
*** include/asm-i386/mach-default/do_timer.h:
- 连续调用了do_timer(),profile_tick(),update_process_times()
** void do_timer(struct pt_regs *regs)
*** kernel/timer.c:
- 为什么这里又要递增jiffies_64呢？不是已经在mark_offset里加了吗？好像mark_offset里的增加。
  这两个地方增加是不一样的，在mark_offset()里加的丢失的时钟中断的时间，而在这里加的是定时到
  来的时间。是jiffies_64是在中断丢失的情况下增加的。
- 调用了update_times
** static inline void update_times(void)
*** kernel/timer.c:
- 调用了update_wall_time()
- jiffies和wall_jiffies是什么关系呢？只有在这个函数wall_jiffies被修改，把它与jiffies的差值加到wall_jiffies,
** static void update_wall_time(unsigned long ticks)
*** kernel/timer.c:
- 调用ticks次update_wall_time_one_tick().和second_overflow()
** static void update_wall_time_one_tick(void)
*** kernel/timer.c:
- 这个函数主要是用来更新xtime中的tv_nsec成员的。
- 这个函数的实现考虑到了NTP和adjtimex()系统调用。
- time_adjust是指要调整的时间，单位是微秒的（scale us）,它会在do_settimeofday()和
  do_adjtimex()被修改成0，在这个函数里会被修改成time_next_adjust,而time_next_adjust会在
  do_adjtimex()里被修改,所以do_timeadjx()调用之后不会马上改变时间，只是在时钟中断处理函数执
  行时才会改变,因为time_adjust_step是微秒的,所以要乘1000,又因为是在中断定时器时调用了这个函
  数所以要加上tick_nsec.
- 从代码来看就是把xtime.tv_nsec加上（减去）time_phase上的高几位。time_phase和time_adj是与
  second_overflow()有关的
** static void second_overflow(void)
*** kernel/timer.c:
- 用来处理微秒数成员溢出的情况。
- 为什么second_overflow()要在xtime.tv_sec增加之后才调用呢?


- 在极端的条件下，同时会有多个 TV 需要进行 cascade 处理，会产生很大的时延。这也是为什么说
  timeout 类型的定时器是 timer wheel 的主要应用环境，或者说 timer wheel 是为 timeout 类型的
  定时器优化的。因为 timeout 类型的定时器的应用场景多是错误条件的检测，这类错误发生的机率很
  小，通常不到超时就被删除了，因此不会产生 cascade 的开销。另一方面，由于 timer wheel 是建
  立在 HZ 的基础上的，因此其计时精度无法进一步提高。毕竟一味的通过提高 HZ 值来提高计时精度
  并无意义，结果只能是产生大量的定时中断，增加额外的系统开销。因此，有必要将高精度的 timer
  与低精度的 timer 分开，这样既可以确保低精度的 timeout 类型的定时器应用，也便于高精度的
  timer 类型定时器的应用。还有一个重要的因素是 timer wheel 的实现与 jiffies 的耦合性太强，
  非常不便于扩展。因此，自从 2.6.16 开始，一个新的 timer 子系统 hrtimer 被加入到内核中。
- 内核使用全局变量 xtime 来记录这一信息，这就是通常所说的“Wall Time”或者“Real Time”。与
  此对应的是“System Time”。System Time 是一个单调递增的时间，每次系统启动时从 0 开始计时。
- 每个CPU都必须定义两个时钟源：REAL和MONOTONIC。REAL代表实时时钟，MONOTONIC代表单调递增时钟。
  两者的区别在于，当用户更改计算机时间时，REAL时钟会收到影响，但MONOTONIC不受影响。
- wall_to_monotonic 没有被EXPORT_SYMBOL,xtime被EXPORT_SYMBOL
