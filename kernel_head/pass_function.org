#+STARTUP: showall
* question/answer:
- 因为中断的处理函数在内核态运行，又因为中断可以嵌套的，如果一连续有行验中断产生，那么会不
  会把内核栈给爆了？应该不会,因为产生某个中断之后系统会禁止相应的中断.
- 内核线程用谁的栈呢？应该是当前进程的,再次回到用户态的时候线程已经执行完了,所以内核栈不用
  因为再次回到用户态的时候把内核栈保存下来.
- 进程0最后执行cpu_idle()
- linux2.6有exit_group()和_exit()系统调用来终止一个用户程序。前者用do_group_exit()实现，C库
  的exit()调用，后者用do_exit()实现，如C库的pthread_exit()调用。
- TGID，PGID，SID这几个hash表的主要目的是让你容易通过一个领头进程找到它的线程组中的其它线程，
  进程组中的其它进程，对话中的其它进程。
- 一个中断号一个irq_desc_t结构体。
- irq_desc_t里的depth表示这个中断被禁止了多少次，但是Linux经常是禁止所有中断，为了效率不能
  在这种情况一个一个中断来禁止。
- arm的用arch/arm/kernel/irq.c的，里面有disable_irq()之类的，i386用kernel/irq/manage.c也有
  disable_irq()之类的，但是disable_irq()的实现是一样的。
- 中断丢失是发生要多处理器中的。CPU A在应答一个中断线前被CPU B禁止了相同的中断，但是CPU A在
  应答之后执行do_irq()，但在do_irq()里会检查IRQ_DISABLE,所以do_irq()不会往下执行了。
- SA_INTERRUPT 这个标志指的是在禁止本地上所有的中断，而不是自已本身。
- IRQ_PER_CPU:该IRQ只能发生在一个cpu上
  IRQ_LEVEL:该中断由电平触发
  IRQ_MASKED:屏蔽了其他中断
** struct pid * fastcall find_pid(enum pid_type type, int nr)
- 没办法，还是要用遍历
** int fastcall attach_pid(task_t *task, enum pid_type type, int nr)
- 注意所有的成员都要设置好。
** static fastcall int __detach_pid(task_t *task, enum pid_type type)
- 返回值被detach_pid使用得有点巧妙。
** void fastcall detach_pid(task_t *task, enum pid_type type)
- 比__detach_pid ()多一个功能就是把从pid位图里把nr删掉。
** task_t *find_task_by_pid_type(int type, int nr)
** void switch_exec_pids(task_t *leader, task_t *thread)
- 一个非领头线程调用sys_execve()时就调用它。
** void __init pidhash_init(void)
** void __init pidmap_init(void)
- 主要是做0号进程的工作。只分配一页。
** int alloc_pidmap(void)
- 在这里也分配页给page
- alloc_pidmap里的求max_scan的方法为什么要减!offset呢?因为若不在一页的起始位置就要减去0而不是1是因为想多循环一次当前页，所以max_scan指的是
  将要经过多少次页头（页尾）.
** int default_wake_function(wait_queue_t *curr, unsigned mode, int sync, void *key)
- 仅仅是调用try_to_wake_up
- key参数没有用
- 所以自定义唤醒函数时,里面可以一开始调用default_wake_function,在最后做一些想做的事情,而不
  能在一开始做想做的事情因为进程还没有切换.不是这样的,无论在default_wake_function之前还是之
  后所做的事都是在被切换的进程的上下文中进行的.
** int autoremove_wake_function(wait_queue_t *wait, unsigned mode, int sync, void *key)
- 调用上一个函数后从链表中删除,删除用list_del_init,与__remove_wait_queue所用的list_del不一
  样,为什么是在调用上一个函数之前而不是之后呢?被try_to_wake_up()之后没有从等待队列里删除会
  不会又再次唤醒呢?
** #define DEFINE_WAIT(name)
- 用了上一个函数作为唤醒函数。
- 若用这个定义一个WAIT,因为用上一个函数作为唤醒调用函数,所以同时会把它从队列删除.唤醒之后不
  用再把它从队列删除.
** static inline void init_waitqueue_func_entry(wait_queue_t *q, wait_queue_func_t func) 
*** include/linux/wait.h:
- 可以自定义唤醒函数。仅此而已,没有赋值给task
** static inline void init_waitqueue_entry(wait_queue_t *q, struct task_struct *p)
*** include/linux/wait.h:
- 与上一个比多了初始化进程。但唤醒函数用default_wake_function, flags都是0
** #define DECLARE_WAITQUEUE(name, tsk)
*** include/linux/wait.h:
- 注意与DEFINE_WAIT的不同，用tsk,default_wake_function,NULL和NULL初始task_list,而不是
  current,autoremove_wake_function,LIST_HEAD_INIT
- 那么用DECLARE_WAITQUEUE定义的要不要在删除的时候把它从链表删除呢？要的,用
  remove_wait_queue，在ulk里也有说的:unless DEFINE_WAIT or finish_wait( ) are used, the
  kernel must remove the wait queue element from the list after the waiting process has
  been awakened.
** #define DECLARE_WAIT_QUEUE_HEAD(name)
*** include/linux/wait.h:
- 用自已来初始化链表.
** static inline void init_waitqueue_head(wait_queue_head_t *q)
*** include/linux/wait.h:
- 结果和DECLARE_WAIT_QUEUE_HEAD(name)一样.
** static inline int waitqueue_active(wait_queue_head_t *q)
*** include/linux/wait.h:
- 看队列是否为空
** static inline void __add_wait_queue(wait_queue_head_t *head, wait_queue_t *new)
*** include/linux/wait.h:
- 这个是加在队列前面的
** static inline void __add_wait_queue_tail(wait_queue_head_t *head, wait_queue_t *new)
*** include/linux/wait.h:
- 这个是加在队列尾的
** void fastcall __sched sleep_on(wait_queue_head_t *q)
*** kernel/sched.c:
- 就是改状态,加入队列,schedule,删除队列. 要注意加锁.
- sleep_on系列的函数是与等待队列相关的.
- 时间窗口出现在改状态和schedule之间可能会被唤醒.
- the sleep_on( )-like functions cannot be used in the common situation where one has to
  test a condition and atomically put the process to sleep when the condition is not
  verified; therefore, because they are a well-known source of race conditions, their use
  is discouraged.
** long fastcall __sched sleep_on_timeout(wait_queue_head_t *q, long timeout)
** long fastcall __sched interruptible_sleep_on_timeout(wait_queue_head_t *q, long timeout)
** void fastcall __sched interruptible_sleep_on(wait_queue_head_t *q)
** void fastcall prepare_to_wait(wait_queue_head_t *q, wait_queue_t *wait, int state)
*** include/linux/wait.h:
- 这个用于把current加入等待队列的。
- 注释有说为什么把设置进程状态放在加入队列的后面
- 要先判断wait->task_list为空的时候才把wait加入队列。为什么在sleep_on里不用呢?因为
  prepare_to_wait的应用场合不同，prepare_to_wait会放在一个循环里重复调用，但是finish_wait不会被放到循环里，看看__wait_event就知道了。
- 虽然在is_sync_wait里会检查wait是否为空，但进入prepare_to_wait是肯定不会为空的，所以is_sync_wait做了多余的事情。
** #define is_sync_wait(wait)	(!(wait) || ((wait)->task))
*** include/linux/wait.h:
- 有一段注释：Used to distinguish between sync and async io wait context: sync i/o typically specifies a NULL wait queue entry or a wait
  queue entry bound to a task (current task) to wake up. aio specifies a wait queue entry with an async notification
  callback routine, not associated with any task.为什么同步io可以指定一个NULL 的wait呢？
** void fastcall prepare_to_wait_exclusive(wait_queue_head_t *q, wait_queue_t *wait, int state)
*** include/linux/wait.h:
- 不同的是设置了exclusive标志。
** void fastcall finish_wait(wait_queue_head_t *q, wait_queue_t *wait)
*** kernel/wait.c:
- 用了list_empty_careful，为什么呢？只能用于调用list_del_init的情况，因为list_del_init里调用了INIT_LIST_HEAD
- sleep_on是状态->插入队列->schedule->删除队列;插入队列(prepare)（检测是否已插入）->状态
  (prepare)（检查同步）->schedule->状态(finish)->删除队列(finish)(先list_empty_careful)
- 有一个例子：
#+BEGIN_EXAMPLE
    DEFINE_WAIT(wait);
    prepare_to_wait_exclusive(&wq, &wait, TASK_INTERRUPTIBLE);
                                /* wq is the head of the wait queue */
    ...
    if (!condition)
        schedule();
    finish_wait(&wq, &wait);
#+END_EXAMPLE
** #define wake_up(x)			__wake_up(x, TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE, 1, NULL)
*** kernel/sched.c:
- 要知道linux是不能指定下一个切换到某个进程。
- wake_up也不能指定唤醒某个进程（把某个进程状态改成运行），注意只有一个参数x，但是找到一个
  被唤醒的进程后就会马上调用它的func，因为大部分的func是default_wake_function，会调用
  try_to_wake_up
- 等待队列是从第一个开始唤醒的，一个wait可以加入到队列头add_wait_queue也可以加到队列尾
  add_wait_queue_tail，同时还有互斥和非互斥的wait，所以可以用这些东西组合成一个有优先级的队
  列。

** #define wake_up_nr(x, nr)		__wake_up(x, TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE, nr, NULL)
** #define wake_up_all(x)			__wake_up(x, TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE, 0, NULL)
** #define wake_up_interruptible(x)	__wake_up(x, TASK_INTERRUPTIBLE, 1, NULL)
** #define wake_up_interruptible_nr(x, nr)	__wake_up(x, TASK_INTERRUPTIBLE, nr, NULL)
** #define wake_up_interruptible_all(x)	__wake_up(x, TASK_INTERRUPTIBLE, 0, NULL)
** #define wake_up_locked(x)		__wake_up_locked((x), TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE)
- 已经把队列给lock住了
** #define wake_up_interruptible_sync(x)   __wake_up_sync((x),TASK_INTERRUPTIBLE, 1)
** void fastcall __wake_up_sync(wait_queue_head_t *q, unsigned int mode, int nr_exclusive)
*** kernel/sched.c:
- 这个函数目前为止只是用于上一个宏，所以nr_exclusive一直是1，但是在实现的时候nr_exclusive为0的时候就不同步了，为什么呢？
** static void __wake_up_common(wait_queue_head_t *q, unsigned int mode, int nr_exclusive, int sync, void *key)
- sync这个参数是只是传给func而已。
- 如果想唤醒所有的进程而不管它是否互斥，那么nr_exclusive就是0，实现的方法是!--nr_exclusive
** clone
- 这个是C的库函数，它有多个参数但是它调用的sys_clone只有一个参数，转而调用的do_fork有多个参
  数。但是ARM又是不一样的，它的包含了很多参数。
- 关于fn和arg参数在ULK有：the wrapper function saves the pointer fn into the child's stack
  position corresponding to the return address of the wrapper function itself; the pointer
  arg is saved on the child's stack right below fn.
** fork
- 也是一个C库函数。
- ULK:The traditional fork( ) system call is implemented by Linux as a clone( ) system
  call whose flags parameter specifies both a SIGCHLD signal and all the clone flags
  cleared, and whose child_stack parameter is the current parent stack pointer. Therefore,
  the parent and child temporarily share the same User Mode stack.总之比clone就多了一个
  SIGCHLD和与父进程共用一个堆栈.
** vfork
- 也是一个C库函数。
- ULK:The vfork( ) system call, introduced in the previous section, is implemented by
  Linux as a clone( ) system call whose flags parameter specifies both a SIGCHLD signal
  and the flags CLONE_VM and CLONE_VFORK, and whose child_stack parameter is equal to the
  current parent stack pointer.总之比fork就多了CLONE_VM和CLONE_VFORK
** long do_fork(unsigned long clone_flags, unsigned long stack_start, struct pt_regs *regs, unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr)
*** kernel/fork.c:
- 注意参数的意思
- 如果clone_flags和current->ptrace的符合某些条件时，就算clone_flags不设置CLONE_PTRACE也给它加上。主要是看current_ptrace的设置。
- 关于调用ptrace_notify在ULK有这样说：If the parent process is being traced, it stores the
  PID of the child in the ptrace_message field of current and invokes ptrace_notify( ),
  which essentially stops the current process and sends a SIGCHLD signal to its
  parent. The "grandparent" of the child is the debugger that is tracing the parent; the
  SIGCHLD signal notifies the debugger that current has forked a child, whose PID can be
  retrieved by looking into the current->ptrace_message field.
- 在调用ptrace_notify时的参数在里面被赋给了task_struct->exit_code，为什么要这样呢？也赋给了
  si_code,这还可以理解
- 调的ptrace_notify的原因：因为父进程被跟踪而且要求被创建的子进程也要被跟踪，所以就调用了。
  调用完这个函数的过程中因调用schedule(do_notify_parent_cldstop())所以会停下。
- 这个函数是在哪里真正创建一个进程并开始以两个执行路径运行的呢？好像整个进程都是以current来
  运行的。那创建的子进程在什么时候运行呢？可能是在copy_process函数里把它插入到了某个运行队列里了。
- 若CLONE_VFORK设置了要在ptrace_notify之后才可以等待，子进程运行完。
** static inline int fork_traceflag (unsigned clone_flags)
*** kernel/fork.c:
- 在clone_flags里的最低8位是指定退出时所要发送的信号。
- 若系统调用是由vfork发起的且想跟踪vfork发起的创建的子进程就返回PTRACE_EVENT_VFORK;若子进程
  退出时所发的信号不是SIGCHLD(为什么要这个条件呢？)且想跟踪clone创建的子进程就返回PTRACE_EVENT_CLONE；若想跟踪由
  fork创建的子进程就返回PTRACE_EVENT_FORK.
- 为什么是CLONE_VFORK是要使用completion原语呢？因为vfork的man手册有一段这样的话：vfork()
       is a special case of clone(2).  It is used to create new processes without copying
       the page tables of the parent process.  It may be useful in performance-sensitive
       applica‐ tions where a child is created which then immediately issues an
       execve(2)vfork() differs from fork(2) in that the parent is suspended until the
       child terminates (either normally, by calling _exit(2), or abnormally, after
       delivery of a fatal signal), or it makes a call to execve(2).  Until that point,
       the child shares all memory with its parent, including the stack.  The child must
       not return from the current function or call exit(3), but may call _exit(2).
       Signal handlers are inherited, but not shared.  Signals to the parent arrive after
       the child releases the parent's memory (i.e., after the child terminates or calls
       execve(2)).
- CLONE_STOPPED:Forces the child to start in the TASK_STOPPED state.
- 若设置了CLONE_STOPPED,为什么还要设置PT_PTRACE才可以添加SIGSTOP的信号呢?
** void fastcall wake_up_new_task(task_t * p, unsigned long clone_flags)
*** kernel/sched.c:
- 再次说一下task_t->array是指向CPU运行队列里的某一个active或expire成员.
- 如何通过一个task_t来获得一个运行队列:从task_t里的thread_inof里的CPU来找到task是在哪一个
  CPU上,知道哪个CPU就可以找出相应的运行队列了.task_t里的run_list就是task_t->array链表里的一
  个结点.
- 会根据是否共用相同的VM和是否在同一个CPU来插入进程和父进程的相对位置。
- __activate_task会使用enqueue_task来把进程插入到相应的运行队列尾，而不是头。
- 在这个函数里current->array会有空的时候,是什么时候呢？
- 为什么不共享VM就要子进程运行先呢？注释有说明是因为可能运行exec，那么是不是子进程运行
  exec后会把所有的原来的VM删掉呢？
- 好像在cpu==this且CLONE_VM清除且current->array不为空时的情况下没有设置array->bitmap,这个是
  一个bug吗？在这里为什么要把子进程的prio设置成父进程的prio呢？难道仅是为了想在父进程之前运
  行而把它放在程父进程相同优先级的运行队列中？
- 它的this_rq为什么不是通过task_rq_lock来获取的呢？而是根据cpu==this_cpu来判断的呢？
- 为什么在不是同一个CPU时要重新计算timestamp呢？计算的方法是减去父进程所在运行队列的
  timestamp_last_tick再加上子进程所在运行队列的timestamp_last_tick
- __activate_task这个函数里会把进程加入到运行队列里的，虽然名子看起来不是这样子的，但结合参
  数一起还是可以看来的。
- 把一个进程加入到另外一个CPU之后还要看那个CPU需不需要重新调度。实现很简单，用被加入的进程
  的优先级（动态优先级）与CPU上的运行队列里的curr->prio比较即可。
- 为什么不实现CONFIG_SMP版和非CONFIG_SMP版的呢？像resched_task那样。
- set_need_resched()和resched_task()不一样的，前者只是设置了current的标志，而后者会让其它
  CPU的进程重新调度。
- 为什么要把current的运行队列锁住呢？
- 这个函数只有do_fork调用而已
** void ptrace_notify(int exit_code)
*** kernel/signal.c:
- ULK有解释：ptrace_notify( ), which essentially stops the current process and sends a
  SIGCHLD signal to its parent.
- si_signo的是SIGTRAP，且调的的ptrace_stop函数里的do_notify_parent_cldstop是用相应的
  CLD_TRAPPED
- 在这个函数里建立的siginfo_t是在ptrace_stop函数被放到last_siginfo里，在
  do_notify_parent_cldstop里建立的siginfo_t是发给跟踪进程的.
- 调的这个函数因ptrace_stop的schedule，所以可能会被调度.是在do_notify_parent_cldstop里唤醒
  父进程,在ptrace_stop调度。
- current重新可以运行后是马上看有没有挂起的进程。为什么这之前要把last_sigpending清掉呢？
** static void ptrace_stop(int exit_code, int nostop_code, siginfo_t *info)
*** kernel/signal.c:
- 这个函数的作用应该是在current被跟踪时用来停止current的,并通知跟踪进程
- 不知道为什么要自减group_stop_count
- task_t->last_siginfo是给跟踪用的,保存的东西有什么用呢?
- 为什么要设置current->exit_code呢?
- 把current的状态改成TASK_TRACED之后没有把它从运行队列中删除吗？
- 函数里是先解siglock的锁再加上siglock的锁
- 为什么那个PT_ATTACHED要非呢?好像不对的吧
- current->parent->signal不等于current->signal是不是说明current与current->parent不在同一个
  线程组呢?
- 为什么要各种条件不成立的时候再次设置进程为TASK_RUNNING状态呢？有注释说是跟踪进程已不在了。
** static void do_notify_parent_cldstop(struct task_struct *tsk, struct task_struct *parent, int why)
*** kernel/signal.c:
- 重新认识一下struct siginfo_t,结构体里的联合体用得有技巧，因为_kill->_pid和_sigchld->_pid
  的地址相同，_kill->_uid和_sigchld->_uid地址相同，所以只需提供访问_kill或_sigchld里其
  中_pid和_uid即可，所以只提供了访问了_kill->_uid和_kill->_pid的宏而没有_sigchld.si_errno是
  The error code of the instruction that caused the signal to be raised, or 0 if there was
  no error。si_code是A code identifying who raised the signal 。si_status是exit code.不知道
  si_utime和si_stime有什么用，保存什么的，但是它们分别被赋tsk->utime和tsk->stime,原来ULK里
  列出的si_code只是一部分，还有一些SIGILL类、SIGFPE类、SIGSEGV类、SIGBUF类的、SIGTRAP类的、
  SIGCHLD类的等。每次发信号时都要填这个结构体，在这个函数里因为要给发一个信号所以要填这个结
  构体,又因为发的是SIGCHLD信号，所以要填结构体中的联合体的SIGCHLD结构体。
- CLD_TRAPPED这个表示被跟踪进程被捕获，可能运行到了breakpoint,所以运行要停下来，这时候应该
  给跟踪进程发一个信号，所以在这个函数里要检查CLD_TRAPPED是否被置。但是为什么也要检查
  CLD_CONTINUED.
- 为什么是CLD_STOPPED时要这样设置si_status呢？是CLD_TRAPPED时要这样设置si_status呢?
- 既然要在两个判断之后才使用info为什么花那么多时间先设置info呢？
- 因为一个子进程只有一个父进程，所以__wake_up_parent函里使用的wait_chldexit等待队列最多只有
  一个进程，这样解释对吗？
- wait_chldexit是给wait4()系统调用用的，但是子进程只给父进程发一个SIGCHLD信号而已，父进程是
  怎么是子进程退出了呢？
- 这个函数的主要功能是什么呢？是给父进程发一个SIGCHLD信号，而且还必须与CLD_CONTINUED、
  CLD_STOPPED、CLD_TRAPPED相关的。
** static task_t *copy_process(unsigned long clone_flags, unsigned long stack_start, struct pt_regs *regs, long stack_size, int __user *parent_tidptr,int __user *child_tidptr, int pid)
*** kernel/fork.c:
- p->user这个成员是一个指针，就是说还是和父进程共用的。这是对的，因为创建子进程时的用户是与
  父进程的用户相同的
- nr_threads在这个函数里增加，在__unhash_process减，__unhash_process被release_task和
  unhash_process调用
- max_threads表示什么意思呢？它在fork_init里被初始化
- 我觉得nr_threads>=max_threads不应该放在nr_threads++之前，如果root调用fork足够多次且每次都
  在nr_threads>=max_threads这个比较之后且在nr_threads++之前那么nr_threads就会大于
  max_threads
- 在这里把tgid设置了pid,就是说创建一个进程时把子进程作一个新线程组的领头进程,是这样子吗?为
  什么呢?但是设置了CLONE_THREAD又不同了.
- 为什么要设置set_child_tid和clear_child_tid呢？clear_child_tid是什么来的，有一句主释：
  Clear TID on mm_release()?
- 创建的子进程是不能跟踪它运行后的系统调用的.
- 把父进程的执行域设置成了自已的执行域,为什么呢?
- 为什么要这样设置exit_signal呢?若没设置CLONE_THREAD,那么用clone_flags里的
- 要设置group_leader为子进程,好像不对的吧.是不对,在后面会因为CLONE_THREAD而做修改的
- 把cpus_allowed设置成与current的一样,设置子进程的cpu与current的一样.
- 若current有一个SIGKILL信号,那么它就不能创建子进程.
- 若设置了CLONE_PARENT或CLONE_THREAD的时候要把子进程的real_parent设置了current的
  reald_parent,为什么有CLONE_THREAD的要这样设置,正真创建子进程的current竟然不是current,
- 刚创建完的子进程的parent与real_parent是一样的.
- 若CLONE_THREAD设置了同是SIGNAL_GROUP_EXIT也设置了,那么是不能创建子进程的.
- 若CLONE_THREAD设置了那么把子进程的group_leader设置成current的group_leader
- SIGNAL_GROUP_EXIT和group_stop_count没有关联的吗?可以不设置SIGNAL_GROUP_EXIT但
  group_stop_count可以大于0?
- 若group_stop_count大于0说明一个全组的停止正在进行,那么就要把正创建的进程加入到停止组中.
- 有一个跟踪进程的被跟踪进程链表(task_struct->ptrace_list, task_struct->ptrace_childen)
- 子进程一定会被插入到PID hash表和TGID hash（tgid在上面被设置成正确的值了）表，但是为什么要
  在子进程为线程组领头进程时才会把子进程插入PGID hash表和SID hash表呢？
- 在这里居然还会检查p->pid是否为0，是否多此一举？
- 每个CPU都有一个进程个数计数器process_counts
- ULK有一句这样的话：If the child is a thread group leader (flag CLONE_THREAD cleared)。就
  是说CLONE_THREAD若不设置那么子进程就是线程组领头进程，若进程是一个线程而不是一个线程组领
  头进程那么它就不是一个进程组的成员，若进程是一个线程组领头进程那么它就是一个进程组的成员，
  那么一个进程怎样才可以成为进程组领头进程呢？
- 关于进程归属的问题总结ULK:若子进程是一个thread group leader(清CLONE_THREAD),就设tgid为
  pid(就是自已),设group_leader为自已(这个有点想不明白,源码的确的这样的.)那么除了把子进程插
  入到TGID,PGID之外还要插入到SID中.若子进程不是一个thread group leader(置CLONE_THREAD),那么
  tgid设为current->tgid(注意不是current,所以线程组不能嵌套),设group_leader为
  current->group_leader并把它插入到TGID中去,但是为什么子进程不是thread group leader了还要插
  入到TGID中呢？哦看错了，源码是这样的attach_pid(p, PIDTYPE_TGID, p->tgid);不是插p而是
  p->tgid那么每创建一个线程时领头线程不是都要被插一次，这点在ULK上表述有错。不是，我错了，
  的确的把子进程插入TGID中。要重新认识一下那4个链表。
** static struct task_struct *dup_task_struct(struct task_struct *orig)
*** kernel/fork.c:
- prepare_to_copy()在i386里用来关闭fpu，在arm里什么也不做。
- 就是分配了task_struct和thread_info并拷贝和设置之间的指针；再设置tsk->usage.
** static inline void copy_flags(unsigned long clone_flags, struct task_struct *p)
*** kernel/fork.c:
- 这个函数是被copy_process调用的，为什么要把PF_SUPERPRIV清掉呢？不能继承父进程的
  PF_SUPERPRIV吗？为什么把PF_FORKNOEXEC给置了？
- 由copy_process传入的clone_flags在do_fork可能对CLONE_PTRACE动了手脚.task_struct->ptrace是
  在这里设置的,在do_fork里用到,为什么不在do_fork做修改呢?隔太远了.
** static int copy_files(unsigned long clone_flags, struct task_struct * tsk)
*** kernel/fork.c:
- 一个后台程序可能不包含任何文件.
- 若设置了CLONE_FILES那么就用current的files,不用改.
- 
** static int count_open_files(struct files_struct *files, int size)
*** kernel/fork.c:
- 这种的计算方法是不是有的粗略了?
** static inline int copy_fs(unsigned long clone_flags, struct task_struct * tsk)
*** kernel/fork.c:
- CLONE_FS:ulk:Shares the table that identifies the root directory and the current working
  directory, as well as the value of the bitmask used to mask the initial file permissions
  of a new file (the so-called file umask ).
** static inline struct fs_struct *__copy_fs_struct(struct fs_struct *old)
*** kernel/fork.c:
- 主要的步骤的分配一个fs_struct再把old里的值拷贝过去
** static inline int copy_sighand(unsigned long clone_flags, struct task_struct * tsk)
*** kernel/fork.c:
- 若是CLONE_sighand或CLONE_THREAD其中一个设置就与父进程共享，即增加计数器就可以了。
- 若不共享，但还要把action的内容拷贝过来，为什么呢？所以无论共享与否都会把共享action
** static inline int copy_signal(unsigned long clone_flags, struct task_struct * tsk)
*** kernel/fork.c:
- 若CLONE_THREAD设置那么就共享进程的，增加计数器即可。
** static int copy_mm(unsigned long clone_flags, struct task_struct * tsk)
*** kernel/fork.c:
- 若current->mm为空的时候就不用拷贝也不分配了，为什么不分配了呢？
- 若设置了CLONE_VM就共享.若不共享,还会把父进程的mm给拷贝过来.再后来又修改了部分成员
** int copy_thread(int nr, unsigned long clone_flags, unsigned long esp, unsigned long unused, struct task_struct * p, struct pt_regs * regs)
*** arch/i386/kernel/process.c:
- 这个函数初始化了task_struct->thread_info结构体,其中有reg成员、栈、ip寄存器，使子进程被调
  度运行时在正确的栈和ip指针下运行。
- ULK:The value returned by the system call is contained in eax: the value is 0 for the
  child and equal to the PID for the child's parent. To understand how this is done, look
  back at what copy_thread() does on the eax register of the child's process.
** void fastcall sched_fork(task_t *p)
*** kernel/sched.c:
- 函数一开始把进程状态设置为运行,但到目前为止还没有把进程插入到运行队列,所以还不会被调度.但
  可以不可以通过把它插入到一个等待队列来获得运行呢?
- 给子进程分时间片时为什么current的时间片要先加1呢?current->time_slice不可能是0;若是1的话,
  如果不加1,那么子进程的时间就是0,又因为current的时间片又会用移位的方式重新调整,所以若是1,
  最后父和子进程的时间片都是0.用这种计算方式无论如何都不会增加和减少原来current的时间片.
- 调整之后的current时间片若为0那么会马上开始定时器的调度.
** NORET_TYPE void do_group_exit(int exit_code)
*** kernel/exit.c:
- SIGNAL_GROUP_EXIT是该线程组中所有的线程都要设置的吗？还是只是调用这个函数的线程才会设置。
  不是这样的，task_struct->signal是线程共享的。
- 这代码实现了退出代码的传递性，就是第一个调用该函数的线程所使用的exit_code参数才会被一值采
  用。
** void zap_other_threads(struct task_struct *p)
*** kernel/signal.c:
- SIGNAL_GROUP_EXIT不是在do_group_exit里设置了吗？为什么又要在这里设置SIGNAL_GROUP_EXIT呢？
  多此一举吗？
- 要把group_stop_count清零。所以group_stop_count是从0开始计数的。
- thread_group_exit不是在do_goup_exit里查过了吗？这里是不是多此一举呢？
- 在copy_process里可以看出线程的group_leader与领头线程的一样。但这里为什么有不相等的情况呢？
  一个线程可以不与领头线程在相同的进程组吗？可以从注释上看出若线程执行execve或类似的东西的
  时候不在同一进程组
- 不在同一进程组时要设exit_signal为-1呢？就算不在同一线程组也要发SIGKILL信号给它。
- 会把被杀线程的SIGSTOP,SIGSTP,SIGTTIN,SIGTTOU的信号删掉。
** void signal_wake_up(struct task_struct *t, int resume)
*** kernel/signal.c:
- ULK:to notify the process about the new pending signal
- 若想恢复执行，那么就不管进程的状态是TASK_INTERRUPTIBLE，TASK_STOPPED还是TASK_TRACED.
- 会调的wake_up_state,转而调用try_to_wake_up来唤配进程。若在其它CPU会发一个CPU间中断让它调
  度。
** fastcall NORET_TYPE void do_exit(long code)
*** kernel/exit.c:
- 在能在中断上下文调的，不能对进程0进程1调用
- 按照字面意思，PT_TRACE_EXIT应该是指跟踪进程退出，就是在退出时通知跟踪进程。
** static void exit_notify(struct task_struct *tsk)
*** kernel/exit.c:
- 有一个调用exit同时该进程被选中来执行一个线程组信号。这时它要找其它线程来处理。
- 有注释：Check to see if any process groups have become orphaned as a result of our
  exiting, and if they have any stopped jobs, send them a SIGHUP and then a SIGCONT.
  (POSIX 3.2.2.2)
- 如果被杀进程的exit_signal不等于SIGCHLD且exit_signal不为空，安全域或执行域被修改且没有
  KILL权限那么改exit_signla为SIGCHLD。为了是让父进程知道子进程已死。
- 进入这个函数之后，退出进程有可能在EXIT_ZOMBIE状态，也有可能在EXIT_DEAD状态，如果进入
  EXIT_DEAD了，那么之后会调用release_task.若没在出退信号且不被跟踪或在进行组退出就是
  EXIT_DEAD,否则是EXIT_ZOMBIE.如果在这里被设置成EXIT_ZOMBIE,那么会在那被设成EXIT_DEAD呢？好
  像是如果在EXIT_ZOMBIE时，就表明等待父进程调用wait类函数。
- 在这里会把forget_original_parent收集到的子进程给release_task掉。
- 在这个函数一定会把tsk->flags设为PF_DEAD，说明无论是EXIT_DEAD还是EXIT_ZOMBIE,那是PF_DEAD.
- 想到一个问题：release_task之后应该是所有的内存空都被收回了，但是为什么被退出的进程还可以
  运行呢？因为内存空间被收回后并没有把内存空间的内容清掉且这些内存没有被分配，因为已把抢占
  给禁止了，所以进程的代码代和数据都没被破坏。好像上面那个解释是错的，因为ULK：The
  release_task( ) function detaches the last data structures from the descriptor of a
  zombie process; it is applied on a zombie process in two possible ways: by the
  do_exit()function if the parent is not interested in receiving signals from the child,
  or by the wait4( ) or waitpid( ) system calls after a signal has been sent to the
  parent. In the latter case, the function also will reclaim the memory used by the
  process descriptor,while in the former case the memory reclaiming will be done by the
  scheduler (see Chapter7).
** static inline void forget_original_parent(struct task_struct * father, struct list_head *to_release)
*** kernel/exit.c:
- ULK：All child processes created by the terminating process become children of another
  process in the same thread group, if any is running, or otherwise of the init process.
- 里面有一个child_reaper是被初始化为init_task的。
- 要处理这个进程的两个进程链表：子进程链表，跟踪进程链表。在task_struct->children里这两种的
  进程那包含了。
- 有注释：If something other than our normal parent is ptracing us, then send it a SIGCHLD
  instead of honoring exit_signal.  exit_signal only has special meaning to our real
  parent.被杀进程要是被跟踪，就发SIGCHLD，否则且exit_signal不为空且所在的线程组没有其它线程
  (thread_group_empty(tsk)是指tsk作为一个线程所在的线程组没有其它线程，不是指以tsk作为线
  程组领头线程的线程组没有其它线程)（为什么要这个条件呢？）
** static inline void reparent_thread(task_t *p, task_t *father, int traced)
*** kernel/exit.c:
- exit_signal等于-1是什么意思,表示没有任何信号，就是初始值，不能用0，这个好像用来测试的。
- 若子进程有退出信号，那么把它改成SIGCHLD,为什么要这样子做呢？
- pdeath_singal是在ULK：The signal sent when the parent dies时候发的。但是发给谁呢？从代码
  看好像是发给自已,从forget_original_parent来看好像发给父进程的.
- 在task_struct里关于跟踪的链表也有两个：ptrace_list和ptrace_children.
- 在这里father是正在退出的进程,在进入这个函数之前real_parent被改了，无论是有没跟踪的。
- 参数traced说明的是父进程有没有被跟踪。
- 如果父进程是被跟踪的且p的parent和real_parent不相同，那么就把p插入到real_parent的
  ptrace_children中,但什么时候父进程是被跟踪的且parent与修改之后的real_parent是相同的呢？好
  像这样是不可能的吧，因为在以参数trace=1调用之前p是在father->ptrace_children链表里的，所以
  p->parent一定是father，又因为在调用reparent_thread () 之前调用了choose_new_parent把
  p->real_parent改成了不可能为father的reaper,所以在reparent_thread里是不可能有
  p->parent==p->real_parent的,如果有可能的话，那么可能是p虽在father->ptrace_children里但是
  p->parent不等于father.
- ptrace不为0是什么意思，为0又是什么意思。
- 如果进程A在进程B的children中，那么进程A的real_parent一定是进程B吗？
- 如果进程A在进程B的ptrace_children中，那么进程A的parent一定是进程B吗？
- 不知道为什么在traced假的时候要设p->ptrace为0而且还把p->parent改为p->real_parent，如果是这
  样的话，那么有可能有这样一种情况：p->parent和p->real_parent不相同(p被p->parent跟踪)且它的
  real_parent正被杀成为father参数且又先以traced=0调用reparent_thread ()，这时会在reparent里
  把p->ptrace设为0，把p->parent设为p->real_parent,但一直没有从p->parent的ptrace_children把
  p删掉，这合理吗？
- 在这个函数里如果发现有僵死进程且有退出信号那么就通知父进程，为什么还要加多一个判断线程组是否为空呢？
- 关于p->state==TASK_TRACED 有注释:If it was at a trace stop, turn it into a normal stop
  since it's no longer being traced.
- 又有不明白了，本来p和father是父子关系，按理说应该在同一个进程组，但是为什么还要判断是否在
  同一个进程组呢？可以这样的。孤儿进程组： 一个进程组中的所有进程的父进程要么是该进程组的一
  个进程，要么不是该进程组所在的会话中的进程。 一个进程组不是孤儿进程组的条件是，该组中有一
  个进程其父进程在属于同一个会话的另一个组中。函数里有一个判断孤立进程组的代码？又有一个问
  题：在同一个进程组里的任意一个进程都与同组中其它至少一个进程有父子或兄弟关系吗？
- 在forget_original_parent里以traced为0调用reparent_thread时的father是p的real_parent,在这种
  情况下，在reparent_thread里会把对p的跟踪去掉，换句话说就是如果一个进程A的父进程
  real_parent被杀掉，那么进程A就不能再被跟踪和去跟踪了，因为p->ptrace被清和p->parent设为
  p->real_parent。
- 如果进程A的父进程被杀掉，且进程A被跟踪且是EXIT_ZOMBIE状态，且没有退出信号，这种情况为什么
  要收集这些进程呢？
- 在forget_original_parent里以traced为1调用reparent_thread时的father是p的parent（可能与
  real_parent一样），且p->parent不等于p->real_parent,在这种情况下，reparent_thread里会把
  p->ptrace_list插入到p->real_parent->ptrace_children中，但p->real_parent可能不是一个跟踪函
  数，为什么要这样做呢？有这样的注释：Preserve ptrace links if someone else is tracing
  this child.
** void ptrace_untrace(task_t *child)
*** kernel/ptrace.c:
- 也不是一定是切回TASK_STOPPED状态，还要看看是不是有停止信号。
** void release_task(struct task_struct * p)
*** kernel/exit.c:
- 在这里p->ptrace还有可能不为0，这是会调用__ptrace_unlink把p->trace改为0
- 为什么如果这个函数被跟踪就要脱离跟踪呢?而且是在release_task里做
- ULK关于task_struct->parent的说明：this is the process that must be signaled whn the
  child process terminates。
- 看了ULK的一段话:If the process is not a thread group leader, the leader is a zombie, and
  the process is the last member of the thread group, the function sends a signal to the
  parent of the leader to notify it of the death of the process.和看了源码,有一个结
  论:task_struct->group_leader是线程组的领头进程的task_struct.为什么要这样的需求呢?
- 通知已在EXIT_ZOMBIE状态的进程还有用吗?它会做出响应.
- 为什么thread_group_empty(leader)为true时表示被杀进程是最后一个线程,因为被杀进程
  在_unhash_process里被从PIDTYPE_TGID中删除了.
- 在这里调用了put_task_struct回收task_struct了
- 有注释:If we were the last child thread and the leader has exited already, and the
  leader's parent ignores SIGCHLD, then we are the one who should release the leader.所以在
  最后p又会回到函数的开始来把leader删除掉.
** void __ptrace_unlink(task_t *child)
*** kernel/ptrace.c:
- 有一个问题：silbing是一定与real_parent有关系的吗？如果parent与real_parent不相等就和
  parent没有任何关系吗？如果是这样，那为什么还要在这个函数里调同REMOVE_LINKS(child)呢？因为
  REMOVE_LINKS是与real_parent有关的.
- 
** void __exit_signal(struct task_struct *tsk)
*** kernel/signal.c:
- atomic_dec_and_test(v):Subtract 1 from *v and return 1 if the result is zero; 0
  otherwise
- 为什么没有其它进程用signal之后还可以找到next_thread呢？
- 关于group_exit_task有注释： notify group_exit_task when ->count is equal to notify_count；
  everyone except group_exit_task is stopped during signal delivery of fatal signals,
  group_exit_task processes the signal.
- notify_count是通知group_exit_task的阀值，有这种需求吗？
- flush_sigqueue(tsk->pending)是一定的，但是共享的要在signal_struct使用计数为0的时候才flush.
- 如果没有人用signal_struct会在最后回收signal_struct结构体。
** void __exit_sighand(struct task_struct *tsk)
*** kernel/signal.c:
- 这个函数比较简单，没人使用就直接回收。
** static void __unhash_process(struct task_struct *p)
*** kernel/exit.c:
- 减nr_threads, 从PIDTYPE_PID, PIDTYPE_TGID,中删除， 若是线程组领头进程就从PIDTYPE_PGID和
  PIDTYPE_SID中删除，从进程链表中删除。
- 要为线程组领头进程才可以减process_counts,为什么会这样呢?可能创建一个非领头线程时不会增加
  process_coun
- 在这里有可能p->pid为空吗?
** void fastcall sched_exit(task_t * p)
*** kernel/sched.c:
- 用来修改父进程的时间片和平均睡眠时间.注意父进程是parent而不是real_parent
- 有注释:Potentially available exiting-child timeslices are retrieved here - this way the
  parent does not get penalized for creating too many threads.
** void disable_irq(unsigned int irq)
*** kernel/irq/manage.c:
- 这个函数要同步的，看是否正在执行这个中断函数。所以进入中断函数之后不能禁止本中断，这可能是
  为什么要在进入该中断函数之前系统会自已禁止中断。
** void disable_irq_nosync(unsigned int irq)
*** kernel/irq/manage.c:
- depth是先判断再增加的
- 这个函数可以多次被调用，仅是在depth上有变化。
** void synchronize_irq(unsigned int irq)
*** kernel/irq/manage.c:
- 这里的这个是在多处理器的情况下实现的，在非多处理器的情况下的实现在
  include/linux/hardirq.h下，就是一个barrier而己。
- 在进行处理中就relax cpu.
** void enable_irq(unsigned int irq)
*** kernel/irq/manage.c:
- 在case 1时不用break,我还以为depth没有减少
- 虽然在case 1时会挽回丢失的中断，但是已经晚了，因为中断不是在被应答之后马上处理的，这种情
  况有点意思，CPU A在接收到中断后接着CPU B才禁止中断，但是因为中断丢失所以要在CPU B禁止之后
  的不确定时间后才执行中断。
- 有IRQ_PENDING和IRQ_DISABLE就表明有中断丢失了
** fastcall unsigned int __do_IRQ(unsigned int irq, struct pt_regs *regs)
*** kernel/irq/handle.c:
- 在这里会增加kstat->irqs[irq],kstat是per_cpu变量。
- 为什么在这个函数里还要检查IRQ_DISABLE和IRQ_INPROGRESS呢？
- 在这个函数里会把IRQ_PENDING清掉，若IRQ_DISABLE或IRQ_INPROGRESS设置了也有可能会把
  IRQ_PENDING设置了。
- 相同的中断处理函数有可能正在别的CPU上执行，为什么不推到正在处理相同的CPU上运行该中断处理
  函数呢？ULK：This leads to a simpler kernel architecture because device drivers'
  interrupt service routines need not to be reentrant (their execution is
  serialized). Moreover, the freed CPU can quickly return to what it was doing, without
  dirtying its hardware cache; this is beneficial to system performance.

