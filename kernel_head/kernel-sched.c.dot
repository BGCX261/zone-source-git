digraph sched_c{
        subgraph cluster_preempt_schedule{
                label="asmlinkage void __sched preempt_schedule(void)";
                set_ti_current_thread_info[label="set_ti_current_thread_info"];
                ti_preempt_count_not_0_or_irqs_disabled[label="ti_preempt_count_not_0_or_irqs_disabled"];
                return[label="return"];
                add_preempt_count_PPREEMPT_ACTIVE[label="add_preempt_count_PPREEMPT_ACTIVE"];
                save_current_lock_depth[label="save_current_lock_depth"];
                set_current_lock_depth_neg_1[label="set_current_lock_depth_neg_1"];
                schedule[label="()"];
                restore_current_lock_depth[label="restore_current_lock_depth"];
                sub_preempt_count_PREEMPT_ACTIVE[label="sub_preempt_count_PREEMPT_ACTIVE"];
                barrier[label="()"];
                test_thread_flag_TIF_NEED_RESCHED[label="test_thread_flag_TIF_NEED_RESCHED"];
        }

		        subgraph cluster_enqueue_task{
                label="enqueue_task(struct task_struct *p, prio_array_t *array)";

		sched_info_queued[label="sched_info_queued()"];
		list_add_tail[label="list_add_tail(&p->run_list, array->queue + p->prio)"];
		__set_bit[label="__set_bit(p->prio, array->bitmap)"];
		array_nr_active_inc;
		p_array_array[label="p->array = array"];

		sched_info_queued -> list_add_tail;
		list_add_tail -> __set_bit;
		__set_bit -> array_nr_active_inc;
		array_nr_active_inc -> p_array_array;
        }

        subgraph cluster_dequeue_task{
                label="dequeue_task(struct task_struct *p, prio_array_t *array)";

		array_nr_active_dec;
		list_del[label="list_del()"];
		list_empty[label="list_empty(array->queue + p->prio)"];
		__clear_bit[label="__clear_bit(p->prio, array->bitmap)"];
		end;

		array_nr_active_dec -> list_del;
		list_del -> list_empty;
		list_empty -> __clear_bit[label="is empty"];
		list_empty -> end;
		__clear_bit -> end;
        }

        subgraph cluster_default_wake_function{
				label="int default_wake_function(wait_queue_t *curr, unsigned mode, int sync, void *key)"

				get_curr_task[label="task_t *p = curr->task;"];
				try_to_wake_up[label="try_to_wake_up(p, mode, sync);"];

				get_curr_task -> try_to_wake_up;
		}

		subgraph cluster_sleep_on{
				label="sleep_on(wait_queue_head_t *q)";

				init_waitqueue_entry[label="init_waitqueue_entry(&wait, current);"];
				set_UNINTERRUPTIBLE[label="set_UNINTERRUPTIBLE"];
				spin_lock_irqsave_1[label="spin_lock_irqsave(&q->lock,flags);"];
				__add_wait_queue[label="__add_wait_queue(q, &wait);"];
				spin_unlock_1[label="spin_unlock_restore(&q->lock);"];
				schedule[label="schedule()"];
				spin_lock_irqsave_2[label="spin_lock_irqsave(&q->lock,flags);"];
				spin_unlock_2[label="spin_unlock(&q->lock);"];
				__remove_wait_queue[label="__remove_wait_queue(q, &wait);"];

				init_waitqueue_entry -> set_UNINTERRUPTIBLE;
				set_UNINTERRUPTIBLE -> spin_lock_irqsave_1;
				spin_lock_irqsave_1 -> __add_wait_queue;
				__add_wait_queue -> spin_unlock_1;
				spin_unlock_1 -> schedule;
				schedule -> spin_lock_irqsave_2;
				spin_lock_irqsave_2 -> __remove_wait_queue;
				__remove_wait_queue -> spin_unlock_2;
		}

		subgraph cluster_sleep_on_timeout{
				label="sleep_on_timeout(wait_queue_head_t *q, long timeout)";

				init_waitqueue_entry[label="init_waitqueue_entry(&wait, current);"];
				set_UNINTERRUPTIBLE[label="set_UNINTERRUPTIBLE"];
				spin_lock_irqsave_1[label="spin_lock_irqsave(&q->lock,flags);"];
				__add_wait_queue[label="__add_wait_queue(q, &wait);"];
				spin_unlock_1[label="spin_unlock_restore(&q->lock);"];
				schedule_timeout[label="schedule_timeout()"];
				spin_lock_irqsave_2[label="spin_lock_irqsave(&q->lock,flags);"];
				spin_unlock_2[label="spin_unlock(&q->lock);"];
				__remove_wait_queue[label="__remove_wait_queue(q, &wait);"];

				init_waitqueue_entry -> set_UNINTERRUPTIBLE;
				set_UNINTERRUPTIBLE -> spin_lock_irqsave_1;
				spin_lock_irqsave_1 -> __add_wait_queue;
				__add_wait_queue -> spin_unlock_1;
				spin_unlock_1 -> schedule_timeout;
				schedule_timeout -> spin_lock_irqsave_2;
				spin_lock_irqsave_2 -> __remove_wait_queue;
				__remove_wait_queue -> spin_unlock_2;
		}

		subgraph cluster__wake_up_locked{
				label="__wake_up_locked(wait_queue_head_t *q, unsigned int mode,int nr_exclusive, void *key)";

				__wake_up_common[label="__wake_up_common(q, mode, 1, 0, NULL);"];
		}

		subgraph cluster__wake_up_common{
				label="void __wake_up_common(wait_queue_head_t *q, unsigned int mode,int nr_exclusive, int sync, void *key)";

				list_for_each_safe[label="list_for_each_safe(tmp, next, &q->task_list)"];
				list_entry[label="get wait_queue_t \llist_entry(tmp, wait_queue_t, task_list);"];
				call_wait_queue_t_func_and_WQ_FLAG_EXCLUSIVE_set_and_dec_nr_exclusive_null[label="call_wait_queue_t_func_and_WQ_FLAG_EXCLUSIVE_set_and_dec_nr_exclusive_null"];
				return[label="return"];

				list_for_each_safe -> return;
				list_for_each_safe -> list_entry;
				list_entry -> call_wait_queue_t_func_and_WQ_FLAG_EXCLUSIVE_set_and_dec_nr_exclusive_null;
				call_wait_queue_t_func_and_WQ_FLAG_EXCLUSIVE_set_and_dec_nr_exclusive_null -> return;
		}

		subgraph cluster___wake_up_sync{
				label="void __wake_up_sync(wait_queue_head_t *q, unsigned int mode, int nr_exclusive)";

				nr_exclusive[label="nr_exclusive_null"];
				clean_sync[label="clean_sync"];

				spin_lock_irqsave_q_lock[label="spin_lock_irqsave_q_lock"];
				__wake_up_common[label="__wake_up_common(q, mode, nr_exclusive, sync, NULL);"];
				spin_unlock_irqsave_q_lock[label="spin_unlock_irqsave_q_lock"];

				spin_lock_irqsave_q_lock -> __wake_up_common;
				__wake_up_common -> spin_unlock_irqsave_q_lock;
		}

		subgraph cluster___wake_up_locked{
				label="void __wake_up_locked(wait_queue_head_t *q, unsigned int mode)";

				__wake_up_common[label="__wake_up_common(q, mode, 1, 0, NULL);"];
		}

		subgraph cluster_complete{
				label="void fastcall complete(struct completion *x)";
				lock_x_wait_lock[label="lock_x_wait_lock"];
				inc_x_done[label="inc_x_done"];
				__wake_up_common_x_wait_TASK_UNINTERRUPTIBLE_or_TASK_INTERRUPTIBLE_1_0_NULL[label="__wake_up_common_x_wait_TASK_UNINTERRUPTIBLE_or_TASK_INTERRUPTIBLE_1_0_NULL"];
				unlock_x_wait_lock[label="unlock_x_wait_lock"];
		}

		subgraph cluster_complete_all{
				label="void fastcall complete_all(struct completion *x)";
				lock_x_wait_lock[label="lock_x_wait_lock"];
				x_done_self_add_UNIT_MAX_divide_2[label="x_done_self_add_UNIT_MAX_divide_2"];
				__wake_up_common_x_wait_TASK_UNINTERRUPTIBLE_or_TASK_INTERRUPTIBLE_0_0_NULL[label="__wake_up_common_x_wait_TASK_UNINTERRUPTIBLE_or_TASK_INTERRUPTIBLE_0_0_NULL"];
				unlock_x_wait_lock[label="unlock_x_wait_lock"];
		}

		subgraph cluster_wait_for_completion{
				label="void fastcall __sched wait_for_completion(struct completion *x)";
				might_sleep[label="might_sleep ()"];
				lock_x_wait_lock[label="lock_x_wait_lock"];
				x_done_null[label="x_done_null"];
				DECLARE_WAITQUEUE[label="DECLARE_WAITQUEUE (wait,current)"];
				set_wait_flags_WQ_FLAG_EXCLUSIVE[label="set_wait_flags_WQ_FLAG_EXCLUSIVE"];
				__add_wait_queue_tail_x_wait_wait[label="__add_wait_queue_tail_x_wait_wait"];
				__set_current_state_TASK_UNINTERRUPTIBLE[label="__set_current_state_TASK_UNINTERRUPTIBLE"];
				unlock_x_wait_lock[label="unlock_x_wait_lock"];
				schedule[label="schedule ()"];
				lock_x_wait_lock[label="lock_x_wait_lock"];
				x_done_not_null[label="x_done_not_null"];
				__remove_wait_queue_x_wait_wait[label="__remove_wait_queue_x_wait_wait"];
				dec_x_done[label="dec_x_done"];
				unlock_x_wait_lock[label="unlock_x_wait_lock"];
		}

		subgraph cluster_preempt_schedule_irq{
				label="asmlinkage void __sched preempt_schedule_irq(void)";
				set_ti_current_thread_info[label="set_ti_current_thread_info"];
				add_preempt_count_PREEMPT_ACTIVE[label="add_preempt_count_PREEMPT_ACTIVE"];
				CONFIG_PREEMPT_BKL[label="CONFIG_PREEMPT_BKL"];
				set_saved_lock_depth_current_lock_depth[label="set_saved_lock_depth_current_lock_depth"];
				set_current_lock_depth_neg_1[label="set_current_lock_depth_neg_1"];
				local_irq_enalbe[label="local_irq_enalbe ()"];
				schedule[label="schedule ()"];
				local_irq_disable[label="local_irq_disable ()"];
				CONFIG_PREEMPT_BKL_1[label="CONFIG_PREEMPT_BKL"];
				set_current_lock_depth_saved_lock_depth[label="set_current_lock_depth_saved_lock_depth"];
				sub_preempt_count_PREEMPT_ACTIVE[label="sub_preempt_count_PREEMPT_ACTIVE"];
				barrier[label="barrier ()"];
				test_thread_flag_TIF_NEED_RESCHED[label="test_thread_flag_TIF_NEED_RESCHED"];
		}

		subgraph cluster_account_user_time{
				label="void account_user_time(struct task_struct *p, cputime_t cputime)";
				set_cpustat_kstat_this_cpu_cpustat[label="set_cpustat_kstat_this_cpu_cpustat"];
				set_p_utime_cputime_add_p_utime_cputime[label="set_p_utime_cputime_add_p_utime_cputime"];
				TASK_NICE_p_great_0[label="TASK_NICE_p_great_0"];
				set_cpustat_nice_cputime64_add_cpustat_nice_cputime_to_cputime64_cputime[label="set_cpustat_nice_cputime64_add_cpustat_nice_cputime_to_cputime64_cputime"];
				set_cpustat_user_cputime64_add_cpustat_user_cputime_to_cputime64_cputime[label="set_cpustat_user_cputime64_add_cpustat_user_cputime_to_cputime64_cputime"];
		}

		subgraph cluster_account_system_time{
				label="void account_system_time(struct task_struct *p, int hardirq_offset,cputime_t cputime)";
				set_cpustat_kstat_this_cpu_cpustat_1[label="set_cpustat_kstat_this_cpu_cpustat"];
				set_rq_this_rq[label="set_rq_this_rq"];
				set_p_stime_cputime_add_p_stiem_cputime[label="set_p_stime_cputime_add_p_stiem_cputime"];
				hardirq_count_sub_hardirq_offset_not_0[label="hardirq_count_sub_hardirq_offset_not_0"];
				set_cpustat_irq_cputime64_add_cpustat_irq_cputime_to_cputime64_cputime[label="set_cpustat_irq_cputime64_add_cpustat_irq_cputime_to_cputime64_cputime"];
				softirq_count_not_null[label="softirq_count_not_null"];
				set_cpustat_softirq_cputime64_add_cpustat_softirq_cputime_to_cputime64_cputime[label="set_cpustat_softirq_cputime64_add_cpustat_softirq_cputime_to_cputime64_cputime"];
				p_not_eq_rq_idle[label="p_not_eq_rq_idle"];
				set_cpustat_system_cputime64_add_cpustat_system_cputime_to_cputime64_cputime[label="set_cpustat_system_cputime64_add_cpustat_system_cputime_to_cputime64_cputime"];
				atomic_read_rq_nr_iowait_great_0[label="atomic_read_rq_nr_iowait_great_0"];
				set_cpustat_iowait_cputime64_add_cpustat_iowait_cputime_to_cputime64_cputime[label="set_cpustat_iowait_cputime64_add_cpustat_iowait_cputime_to_cputime64_cputime"];
				set_cpustat_idle_cputime64_add_cpustat_idle_cputime_to_cputime64_cputime[label="set_cpustat_idle_cputime64_add_cpustat_idle_cputime_to_cputime64_cputime"];
				acct_update_integrals_p[label="acct_update_integrals_p"];
				update_mem_hiwater[label="update_mem_hiwater_p"];
		}

		subgraph cluster_scheduler_tick{
				size="10,12";
				ratio=filled;
				bgcolor=darkolivegreen4;
				node[style=filled,shape=box,fillcolor=gray];
				timestamp_last_tick;
				swap_process[label="swap process"];
				set_TIF_NEED_RESCHED_swap[label="set TIF_NEED_RESCHED"];
				set_TIF_NEED_RESCHED_normal[label="set TIF_NEED_RESCHED"];
				hyper_threading;
				replace[label="haven't replace"];
				lock_rq[label="lock_rq"];
				descrease_time[shape=record,label="{{<f0>realtime|<f1>normal}}"];
				descrease_time_fifo[label="descrease_time"];
				descrease_time_normal[label="descrease_time"];
				effective_prio[label="effective_prio()"];
				
				fifo_rr[shape=record,label="{{<f0>FIFO|<f1>RR}}"];
				nothing[label="nothing to do"];
				move_tail[label="move to tail if 0"];
				dequeue_task[label="dequeue_task()"];
				reset_clean_time[label="reset timeslice and clean first_time,"];
				set_expired_timestamp[label="set expired_timestamp"];
				insert_active_expired[label="insert active or expired,\lTASK_INTERACTIVE,\lEXPIRED_STARVING"];
				timesile_granularity[label="TIMESILE_GRANULARITY"];
				unlock_rq[label="unlock_rq"];
				reblance_tick[label="reblance_tick()"];
				
				timestamp_last_tick -> swap_process;
				swap_process -> replace;
				replace -> lock_rq;
				lock_rq -> descrease_time;
				
				descrease_time:f0 -> fifo_rr;
				fifo_rr:f0:s -> nothing;
				fifo_rr:f1 -> descrease_time_fifo;
				descrease_time_fifo -> move_tail;
				
				unlock_rq -> reblance_tick;
				swap_process -> set_TIF_NEED_RESCHED_swap[label="is swap"];
				set_TIF_NEED_RESCHED_swap -> hyper_threading;
				hyper_threading -> reblance_tick;
				nothing -> unlock_rq;
				move_tail -> unlock_rq;
				
				descrease_time:f1 -> descrease_time_normal;
				descrease_time_normal -> timesile_granularity;
				descrease_time_normal -> dequeue_task[label="timeout"];
				dequeue_task -> set_TIF_NEED_RESCHED_normal;
				set_TIF_NEED_RESCHED_normal -> effective_prio;
				effective_prio -> reset_clean_time;
				reset_clean_time -> set_expired_timestamp;
				set_expired_timestamp -> insert_active_expired;
				insert_active_expired -> unlock_rq;
				timesile_granularity -> unlock_rq;
		}

		subgraph cluster_this_rq{
				label="#define this_rq()";
				__get_cpu_var[label="(&__get_cpu_var(runqueues))"];
		}

		subgraph cluster_sched_fork{
				label="void fastcall sched_fork(task_t *p)";
				set_p_state_TASK_RUNNING[label="set_p_state_TASK_RUNNING"];
				INIT_LIST_HEAD_p_run_list[label="INIT_LIST_HEAD_p_run_list"];
				clear_p_array[label="clear_p_array"];
				lock_p_switch_lock[label="lock_p_switch_lock"];
				memset_p_sched_info[label="memset_p_sched_info"];
				set_p_thread_info_preempt_count_1[label="set_p_thread_info_preempt_count_1"];
				local_irq_disable[label="local_irq_disable"];
				set_p_time_slice_current_time_slice_add_1_move_right_1[label="set_p_time_slice_current_time_slice_add_1_move_right_1"];
				set_p_first_time_slice_1[label="set_p_first_time_slice_1"];
				current_time_slice_self_move_right_1[label="current_time_slice_self_move_right_1"];
				set_p_timestamp_sched_clock[label="set_p_timestamp_sched_clock"];
				current_time_slice_null[label="current_time_slice_null"];
				set_current_time_slice_1[label="set_current_time_slice_1"];
				preempt_disable[label="preempt_disable ()"];
				scheduler_tick[label="scheduler_tick ()"];
				local_irq_enable[label="local_irq_enable ()"];
				preempt_enable[label="preempt_enable ()"];
				local_irq_enable_1[label="local_irq_enable ()"];
		}

		subgraph cluster_try_to_wake_up{
				label="try_to_wake_up(p, stat, sync)";
				bgcolor=gray;
				size="10,10";
				ratio=filled;
				node[style=filled,shape=box,fillcolor=darkorange1];
				
				task_rq_lock[label="task_rq_lock()\ldisable irq and lock rq"];
				mask[label="cmp with mask of process states"];
				set_TASK_RUNNING[label="set TASK_RUNNING;"];
				array[label="task-\>array"];
				task_rq_unlock[label="task_rq_unlock()\lenable irq and unlock rq"];
				move_to_cpu[label="move to cpu"];
				uninterruptible[label="nr_uninterruptible--\lp-\>actived=-1"];
				resched_task[shape=record,label="{resched_task()|{uniprocessor|multiprocessor}}"];

				subgraph cluster_active_task{
						label= "active_task()";
						sched_clock[label="sched_clock()"];
						recalc_task_prio[label="recalc_task_prio()"];
						p_actived[label="p-\>actived"];
						timestamp[label="timestamp"];
						insert_active_list[label="insert active list"];

						sched_clock -> recalc_task_prio;
						recalc_task_prio -> p_actived;
						p_actived -> timestamp;
						timestamp -> insert_active_list;
                }
                

				task_rq_lock -> mask;
				mask -> task_rq_unlock[label="correspond"];
				mask -> array;
				array -> set_TASK_RUNNING;
				array -> move_to_cpu[label="NULL"];
				move_to_cpu -> uninterruptible[label="is UNINTRRUPT"];
				uninterruptible -> sched_clock;
				move_to_cpu -> sched_clock;
				insert_active_list -> resched_task[label="is local cpu or sync=1"];
				insert_active_list -> set_TASK_RUNNING;
				resched_task -> set_TASK_RUNNING;
				set_TASK_RUNNING -> task_rq_unlock;
		}

		subgraph cluster_recalc_task_prio{
				label="recalc_task_prio(p,now)";
				size="16,10";
				ratio=filled;

				node[style=filled,shape=box,fillcolor=gray];
				sleep_time_min[label="sleep_time = min(now - p->timestamp, 10^9)"];
				effective_prio[label="effective_prio()"];
				p_sleep_avg[label="p->sleep_avg = 900"];
				CURRENT_BONUSE[label="CURRENT_BONUSE for bonuse"];
				sleep_time_0[label="sleep_time = 0"];
				sleep_avg_reach_the_limit[label="sleep_avg reach the limit"];
				
				uninterruptible_not_thread[shape=hexagon,label="uninterruptible and \lnot kernel thread"];
				add_sleep_time_avg[label="add sleep_time to sleep_avg"];
				add_and_greater[shape=diamond,label="sleep_time+sleep_avg"];
				set_sleep_avg_lmt[label="set sleep_avg limit\land sleep_time 0"];
				limit_sleep_avg[label="sleep_avg under 1000"];
				
				sleep_time_min -> effective_prio[decorate=true,label="smaller than 0"];
				sleep_time_min -> p_sleep_avg[decorate=true,label="kernel thread, \lTASK_UNINTERRUPTIBLE,\lsleep time limit"];
				p_sleep_avg -> effective_prio;
				sleep_time_min -> CURRENT_BONUSE;
				CURRENT_BONUSE -> uninterruptible_not_thread;
				uninterruptible_not_thread -> sleep_avg_reach_the_limit[label="true"];
				sleep_avg_reach_the_limit -> sleep_time_0[label="true"];
				sleep_avg_reach_the_limit -> add_and_greater[label="false"];
				add_and_greater -> set_sleep_avg_lmt[label="greater limit"];
				add_and_greater -> add_sleep_time_avg;
				uninterruptible_not_thread -> add_sleep_time_avg[label="false"];
				sleep_time_0 -> add_sleep_time_avg;
				// sleep_time_0 -> set_sleep_avg_lmt[decorate=true,label="sleep_time+p->slep_avg \lnot smaller than limit"];
				set_sleep_avg_lmt -> add_sleep_time_avg;
				add_sleep_time_avg -> limit_sleep_avg;
				limit_sleep_avg -> effective_prio;
		}

		subgraph cluster_schedule{
				label="schedule()";
				size="10,18";
				ratio=filled;
				
				node[style=filled, shape = box, margin="0.05,0.005",
					 height="0.1",width="0.1"];

					 exiting_atomic;
					 dump_stack[label="dump_stack()"];
					 dump_stack_1[label="dump_stack()"];
					 profile_hit[label="profile_hit()"];
					 preempt_disable[label="preempt_disable()"];
					 
					 release_kernel_lock[label="release_kernel_lock()"];
					 idle_running;
					 
					 sched_clock[label="calc cpu time, limit in 1s"];
					 schedstat_inc_rq_sched_cnt;
					 
					 disable_irq_lock[label="disalbe_irq, lock rq"];
					 PF_DEAD[label="check PF_DEAD, set EXIT_DEAD"];
					 deactivate_task[label="deactivate_task"];
					 set_task_running[label="set TASK_RUNNING"];
					 dependent_sleeper[label="dependent_sleeper()"];
					 idle_balance[label="idle_balance()"];
					 exch_active_expired[label="switch active and expired"];
					 search_process[label="search process by bitmask"];
					 add_sleeptime[label="add sleeptime"];
					 add_all_time[label="add all time"];
					 add_fraction_time[label="add fraction time"];
					 prefect;
					 clear_TIF_NEED_RESCHED[label="clear TIF NEED RESCHED"];
					 rcq_qsctr_inc;
					 substract_sleeptime[label="substract sleeptime"];
					 set_timestamps[label="set timestamps"];
					 same_process[label="same process"];
					 context_switch[label="context_switch()"];
					 set_prev_mm[label="set prev_mm field"];
					 barrier[label="barrier()"];
					 finish_task_switch[label="finish_task_switch()"];
					 
					 exiting_atomic -> dump_stack[color=red];
					 exiting_atomic -> profile_hit;
					 profile_hit -> preempt_disable;
					 preempt_disable -> release_kernel_lock;
					 release_kernel_lock -> idle_running;
					 idle_running -> schedstat_inc_rq_sched_cnt;
					 idle_running -> dump_stack_1[color=red];
					 schedstat_inc_rq_sched_cnt -> sched_clock;
					 sched_clock -> disable_irq_lock;
					 disable_irq_lock -> PF_DEAD;
					 PF_DEAD -> deactivate_task[label="NOT TASK_RUNNINT\land not preempt in kernel mode"];
					 deactivate_task -> set_task_running[label="not signal pend \land in TASK_INTERRUPTIBLE"];
					 set_task_running -> dependent_sleeper[label="have processes in rq"];
					 dependent_sleeper -> exch_active_expired[label="haven't processes in active"];
					 dependent_sleeper -> search_process[label="have processes in active"];
					 set_task_running -> idle_balance[label="haven't processes in rq"];
					 idle_balance -> exch_active_expired[label="haven't processes in active"];
					 idle_balance -> search_process[label="have processes in active"];
					 exch_active_expired -> search_process;
					 search_process -> add_sleeptime;
					 add_sleeptime -> add_all_time[label="by intr or defer"];
					 add_sleeptime -> add_fraction_time[label="by sys call"];
					 
					 add_all_time -> prefect;
					 add_fraction_time -> prefect;
					 prefect -> clear_TIF_NEED_RESCHED;
					 clear_TIF_NEED_RESCHED -> rcq_qsctr_inc;
					 rcq_qsctr_inc -> substract_sleeptime;
					 substract_sleeptime -> set_timestamps;
					 set_timestamps -> same_process;
					 same_process -> context_switch[label="not the same"];
					 same_process -> barrier;
					 context_switch -> set_prev_mm;
					 set_prev_mm -> barrier;
					 barrier -> finish_task_switch;
			 }

}
